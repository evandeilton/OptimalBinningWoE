[{"path":"https://evandeilton.github.io/OptimalBinningWoE/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 OptimalBinningWoE authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"First Last. Author, maintainer.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Last F (2024). OptimalBinningWoE: Package (One Line, Title Case). R package version 0.1.4.9000, https://evandeilton.github.io/OptimalBinningWoE/.","code":"@Manual{,   title = {OptimalBinningWoE: What the Package Does (One Line, Title Case)},   author = {First Last},   year = {2024},   note = {R package version 0.1.4.9000},   url = {https://evandeilton.github.io/OptimalBinningWoE/}, }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/index.html","id":"optimalbinningwoe","dir":"","previous_headings":"","what":"What the Package Does (One Line, Title Case)","title":"What the Package Does (One Line, Title Case)","text":"OptimalBinningWoE package offers robust flexible implementation optimal binning Weight Evidence (WoE) calculation data analysis predictive modeling. package particularly useful data preparation credit scoring models can applied statistical modeling contexts.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"What the Package Does (One Line, Title Case)","text":"can install development version OptimalBinningWoE GitHub :","code":"# install.packages(\"devtools\") devtools::install_github(\"evandeilton/OptimalBinningWoE\")"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"What the Package Does (One Line, Title Case)","text":"Work progress!","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/CalculateSpecialWoE.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Special WoE — CalculateSpecialWoE","title":"Calculate Special WoE — CalculateSpecialWoE","text":"Calculate Special WoE","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/CalculateSpecialWoE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Special WoE — CalculateSpecialWoE","text":"","code":"CalculateSpecialWoE(target)"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/CalculateSpecialWoE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Special WoE — CalculateSpecialWoE","text":"target Target values special cases","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/CalculateSpecialWoE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Special WoE — CalculateSpecialWoE","text":"WoE value special cases","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/CreateSpecialBin.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Special Bin — CreateSpecialBin","title":"Create Special Bin — CreateSpecialBin","text":"Create Special Bin","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/CreateSpecialBin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Special Bin — CreateSpecialBin","text":"","code":"CreateSpecialBin(dt_special, woebin, special_woe)"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/CreateSpecialBin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Special Bin — CreateSpecialBin","text":"dt_special Data special cases woebin Existing WoE bins special_woe WoE value special cases","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/CreateSpecialBin.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Special Bin — CreateSpecialBin","text":"Special bin information","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningCategoricalWoE.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning and Weight of Evidence Calculation for Categorical Variables — OptimalBinningCategoricalWoE","title":"Optimal Binning and Weight of Evidence Calculation for Categorical Variables — OptimalBinningCategoricalWoE","text":"Optimal Binning Weight Evidence Calculation Categorical Variables","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningCategoricalWoE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning and Weight of Evidence Calculation for Categorical Variables — OptimalBinningCategoricalWoE","text":"","code":"OptimalBinningCategoricalWoE(   dt,   target,   features,   method,   min_bins,   max_bins,   control,   positive,   preprocessed_data )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningCategoricalWoE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning and Weight of Evidence Calculation for Categorical Variables — OptimalBinningCategoricalWoE","text":"dt data.table containing dataset. target name target variable. features Vector categorical feature names process. method binning method use. min_bins Minimum number bins. max_bins Maximum number bins. control list additional control parameters. positive Character string specifying category considered positive. preprocessed_data List preprocessed data feature.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningCategoricalWoE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning and Weight of Evidence Calculation for Categorical Variables — OptimalBinningCategoricalWoE","text":"list containing results, reports, woebins, bestmod, failed_features.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningDataPreprocessor.html","id":null,"dir":"Reference","previous_headings":"","what":"Preprocesses a numeric or categorical variable for optimal binning with handling of missing values and outliers — OptimalBinningDataPreprocessor","title":"Preprocesses a numeric or categorical variable for optimal binning with handling of missing values and outliers — OptimalBinningDataPreprocessor","text":"function preprocesses given numeric categorical feature, handling missing values outliers based specified method. can process numeric categorical features supports outlier detection various methods, including IQR, Z-score, Grubbs' test. function also generates summary statistics preprocessing.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningDataPreprocessor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preprocesses a numeric or categorical variable for optimal binning with handling of missing values and outliers — OptimalBinningDataPreprocessor","text":"","code":"OptimalBinningDataPreprocessor(   target,   feature,   num_miss_value = -999,   char_miss_value = \"N/A\",   outlier_method = \"iqr\",   outlier_process = FALSE,   preprocess = as.character(c(\"both\")),   iqr_k = 1.5,   zscore_threshold = 3,   grubbs_alpha = 0.05 )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningDataPreprocessor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preprocesses a numeric or categorical variable for optimal binning with handling of missing values and outliers — OptimalBinningDataPreprocessor","text":"target Numeric vector representing binary target variable, 1 indicates positive event (e.g., default) 0 indicates negative event (e.g., non-default). feature Numeric character vector representing feature binned. num_miss_value (Optional) Numeric value replace missing values numeric features. Default -999.0. char_miss_value (Optional) String value replace missing values categorical features. Default \"N/\". outlier_method (Optional) Method detect outliers. Choose \"iqr\", \"zscore\", \"grubbs\". Default \"iqr\". outlier_process (Optional) Boolean flag indicating whether outliers processed. Default FALSE. preprocess (Optional) Character vector specifying return: \"feature\", \"report\", \"\". Default \"\". iqr_k (Optional) multiplier interquartile range (IQR) using IQR method detect outliers. Default 1.5. zscore_threshold (Optional) threshold Z-score detect outliers. Default 3.0. grubbs_alpha (Optional) significance level Grubbs' test detect outliers. Default 0.05.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningDataPreprocessor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preprocesses a numeric or categorical variable for optimal binning with handling of missing values and outliers — OptimalBinningDataPreprocessor","text":"list containing following elements based preprocess parameter: preprocess: DataFrame containing original preprocessed feature values. report: DataFrame summarizing variable type, number missing values, number outliers (numeric features), statistics preprocessing.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningDataPreprocessor.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Preprocesses a numeric or categorical variable for optimal binning with handling of missing values and outliers — OptimalBinningDataPreprocessor","text":"function can handle numeric categorical features. numeric features, replaces missing values num_miss_value can apply outlier detection using different methods. categorical features, replaces missing values char_miss_value. function can return preprocessed feature /report summary statistics.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningDataPreprocessor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Preprocesses a numeric or categorical variable for optimal binning with handling of missing values and outliers — OptimalBinningDataPreprocessor","text":"","code":"if (FALSE) { # \\dontrun{ target <- c(0, 1, 1, 0, 1) feature_numeric <- c(10, 20, NA, 40, 50) feature_categorical <- c(\"A\", \"B\", NA, \"B\", \"A\") result <- OptimalBinningDataPreprocessor(target, feature_numeric, outlier_process = TRUE) result <- OptimalBinningDataPreprocessor(target, feature_categorical) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningGainsTable.html","id":null,"dir":"Reference","previous_headings":"","what":"Generates a Comprehensive Gains Table from Optimal Binning Results — OptimalBinningGainsTable","title":"Generates a Comprehensive Gains Table from Optimal Binning Results — OptimalBinningGainsTable","text":"function takes result optimal binning process generates detailed gains table. table includes various metrics assess performance characteristics bin.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningGainsTable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generates a Comprehensive Gains Table from Optimal Binning Results — OptimalBinningGainsTable","text":"","code":"OptimalBinningGainsTable(binning_result)"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningGainsTable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generates a Comprehensive Gains Table from Optimal Binning Results — OptimalBinningGainsTable","text":"binning_result list containing binning results, must include data frame following columns: \"bin\", \"count\", \"count_pos\", \"count_neg\", \"woe\".","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningGainsTable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generates a Comprehensive Gains Table from Optimal Binning Results — OptimalBinningGainsTable","text":"data frame containing following columns bin: bin: bin labels. count: Total count observations bin. pos: Count positive events bin. neg: Count negative events bin. woe: Weight Evidence (WoE) bin. iv: Information Value (IV) contribution bin. total_iv: Total Information Value (IV) across bins. cum_pos: Cumulative count positive events current bin. cum_neg: Cumulative count negative events current bin. pos_rate: Rate positive events within bin. neg_rate: Rate negative events within bin. pos_perc: Percentage positive events relative total positive events. neg_perc: Percentage negative events relative total negative events. count_perc: Percentage total observations bin. cum_count_perc: Cumulative percentage observations current bin. cum_pos_perc: Cumulative percentage positive events current bin. cum_neg_perc: Cumulative percentage negative events current bin. cum_pos_perc_total: Cumulative percentage positive events relative total observations. cum_neg_perc_total: Cumulative percentage negative events relative total observations. odds_pos: Odds positive events bin. odds_ratio: Odds ratio positive events compared total population. lift: Lift bin, calculated ratio positive rate bin overall positive rate. ks: Kolmogorov-Smirnov statistic, measuring difference cumulative positive negative percentages. gini_contribution: Contribution Gini coefficient bin. precision: Precision bin. recall: Recall current bin. f1_score: F1 score bin. log_likelihood: Log-likelihood bin. kl_divergence: Kullback-Leibler divergence bin. js_divergence: Jensen-Shannon divergence bin.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningGainsTable.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generates a Comprehensive Gains Table from Optimal Binning Results — OptimalBinningGainsTable","text":"function calculates various metrics bin: Weight Evidence (WoE): $$WoE_i = \\ln\\left(\\frac{P(X_i|Y=1)}{P(X_i|Y=0)}\\right)$$ Information Value (IV): $$IV_i = (P(X_i|Y=1) - P(X_i|Y=0)) \\times WoE_i$$ Kolmogorov-Smirnov (KS) statistic: $$KS_i = |F_1() - F_0()|$$ \\(F_1()\\) \\(F_0()\\) cumulative distribution functions positive negative classes. Odds Ratio: $$OR_i = \\frac{P(Y=1|X_i) / P(Y=0|X_i)}{P(Y=1) / P(Y=0)}$$ Lift: $$Lift_i = \\frac{P(Y=1|X_i)}{P(Y=1)}$$ Gini Contribution: $$Gini_i = P(X_i|Y=1) \\times F_0() - P(X_i|Y=0) \\times F_1()$$ Precision: $$Precision_i = \\frac{TP_i}{TP_i + FP_i}$$ Recall: $$Recall_i = \\frac{\\sum_{j=1}^TP_j}{\\sum_{j=1}^n TP_j}$$ F1 Score: $$F1_i = 2 \\times \\frac{Precision_i \\times Recall_i}{Precision_i + Recall_i}$$ Log-likelihood: $$LL_i = n_{1i} \\ln(p_i) + n_{0i} \\ln(1-p_i)$$ \\(n_{1i}\\) \\(n_{0i}\\) counts positive negative cases bin , \\(p_i\\) proportion positive cases bin . Kullback-Leibler (KL) Divergence: $$KL_i = p_i \\ln\\left(\\frac{p_i}{p}\\right) + (1-p_i) \\ln\\left(\\frac{1-p_i}{1-p}\\right)$$ \\(p_i\\) proportion positive cases bin \\(p\\) overall proportion positive cases. Jensen-Shannon (JS) Divergence: $$JS_i = \\frac{1}{2}KL(p_i || m) + \\frac{1}{2}KL(q_i || m)$$ \\(m = \\frac{1}{2}(p_i + p)\\), \\(p_i\\) proportion positive cases bin , \\(p\\) overall proportion positive cases.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningGainsTable.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generates a Comprehensive Gains Table from Optimal Binning Results — OptimalBinningGainsTable","text":"Siddiqi, N. (2006). Credit Risk Scorecards: Developing Implementing Intelligent Credit Scoring. John Wiley & Sons. Hand, D. J., & Till, R. J. (2001). Simple Generalisation Area ROC Curve Multiple Class Classification Problems. Machine Learning, 45(2), 171-186. Kullback, S., & Leibler, R. . (1951). Information Sufficiency. Annals Mathematical Statistics, 22(1), 79-86. Lin, J. (1991). Divergence measures based Shannon entropy. IEEE Transactions Information Theory, 37(1), 145-151.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningGainsTable.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generates a Comprehensive Gains Table from Optimal Binning Results — OptimalBinningGainsTable","text":"","code":"if (FALSE) { # \\dontrun{ binning_result <- OptimalBinning(target, feature) gains_table <- OptimalBinningGainsTable(binning_result) print(gains_table) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningGainsTableFeature.html","id":null,"dir":"Reference","previous_headings":"","what":"Generates a Comprehensive Gains Table from Weight of Evidence (WoE) and Target Feature Data — OptimalBinningGainsTableFeature","title":"Generates a Comprehensive Gains Table from Weight of Evidence (WoE) and Target Feature Data — OptimalBinningGainsTableFeature","text":"function takes numeric vector Weight Evidence (WoE) values corresponding binary target variable generate detailed gains table. table includes various metrics assess performance characteristics WoE bin.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningGainsTableFeature.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generates a Comprehensive Gains Table from Weight of Evidence (WoE) and Target Feature Data — OptimalBinningGainsTableFeature","text":"","code":"OptimalBinningGainsTableFeature(feature_woe, target)"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningGainsTableFeature.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generates a Comprehensive Gains Table from Weight of Evidence (WoE) and Target Feature Data — OptimalBinningGainsTableFeature","text":"feature_woe Numeric vector representing Weight Evidence (WoE) values observation. target Numeric vector representing binary target variable, 1 indicates positive event (e.g., default) 0 indicates negative event (e.g., non-default).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningGainsTableFeature.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generates a Comprehensive Gains Table from Weight of Evidence (WoE) and Target Feature Data — OptimalBinningGainsTableFeature","text":"data frame containing following columns unique WoE bin: bin: bin labels. count: Total count observations bin. pos: Count positive events bin. neg: Count negative events bin. woe: Weight Evidence (WoE) value bin. iv: Information Value (IV) contribution bin. total_iv: Total Information Value (IV) across bins. cum_pos: Cumulative count positive events current bin. cum_neg: Cumulative count negative events current bin. pos_rate: Rate positive events bin. neg_rate: Rate negative events bin. pos_perc: Percentage positive events relative total positive events. neg_perc: Percentage negative events relative total negative events. count_perc: Percentage total observations bin. cum_count_perc: Cumulative percentage observations current bin. cum_pos_perc: Cumulative percentage positive events current bin. cum_neg_perc: Cumulative percentage negative events current bin. cum_pos_perc_total: Cumulative percentage positive events relative total observations. cum_neg_perc_total: Cumulative percentage negative events relative total observations. odds_pos: Odds positive events bin. odds_ratio: Odds ratio positive events bin compared total population. lift: Lift bin, calculated ratio positive rate bin overall positive rate. ks: Kolmogorov-Smirnov statistic, measuring difference cumulative positive negative percentages. gini_contribution: Contribution Gini coefficient bin. precision: Precision bin. recall: Recall current bin. f1_score: F1 score bin. log_likelihood: Log-likelihood bin. kl_divergence: Kullback-Leibler divergence bin. js_divergence: Jensen-Shannon divergence bin.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningGainsTableFeature.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generates a Comprehensive Gains Table from Weight of Evidence (WoE) and Target Feature Data — OptimalBinningGainsTableFeature","text":"function performs following steps: Checks feature_woe target length. Verifies target contains binary values (0 1). Groups target values unique WoE values. Computes various metrics group, including counts, rates, percentages, statistical measures. Handles cases positive negative classes instances returning zero counts appropriate NA values derived metrics. function calculates following key metrics: Weight Evidence (WoE): $$WoE_i = \\ln\\left(\\frac{P(X_i|Y=1)}{P(X_i|Y=0)}\\right)$$ Information Value (IV): $$IV_i = (P(X_i|Y=1) - P(X_i|Y=0)) \\times WoE_i$$ Kolmogorov-Smirnov (KS) statistic: $$KS_i = |F_1() - F_0()|$$ \\(F_1()\\) \\(F_0()\\) cumulative distribution functions positive negative classes. Odds Ratio: $$OR_i = \\frac{P(Y=1|X_i) / P(Y=0|X_i)}{P(Y=1) / P(Y=0)}$$ Lift: $$Lift_i = \\frac{P(Y=1|X_i)}{P(Y=1)}$$ Gini Contribution: $$Gini_i = P(X_i|Y=1) \\times F_0() - P(X_i|Y=0) \\times F_1()$$ Precision: $$Precision_i = \\frac{TP_i}{TP_i + FP_i}$$ Recall: $$Recall_i = \\frac{\\sum_{j=1}^TP_j}{\\sum_{j=1}^n TP_j}$$ F1 Score: $$F1_i = 2 \\times \\frac{Precision_i \\times Recall_i}{Precision_i + Recall_i}$$ Log-likelihood: $$LL_i = n_{1i} \\ln(p_i) + n_{0i} \\ln(1-p_i)$$ \\(n_{1i}\\) \\(n_{0i}\\) counts positive negative cases bin , \\(p_i\\) proportion positive cases bin . Kullback-Leibler (KL) Divergence: $$KL_i = p_i \\ln\\left(\\frac{p_i}{p}\\right) + (1-p_i) \\ln\\left(\\frac{1-p_i}{1-p}\\right)$$ \\(p_i\\) proportion positive cases bin \\(p\\) overall proportion positive cases. Jensen-Shannon (JS) Divergence: $$JS_i = \\frac{1}{2}KL(p_i || m) + \\frac{1}{2}KL(q_i || m)$$ \\(m = \\frac{1}{2}(p_i + p)\\), \\(p_i\\) proportion positive cases bin , \\(p\\) overall proportion positive cases.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningGainsTableFeature.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generates a Comprehensive Gains Table from Weight of Evidence (WoE) and Target Feature Data — OptimalBinningGainsTableFeature","text":"Siddiqi, N. (2006). Credit Risk Scorecards: Developing Implementing Intelligent Credit Scoring. John Wiley & Sons. Hand, D. J., & Till, R. J. (2001). Simple Generalisation Area ROC Curve Multiple Class Classification Problems. Machine Learning, 45(2), 171-186. Kullback, S., & Leibler, R. . (1951). Information Sufficiency. Annals Mathematical Statistics, 22(1), 79-86. Lin, J. (1991). Divergence measures based Shannon entropy. IEEE Transactions Information Theory, 37(1), 145-151.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningGainsTableFeature.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generates a Comprehensive Gains Table from Weight of Evidence (WoE) and Target Feature Data — OptimalBinningGainsTableFeature","text":"","code":"if (FALSE) { # \\dontrun{ feature_woe <- c(-0.5, 0.2, 0.2, -0.5, 0.3) target <- c(1, 0, 1, 0, 1) gains_table <- OptimalBinningGainsTableFeature(feature_woe, target) print(gains_table) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningNumericalWoE.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning and Weight of Evidence Calculation for Numerical Variables — OptimalBinningNumericalWoE","title":"Optimal Binning and Weight of Evidence Calculation for Numerical Variables — OptimalBinningNumericalWoE","text":"Optimal Binning Weight Evidence Calculation Numerical Variables","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningNumericalWoE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning and Weight of Evidence Calculation for Numerical Variables — OptimalBinningNumericalWoE","text":"","code":"OptimalBinningNumericalWoE(   dt,   target,   features,   method,   min_bins,   max_bins,   control,   positive,   preprocessed_data )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningNumericalWoE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning and Weight of Evidence Calculation for Numerical Variables — OptimalBinningNumericalWoE","text":"dt data.table containing dataset. target name target variable. features Vector numeric feature names process. method binning method use. min_bins Minimum number bins. max_bins Maximum number bins. control list additional control parameters. positive Character string specifying category considered positive. preprocessed_data List preprocessed data feature.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningNumericalWoE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning and Weight of Evidence Calculation for Numerical Variables — OptimalBinningNumericalWoE","text":"list containing results, reports, woebins, bestmod, failed_features.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningSelectAlgorithm.html","id":null,"dir":"Reference","previous_headings":"","what":"Select Optimal Binning Algorithm — OptimalBinningSelectAlgorithm","title":"Select Optimal Binning Algorithm — OptimalBinningSelectAlgorithm","text":"function selects appropriate binning algorithm based method variable type.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningSelectAlgorithm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select Optimal Binning Algorithm — OptimalBinningSelectAlgorithm","text":"","code":"OptimalBinningSelectAlgorithm(feature, method, dt, min_bin, max_bin, control)"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningSelectAlgorithm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select Optimal Binning Algorithm — OptimalBinningSelectAlgorithm","text":"feature name feature bin. method binning method use. dt data.table containing dataset. min_bin Minimum number bins. max_bin Maximum number bins. control list additional control parameters.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningSelectAlgorithm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select Optimal Binning Algorithm — OptimalBinningSelectAlgorithm","text":"list containing selected algorithm, parameters, method name.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningSelectBestModel.html","id":null,"dir":"Reference","previous_headings":"","what":"Select Best Binning Model — OptimalBinningSelectBestModel","title":"Select Best Binning Model — OptimalBinningSelectBestModel","text":"Select Best Binning Model","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningSelectBestModel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select Best Binning Model — OptimalBinningSelectBestModel","text":"","code":"OptimalBinningSelectBestModel(   dt_binning,   target,   feature,   min_bins,   max_bins,   control,   allowed_methods )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningSelectBestModel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select Best Binning Model — OptimalBinningSelectBestModel","text":"dt_binning Data binning target Target variable name feature Feature variable name min_bins Minimum number bins max_bins Maximum number bins control Control parameters allowed_methods Vector allowed binning methods","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningSelectBestModel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select Best Binning Model — OptimalBinningSelectBestModel","text":"Best binning result","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningValidateInputs.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate Inputs for Optimal Binning — OptimalBinningValidateInputs","title":"Validate Inputs for Optimal Binning — OptimalBinningValidateInputs","text":"Validate Inputs Optimal Binning","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningValidateInputs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate Inputs for Optimal Binning — OptimalBinningValidateInputs","text":"","code":"OptimalBinningValidateInputs(   dt,   target,   features,   method,   preprocess,   min_bins,   max_bins,   control,   positive )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningValidateInputs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate Inputs for Optimal Binning — OptimalBinningValidateInputs","text":"dt data.table containing dataset. target name target variable. features Vector feature names process. method binning method use. preprocess Logical. Whether preprocess data binning. min_bins Minimum number bins. max_bins Maximum number bins. control list additional control parameters. positive Character string specifying category considered positive.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningValidateInputs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate Inputs for Optimal Binning — OptimalBinningValidateInputs","text":"None. Throws error input invalid.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/binning_categorical_cutpoints.html","id":null,"dir":"Reference","previous_headings":"","what":"Binning Categorical Variables using Custom Cutpoints — binning_categorical_cutpoints","title":"Binning Categorical Variables using Custom Cutpoints — binning_categorical_cutpoints","text":"function performs optimal binning categorical variables based predefined cutpoints, calculates Weight Evidence (WoE) Information Value (IV) bin, transforms feature accordingly.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/binning_categorical_cutpoints.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Binning Categorical Variables using Custom Cutpoints — binning_categorical_cutpoints","text":"","code":"binning_categorical_cutpoints(feature, target, cutpoints)"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/binning_categorical_cutpoints.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Binning Categorical Variables using Custom Cutpoints — binning_categorical_cutpoints","text":"feature character vector representing categorical feature binned. target integer vector representing binary target variable (0 1). cutpoints character vector containing bin definitions, categories separated '+' (e.g., \"+B+C\").","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/binning_categorical_cutpoints.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Binning Categorical Variables using Custom Cutpoints — binning_categorical_cutpoints","text":"list two elements: woefeature numeric vector representing transformed feature WoE values observation. woebin data frame containing detailed statistics bin, including counts, WoE, IV.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/binning_categorical_cutpoints.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Binning Categorical Variables using Custom Cutpoints — binning_categorical_cutpoints","text":"Binning preprocessing step groups categories categorical feature smaller number bins. function performs binning based user-defined cutpoints, cutpoint specifies group categories combined single bin. resulting bins evaluated using WoE IV metrics, often used predictive modeling, especially credit risk modeling. Weight Evidence (WoE) calculated : $$\\text{WoE} = \\log\\left(\\frac{\\text{Positive Rate}}{\\text{Negative Rate}}\\right)$$ Positive Rate proportion positive observations (target = 1) within bin, Negative Rate proportion negative observations (target = 0) within bin. Information Value (IV) measures predictive power categorical feature calculated : $$IV = \\sum (\\text{Positive Rate} - \\text{Negative Rate}) \\times \\text{WoE}$$ IV metric provides insight well binned feature predicts target variable: IV < 0.02: predictive 0.02 ≤ IV < 0.1: Weak predictive power 0.1 ≤ IV < 0.3: Medium predictive power IV ≥ 0.3: Strong predictive power WoE used transform categorical variable continuous numeric variable, can used directly logistic regression predictive models.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/binning_categorical_cutpoints.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Binning Categorical Variables using Custom Cutpoints — binning_categorical_cutpoints","text":"Siddiqi, N. (2006). Credit Risk Scorecards: Developing Implementing Intelligent Credit Scoring. John Wiley & Sons.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/binning_categorical_cutpoints.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Binning Categorical Variables using Custom Cutpoints — binning_categorical_cutpoints","text":"","code":"if (FALSE) { # \\dontrun{ # Example usage feature <- c(\"A\", \"B\", \"C\", \"A\", \"B\", \"C\", \"A\", \"C\", \"C\", \"B\") target <- c(1, 0, 1, 1, 0, 0, 0, 1, 1, 0) cutpoints <- c(\"A+B\", \"C\") result <- binning_categorical_cutpoints(feature, target, cutpoints) print(result$woefeature)  # WoE-transformed feature print(result$woebin)      # WoE and IV statistics for each bin } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/binning_numerical_cutpoints.html","id":null,"dir":"Reference","previous_headings":"","what":"Binning Numerical Variables using Custom Cutpoints — binning_numerical_cutpoints","title":"Binning Numerical Variables using Custom Cutpoints — binning_numerical_cutpoints","text":"function performs optimal binning numerical variable based predefined cutpoints, calculates Weight Evidence (WoE) Information Value (IV) bin, transforms feature accordingly.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/binning_numerical_cutpoints.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Binning Numerical Variables using Custom Cutpoints — binning_numerical_cutpoints","text":"","code":"binning_numerical_cutpoints(feature, target, cutpoints)"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/binning_numerical_cutpoints.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Binning Numerical Variables using Custom Cutpoints — binning_numerical_cutpoints","text":"feature numeric vector representing numerical feature binned. target integer vector representing binary target variable (0 1). cutpoints numeric vector containing cutpoints define bin boundaries.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/binning_numerical_cutpoints.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Binning Numerical Variables using Custom Cutpoints — binning_numerical_cutpoints","text":"list two elements: woefeature numeric vector representing transformed feature WoE values observation. woebin data frame containing detailed statistics bin, including counts, WoE, IV.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/binning_numerical_cutpoints.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Binning Numerical Variables using Custom Cutpoints — binning_numerical_cutpoints","text":"Binning preprocessing step groups continuous values numerical feature smaller number bins. function performs binning based user-defined cutpoints, allows define numerical feature split intervals. resulting bins evaluated using WoE IV metrics, often used predictive modeling, especially credit risk modeling. Weight Evidence (WoE) calculated : $$\\text{WoE} = \\log\\left(\\frac{\\text{Positive Rate}}{\\text{Negative Rate}}\\right)$$ Positive Rate proportion positive observations (target = 1) within bin, Negative Rate proportion negative observations (target = 0) within bin. Information Value (IV) measures predictive power numerical feature calculated : $$IV = \\sum (\\text{Positive Rate} - \\text{Negative Rate}) \\times \\text{WoE}$$ IV metric provides insight well binned feature predicts target variable: IV < 0.02: predictive 0.02 <= IV < 0.1: Weak predictive power 0.1 <= IV < 0.3: Medium predictive power IV >= 0.3: Strong predictive power WoE transformation helps convert numerical variable continuous numeric feature, can directly used logistic regression predictive models, improving model interpretability performance.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/binning_numerical_cutpoints.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Binning Numerical Variables using Custom Cutpoints — binning_numerical_cutpoints","text":"Siddiqi, N. (2006). Credit Risk Scorecards: Developing Implementing Intelligent Credit Scoring. John Wiley & Sons.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/binning_numerical_cutpoints.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Binning Numerical Variables using Custom Cutpoints — binning_numerical_cutpoints","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/binning_numerical_cutpoints.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Binning Numerical Variables using Custom Cutpoints — binning_numerical_cutpoints","text":"","code":"if (FALSE) { # \\dontrun{ # Example usage feature <- c(23, 45, 34, 25, 56, 48, 35, 29, 53, 41) target <- c(1, 0, 1, 1, 0, 0, 0, 1, 1, 0) cutpoints <- c(30, 40, 50) result <- binning_numerical_cutpoints(feature, target, cutpoints) print(result$woefeature)  # WoE-transformed feature print(result$woebin)      # WoE and IV statistics for each bin } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/configure_parallel_setup.html","id":null,"dir":"Reference","previous_headings":"","what":"Configure Parallel Processing for Package Installation — configure_parallel_setup","title":"Configure Parallel Processing for Package Installation — configure_parallel_setup","text":"function detects operating system sets environment parallel processing package installation. determines number cores use based system's capabilities sets appropriate compiler flags OpenMP support.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/configure_parallel_setup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Configure Parallel Processing for Package Installation — configure_parallel_setup","text":"","code":"configure_parallel_setup()"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/configure_parallel_setup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Configure Parallel Processing for Package Installation — configure_parallel_setup","text":"list following components: os Detected operating system (Windows, macOS, Linux) cores Number cores use parallel processing openmp_flags Compiler flags OpenMP support","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/configure_parallel_setup.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Configure Parallel Processing for Package Installation — configure_parallel_setup","text":"function performs following tasks: Detects operating system. Determines number available cores, using conservative approach. Sets appropriate compiler flags OpenMP based OS. macOS, checks OpenMP available provides alternative flags. function designed called silently package installation, typically within .onLoad() function package.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/configure_parallel_setup.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Configure Parallel Processing for Package Installation — configure_parallel_setup","text":"function conservative core allocation avoid system overload. uses 50% available cores systems 2 cores.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/configure_parallel_setup.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Configure Parallel Processing for Package Installation — configure_parallel_setup","text":"","code":"if (FALSE) { # \\dontrun{ parallel_setup <- configure_parallel_setup() print(parallel_setup) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/is_woe_monotonic.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if WoE values are monotonic — is_woe_monotonic","title":"Check if WoE values are monotonic — is_woe_monotonic","text":"Check WoE values monotonic","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/is_woe_monotonic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if WoE values are monotonic — is_woe_monotonic","text":"","code":"is_woe_monotonic(woe_values)"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/is_woe_monotonic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if WoE values are monotonic — is_woe_monotonic","text":"woe_values Vector WoE values","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/is_woe_monotonic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if WoE values are monotonic — is_woe_monotonic","text":"Logical indicating WoE values monotonic","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/mapTargetVariable.html","id":null,"dir":"Reference","previous_headings":"","what":"Map Target Variable — mapTargetVariable","title":"Map Target Variable — mapTargetVariable","text":"Map Target Variable","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/mapTargetVariable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Map Target Variable — mapTargetVariable","text":"","code":"mapTargetVariable(dt, target, positive)"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/mapTargetVariable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Map Target Variable — mapTargetVariable","text":"dt Data table target Target variable name positive Positive class indicator","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/mapTargetVariable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Map Target Variable — mapTargetVariable","text":"Updated data table mapped target variable","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/obwoe.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning and Weight of Evidence Calculation — obwoe","title":"Optimal Binning and Weight of Evidence Calculation — obwoe","text":"function performs optimal binning calculates Weight Evidence (WoE) numerical categorical features.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/obwoe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning and Weight of Evidence Calculation — obwoe","text":"","code":"obwoe(   dt,   target,   features = NULL,   method = \"auto\",   preprocess = TRUE,   min_bins = 3,   max_bins = 4,   control = list(),   positive = \"bad|1\" )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/obwoe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning and Weight of Evidence Calculation — obwoe","text":"dt data.table containing dataset. target name target variable (must binary). features Vector feature names process. NULL, features except target processed. method binning method use. Can \"auto\" specific method name. preprocess Logical. Whether preprocess data binning. min_bins Minimum number bins. max_bins Maximum number bins. control list additional control parameters. positive Character string specifying category considered positive. Must either \"bad|1\" \"good|1\".","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/obwoe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning and Weight of Evidence Calculation — obwoe","text":"list containing: woedt original dataset added WoE columns woebins Information bins created prepreport Preprocessing report feature bestsreport Report best models used failedfeatures List features failed processing bestmethod Best method used binning","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_cm.html","id":null,"dir":"Reference","previous_headings":"","what":"Categorical Optimal Binning with Chi-Merge — optimal_binning_categorical_cm","title":"Categorical Optimal Binning with Chi-Merge — optimal_binning_categorical_cm","text":"Implements optimal binning categorical variables using Chi-Merge algorithm, calculating Weight Evidence (WoE) Information Value (IV) resulting bins.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_cm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Categorical Optimal Binning with Chi-Merge — optimal_binning_categorical_cm","text":"","code":"optimal_binning_categorical_cm(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_cm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Categorical Optimal Binning with Chi-Merge — optimal_binning_categorical_cm","text":"target Integer vector binary target values (0 1). feature Character vector categorical feature values. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum frequency separate bin (default: 0.05). max_n_prebins Maximum number pre-bins merging (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_cm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Categorical Optimal Binning with Chi-Merge — optimal_binning_categorical_cm","text":"list two elements: woefeature: Numeric vector WoE values input feature value. woebin: Data frame binning results (bin names, WoE, IV, counts).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_cm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Categorical Optimal Binning with Chi-Merge — optimal_binning_categorical_cm","text":"Chi-Merge algorithm uses chi-square statistics merge adjacent bins: $$\\chi^2 = \\sum_{=1}^{2}\\sum_{j=1}^{2} \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}$$ \\(O_{ij}\\) observed frequency \\(E_{ij}\\) expected frequency bin class j. Weight Evidence (WoE) bin: $$WoE = \\ln(\\frac{P(X|Y=1)}{P(X|Y=0)})$$ Information Value (IV) bin: $$IV = (P(X|Y=1) - P(X|Y=0)) * WoE$$ algorithm initializes bins category, merges rare categories based bin_cutoff, iteratively merges bins lowest chi-square statistic reaching max_bins. enforces WoE monotonicity handles edge cases like zero frequencies using small constant values.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_cm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Categorical Optimal Binning with Chi-Merge — optimal_binning_categorical_cm","text":"Kerber, R. (1992). ChiMerge: Discretization numeric attributes. Proceedings tenth national conference Artificial intelligence (pp. 123-128). AAAI Press. Beltrami, M., Mach, M., & Dall'Aglio, M. (2021). Monotonic Optimal Binning Algorithm Credit Risk Modeling. Risks, 9(3), 58.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_cm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Categorical Optimal Binning with Chi-Merge — optimal_binning_categorical_cm","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_cm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Categorical Optimal Binning with Chi-Merge — optimal_binning_categorical_cm","text":"","code":"if (FALSE) { # \\dontrun{ # Sample data target <- c(1, 0, 1, 1, 0, 1, 0, 0, 1, 1) feature <- c(\"A\", \"B\", \"A\", \"C\", \"B\", \"D\", \"C\", \"A\", \"D\", \"B\")  # Run optimal binning result <- optimal_binning_categorical_cm(target, feature, min_bins = 2, max_bins = 4)  # View results print(result$woebin) print(result$woefeature) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_dplc.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Categorical Variables using Dynamic Programming with Linear Constraints — optimal_binning_categorical_dplc","title":"Optimal Binning for Categorical Variables using Dynamic Programming with Linear Constraints — optimal_binning_categorical_dplc","text":"function performs optimal binning categorical variables using dynamic programming approach linear constraints. aims find optimal grouping categories maximizes Information Value (IV) respecting user-defined constraints number bins.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_dplc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Categorical Variables using Dynamic Programming with Linear Constraints — optimal_binning_categorical_dplc","text":"","code":"optimal_binning_categorical_dplc(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_dplc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Categorical Variables using Dynamic Programming with Linear Constraints — optimal_binning_categorical_dplc","text":"target integer vector binary target values (0 1). feature character vector categorical feature values. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum proportion total observations bin (default: 0.05). max_n_prebins Maximum number pre-bins merging (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_dplc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Categorical Variables using Dynamic Programming with Linear Constraints — optimal_binning_categorical_dplc","text":"list containing two elements: woefeature: numeric vector Weight Evidence (WOE) values observation. woebin: data frame containing binning information, including bin names, WOE, IV, counts.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_dplc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Categorical Variables using Dynamic Programming with Linear Constraints — optimal_binning_categorical_dplc","text":"algorithm uses dynamic programming find optimal binning solution maximizes total Information Value (IV) respecting constraints number bins. follows main steps: Preprocess data counting occurrences merging rare categories. Sort categories based event rates. Use dynamic programming find optimal binning solution. Backtrack determine final bin edges. Calculate WOE IV bin. dynamic programming approach uses recurrence relation find maximum total IV achievable given number categories bins. Weight Evidence (WOE) bin calculated : $$WOE = \\ln\\left(\\frac{\\text{Distribution Good}}{\\text{Distribution Bad}}\\right)$$ Information Value (IV) bin : $$IV = (\\text{Distribution Good} - \\text{Distribution Bad}) \\times WOE$$ algorithm aims find binning solution maximizes total IV respecting constraints number bins.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_dplc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Categorical Variables using Dynamic Programming with Linear Constraints — optimal_binning_categorical_dplc","text":"Belotti, P., Bonami, P., Fischetti, M., Lodi, ., Monaci, M., Nogales-Gómez, ., & Salvagnin, D. (2016). handling indicator constraints mixed integer programming. Computational Optimization Applications, 65(3), 545-566. Mironchyk, P., & Tchistiakov, V. (2017). Monotone optimal binning algorithm credit risk modeling. SSRN Electronic Journal.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_dplc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Categorical Variables using Dynamic Programming with Linear Constraints — optimal_binning_categorical_dplc","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_dplc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Categorical Variables using Dynamic Programming with Linear Constraints — optimal_binning_categorical_dplc","text":"","code":"if (FALSE) { # \\dontrun{ # Create sample data set.seed(123) n <- 1000 target <- sample(0:1, n, replace = TRUE) feature <- sample(c(\"A\", \"B\", \"C\", \"D\", \"E\"), n, replace = TRUE)  # Perform optimal binning result <- optimal_binning_categorical_dplc(target, feature, min_bins = 2, max_bins = 4)  # View results print(result$woebin) hist(result$woefeature) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_fetb.html","id":null,"dir":"Reference","previous_headings":"","what":"Categorical Optimal Binning with Fisher's Exact Test — optimal_binning_categorical_fetb","title":"Categorical Optimal Binning with Fisher's Exact Test — optimal_binning_categorical_fetb","text":"Implements optimal binning categorical variables using Fisher's Exact Test, calculating Weight Evidence (WoE) Information Value (IV).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_fetb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Categorical Optimal Binning with Fisher's Exact Test — optimal_binning_categorical_fetb","text":"","code":"optimal_binning_categorical_fetb(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_fetb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Categorical Optimal Binning with Fisher's Exact Test — optimal_binning_categorical_fetb","text":"target Integer vector binary target values (0 1). feature Character vector categorical feature values. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum frequency separate bin (default: 0.05). max_n_prebins Maximum number pre-bins merging (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_fetb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Categorical Optimal Binning with Fisher's Exact Test — optimal_binning_categorical_fetb","text":"list two elements: woefeature: Numeric vector WoE values input feature value. woebin: Data frame binning results (bin names, WoE, IV, counts).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_fetb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Categorical Optimal Binning with Fisher's Exact Test — optimal_binning_categorical_fetb","text":"algorithm uses Fisher's Exact Test iteratively merge bins, maximizing statistical significance difference adjacent bins. Weight Evidence (WoE) bin calculated : $$WoE = \\ln\\left(\\frac{P(X|Y=1)}{P(X|Y=0)}\\right)$$ Information Value (IV) bin calculated : $$IV = (P(X|Y=1) - P(X|Y=0)) \\times WoE$$ Fisher's Exact Test p-value calculated using hypergeometric distribution: $$p = \\frac{{+b \\choose }{c+d \\choose c}}{{n \\choose +c}}$$ , b, c, d elements 2x2 contingency table, n total sample size. algorithm first merges rare categories based bin_cutoff, iteratively merges bins lowest p-value Fisher's Exact Test desired number bins reached merging statistically significant.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_fetb.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Categorical Optimal Binning with Fisher's Exact Test — optimal_binning_categorical_fetb","text":"Agresti, . (1992). Survey Exact Inference Contingency Tables. Statistical Science, 7(1), 131-153. Savage, L. J. (1956). Choice Classification Statistic. Contributions Probability Statistics: Essays Honor Harold Hotelling, Stanford University Press, 139-161.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_fetb.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Categorical Optimal Binning with Fisher's Exact Test — optimal_binning_categorical_fetb","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_fetb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Categorical Optimal Binning with Fisher's Exact Test — optimal_binning_categorical_fetb","text":"","code":"if (FALSE) { # \\dontrun{ # Sample data target <- c(1, 0, 1, 1, 0, 1, 0, 0, 1, 1) feature <- c(\"A\", \"B\", \"A\", \"C\", \"B\", \"D\", \"C\", \"A\", \"D\", \"B\")  # Run optimal binning result <- optimal_binning_categorical_fetb(target, feature, min_bins = 2, max_bins = 4)  # View results print(result$woebin) print(result$woefeature) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_gab.html","id":null,"dir":"Reference","previous_headings":"","what":"Categorical Optimal Binning with Genetic Algorithm — optimal_binning_categorical_gab","title":"Categorical Optimal Binning with Genetic Algorithm — optimal_binning_categorical_gab","text":"Implements optimal binning categorical variables using Genetic Algorithm approach, calculating Weight Evidence (WoE) Information Value (IV).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_gab.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Categorical Optimal Binning with Genetic Algorithm — optimal_binning_categorical_gab","text":"","code":"optimal_binning_categorical_gab(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   population_size = 100L,   num_generations = 100L,   mutation_rate = 0.1,   crossover_rate = 0.8,   time_limit_seconds = 300L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_gab.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Categorical Optimal Binning with Genetic Algorithm — optimal_binning_categorical_gab","text":"target Integer vector binary target values (0 1). feature Character vector categorical feature values. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum frequency separate bin (default: 0.05). max_n_prebins Maximum number pre-bins merging (default: 20). population_size Size genetic algorithm population (default: 100). num_generations Number generations genetic algorithm (default: 100). mutation_rate Probability mutation bin (default: 0.1). crossover_rate Probability crossover parents (default: 0.8). time_limit_seconds Maximum execution time seconds (default: 300).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_gab.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Categorical Optimal Binning with Genetic Algorithm — optimal_binning_categorical_gab","text":"list two elements: woefeature: Numeric vector WoE values input feature value. woebin: Data frame binning results (bin names, WoE, IV, counts).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_gab.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Categorical Optimal Binning with Genetic Algorithm — optimal_binning_categorical_gab","text":"algorithm uses genetic algorithm approach find optimal binning solution. evolves population binning solutions multiple generations, using selection, crossover, mutation operations. Weight Evidence (WoE) bin calculated : $$WoE = \\ln\\left(\\frac{P(X|Y=1)}{P(X|Y=0)}\\right)$$ Information Value (IV) bin calculated : $$IV = (P(X|Y=1) - P(X|Y=0)) \\times WoE$$ fitness individual (binning solution) sum IVs across bins. algorithm aims maximize fitness respecting constraints number bins ensuring monotonicity WoE values across bins. genetic algorithm includes following key steps: Initialize population random binning solutions. Evaluate fitness individual. Select parents based fitness (using roulette wheel selection). Create offspring crossover mutation. Ensure offspring respect constraints (number bins, monotonicity). Replace population offspring. Repeat steps 2-6 specified number generations time limit reached.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_gab.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Categorical Optimal Binning with Genetic Algorithm — optimal_binning_categorical_gab","text":"Holland, J. H. (1992). Adaptation natural artificial systems: introductory analysis applications biology, control, artificial intelligence. MIT press. Whitley, D. (1994). genetic algorithm tutorial. Statistics computing, 4(2), 65-85.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_gab.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Categorical Optimal Binning with Genetic Algorithm — optimal_binning_categorical_gab","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_gab.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Categorical Optimal Binning with Genetic Algorithm — optimal_binning_categorical_gab","text":"","code":"if (FALSE) { # \\dontrun{ # Sample data target <- c(1, 0, 1, 1, 0, 1, 0, 0, 1, 1) feature <- c(\"A\", \"B\", \"A\", \"C\", \"B\", \"D\", \"C\", \"A\", \"D\", \"B\")  # Run optimal binning result <- optimal_binning_categorical_gab(target, feature, min_bins = 2, max_bins = 4)  # View results print(result$woebin) print(result$woefeature) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_gmb.html","id":null,"dir":"Reference","previous_headings":"","what":"Categorical Optimal Binning with Greedy Merge Binning — optimal_binning_categorical_gmb","title":"Categorical Optimal Binning with Greedy Merge Binning — optimal_binning_categorical_gmb","text":"Implements optimal binning categorical variables using Greedy Merge approach, calculating Weight Evidence (WoE) Information Value (IV).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_gmb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Categorical Optimal Binning with Greedy Merge Binning — optimal_binning_categorical_gmb","text":"","code":"optimal_binning_categorical_gmb(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_gmb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Categorical Optimal Binning with Greedy Merge Binning — optimal_binning_categorical_gmb","text":"target Integer vector binary target values (0 1). feature Character vector categorical feature values. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum frequency separate bin (default: 0.05). max_n_prebins Maximum number pre-bins merging (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_gmb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Categorical Optimal Binning with Greedy Merge Binning — optimal_binning_categorical_gmb","text":"list two elements: woefeature: Numeric vector WoE values input feature value. woebin: Data frame binning results (bin names, WoE, IV, counts).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_gmb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Categorical Optimal Binning with Greedy Merge Binning — optimal_binning_categorical_gmb","text":"algorithm uses greedy merge approach find optimal binning solution. starts unique category separate bin iteratively merges bins maximize overall Information Value (IV) respecting constraints number bins. Weight Evidence (WoE) bin calculated : $$WoE = \\ln\\left(\\frac{P(X|Y=1)}{P(X|Y=0)}\\right)$$ Information Value (IV) bin calculated : $$IV = (P(X|Y=1) - P(X|Y=0)) \\times WoE$$ algorithm includes following key steps: Initialize bins unique category. Merge rare categories based bin_cutoff. Iteratively merge adjacent bins result highest IV. Stop merging number bins reaches min_bins max_bins. Calculate final WoE IV bin. algorithm handles zero counts using small constant (epsilon) avoid undefined logarithms division zero.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_gmb.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Categorical Optimal Binning with Greedy Merge Binning — optimal_binning_categorical_gmb","text":"Beltrami, M., Mach, M., & Dall'Aglio, M. (2021). Monotonic Optimal Binning Algorithm Credit Risk Modeling. Risks, 9(3), 58. Siddiqi, N. (2006). Credit risk scorecards: developing implementing intelligent credit scoring (Vol. 3). John Wiley & Sons.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_gmb.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Categorical Optimal Binning with Greedy Merge Binning — optimal_binning_categorical_gmb","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_gmb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Categorical Optimal Binning with Greedy Merge Binning — optimal_binning_categorical_gmb","text":"","code":"if (FALSE) { # \\dontrun{ # Sample data target <- c(1, 0, 1, 1, 0, 1, 0, 0, 1, 1) feature <- c(\"A\", \"B\", \"A\", \"C\", \"B\", \"D\", \"C\", \"A\", \"D\", \"B\")  # Run optimal binning result <- optimal_binning_categorical_gmb(target, feature, min_bins = 2, max_bins = 4)  # View results print(result$woebin) print(result$woefeature) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_ivb.html","id":null,"dir":"Reference","previous_headings":"","what":"Categorical Optimal Binning with Information Value Binning — optimal_binning_categorical_ivb","title":"Categorical Optimal Binning with Information Value Binning — optimal_binning_categorical_ivb","text":"Implements optimal binning categorical variables using Information Value (IV) primary criterion, calculating Weight Evidence (WoE) IV resulting bins.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_ivb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Categorical Optimal Binning with Information Value Binning — optimal_binning_categorical_ivb","text":"","code":"optimal_binning_categorical_ivb(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_ivb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Categorical Optimal Binning with Information Value Binning — optimal_binning_categorical_ivb","text":"target Integer vector binary target values (0 1). feature Character vector factor categorical feature values. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum frequency separate bin (default: 0.05). max_n_prebins Maximum number pre-bins merging (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_ivb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Categorical Optimal Binning with Information Value Binning — optimal_binning_categorical_ivb","text":"list two elements: woefeature: Numeric vector WoE values input feature value. woebin: Data frame binning results (bin names, WoE, IV).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_ivb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Categorical Optimal Binning with Information Value Binning — optimal_binning_categorical_ivb","text":"algorithm uses Information Value (IV) create optimal bins categorical variables. starts computing statistics category, sorts categories event rate ensure monotonicity. algorithm creates initial bins based specified constraints computes WoE IV bin. Weight Evidence (WoE) bin calculated : $$WoE = \\ln\\left(\\frac{P(X|Y=1)}{P(X|Y=0)}\\right)$$ Information Value (IV) bin calculated : $$IV = (P(X|Y=1) - P(X|Y=0)) \\times WoE$$ algorithm includes following key steps: Compute category statistics (counts, positive counts, negative counts). Sort categories event rate ensure monotonicity. Create initial bins based sorted categories specified constraints. Compute WoE IV bin. Assign WoE values original feature, handling unseen categories.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_ivb.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Categorical Optimal Binning with Information Value Binning — optimal_binning_categorical_ivb","text":"Siddiqi, N. (2006). Credit risk scorecards: developing implementing intelligent credit scoring. John Wiley & Sons. Thomas, L. C. (2009). Consumer credit models: Pricing, profit portfolios. OUP Oxford.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_ivb.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Categorical Optimal Binning with Information Value Binning — optimal_binning_categorical_ivb","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_ivb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Categorical Optimal Binning with Information Value Binning — optimal_binning_categorical_ivb","text":"","code":"if (FALSE) { # \\dontrun{ # Sample data target <- c(1, 0, 1, 1, 0, 1, 0, 0, 1, 1) feature <- c(\"A\", \"B\", \"A\", \"C\", \"B\", \"D\", \"C\", \"A\", \"D\", \"B\")  # Run optimal binning result <- optimal_binning_categorical_ivb(target, feature, min_bins = 2, max_bins = 4)  # View results print(result$woebin) print(result$woefeature) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_ldb.html","id":null,"dir":"Reference","previous_headings":"","what":"Categorical Optimal Binning with Local Distance-Based Algorithm — optimal_binning_categorical_ldb","title":"Categorical Optimal Binning with Local Distance-Based Algorithm — optimal_binning_categorical_ldb","text":"function performs optimal binning categorical variables using Local Distance-Based (LDB) algorithm, merges categories based Weight Evidence (WoE) similarity Information Value (IV) loss.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_ldb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Categorical Optimal Binning with Local Distance-Based Algorithm — optimal_binning_categorical_ldb","text":"","code":"optimal_binning_categorical_ldb(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_ldb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Categorical Optimal Binning with Local Distance-Based Algorithm — optimal_binning_categorical_ldb","text":"target integer vector binary target values (0 1). feature character vector categorical feature values. min_bins Minimum number bins create (default: 3). max_bins Maximum number bins create (default: 5). bin_cutoff Minimum frequency category considered separate bin (default: 0.05). max_n_prebins Maximum number pre-bins merging (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_ldb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Categorical Optimal Binning with Local Distance-Based Algorithm — optimal_binning_categorical_ldb","text":"list containing two elements: woefeature: numeric vector WoE values input feature value. woebin: data frame binning results, including bin names, WoE, IV, counts.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_ldb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Categorical Optimal Binning with Local Distance-Based Algorithm — optimal_binning_categorical_ldb","text":"LDB algorithm works follows: Compute initial statistics category. Handle rare categories merging similar (terms WoE) non-rare category. Limit number pre-bins max_n_prebins. Iteratively merge bins lowest IV loss desired number bins reached monotonicity achieved. Ensure monotonicity WoE across bins. Weight Evidence (WoE) bin calculated : $$WoE = \\ln\\left(\\frac{P(X|Y=1)}{P(X|Y=0)}\\right)$$ Information Value (IV) bin calculated : $$IV = (P(X|Y=1) - P(X|Y=0)) \\times WoE$$","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_ldb.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Categorical Optimal Binning with Local Distance-Based Algorithm — optimal_binning_categorical_ldb","text":"Beltrami, M., Mach, M., & Dall'Aglio, M. (2021). Monotonic Optimal Binning Algorithm Credit Risk Modeling. Risks, 9(3), 58. Zeng, G. (2014). necessary condition good binning algorithm credit scoring. Applied Mathematical Sciences, 8(65), 3229-3242.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_ldb.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Categorical Optimal Binning with Local Distance-Based Algorithm — optimal_binning_categorical_ldb","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_ldb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Categorical Optimal Binning with Local Distance-Based Algorithm — optimal_binning_categorical_ldb","text":"","code":"if (FALSE) { # \\dontrun{ # Sample data target <- c(1, 0, 1, 1, 0, 1, 0, 0, 1, 1) feature <- c(\"A\", \"B\", \"A\", \"C\", \"B\", \"D\", \"C\", \"A\", \"D\", \"B\")  # Run optimal binning result <- optimal_binning_categorical_ldb(target, feature, min_bins = 2, max_bins = 4)  # View results print(result$woebin) print(result$woefeature) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mba.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Categorical Variables using Monotonic Binning Algorithm (MBA) — optimal_binning_categorical_mba","title":"Optimal Binning for Categorical Variables using Monotonic Binning Algorithm (MBA) — optimal_binning_categorical_mba","text":"function performs optimal binning categorical variables using Monotonic Binning Algorithm (MBA) approach, combines Weight Evidence (WOE) Information Value (IV) methods monotonicity constraints.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mba.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Categorical Variables using Monotonic Binning Algorithm (MBA) — optimal_binning_categorical_mba","text":"","code":"optimal_binning_categorical_mba(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mba.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Categorical Variables using Monotonic Binning Algorithm (MBA) — optimal_binning_categorical_mba","text":"target integer vector binary target values (0 1). feature character vector categorical feature values. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum frequency category considered separate bin (default: 0.05). max_n_prebins Maximum number pre-bins merging (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mba.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Categorical Variables using Monotonic Binning Algorithm (MBA) — optimal_binning_categorical_mba","text":"list containing three elements: woefeature: numeric vector WOE values input feature value woebin: data frame containing bin information, including bin labels, WOE, IV, counts total_iv: total Information Value binning","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mba.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Categorical Variables using Monotonic Binning Algorithm (MBA) — optimal_binning_categorical_mba","text":"algorithm performs following steps: Input validation preprocessing Initial pre-binning based frequency Enforcing minimum bin size (bin_cutoff) Calculating initial Weight Evidence (WOE) Information Value (IV) Enforcing monotonicity WOE across bins Optimizing number bins iterative merging Assigning final WOE values category Weight Evidence (WOE) calculated : $$WOE = \\ln\\left(\\frac{\\text{Proportion Events}}{\\text{Proportion Non-Events}}\\right)$$ Information Value (IV) bin calculated : $$IV = (\\text{Proportion Events} - \\text{Proportion Non-Events}) \\times WOE$$ total IV sum IVs across bins.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mba.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Categorical Variables using Monotonic Binning Algorithm (MBA) — optimal_binning_categorical_mba","text":"Belaid, ., & Ghorbel, H. (2018). Optimal Binning Technique Credit Scoring. Advances Time Series Forecasting (pp. 217-228). Springer, Cham. Mironchyk, P., & Tchistiakov, V. (2017). Monotone optimal binning algorithm credit risk modeling. arXiv preprint arXiv:1711.05095.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mba.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Categorical Variables using Monotonic Binning Algorithm (MBA) — optimal_binning_categorical_mba","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mba.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Categorical Variables using Monotonic Binning Algorithm (MBA) — optimal_binning_categorical_mba","text":"","code":"if (FALSE) { # \\dontrun{ # Create sample data set.seed(123) target <- sample(0:1, 1000, replace = TRUE) feature <- sample(LETTERS[1:5], 1000, replace = TRUE)  # Run optimal binning result <- optimal_binning_categorical_mba(target, feature)  # View results print(result$woebin) print(paste(\"Total IV:\", result$total_iv)) hist(result$woefeature) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mblp.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Categorical Variables using Minimum Binning Loss Principle (MBLP) — optimal_binning_categorical_mblp","title":"Optimal Binning for Categorical Variables using Minimum Binning Loss Principle (MBLP) — optimal_binning_categorical_mblp","text":"function performs optimal binning categorical variables using Minimum Binning Loss Principle (MBLP). creates optimal bins categorical feature based relationship binary target variable, maximizing predictive power respecting user-defined constraints.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mblp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Categorical Variables using Minimum Binning Loss Principle (MBLP) — optimal_binning_categorical_mblp","text":"","code":"optimal_binning_categorical_mblp(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mblp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Categorical Variables using Minimum Binning Loss Principle (MBLP) — optimal_binning_categorical_mblp","text":"target integer vector binary target values (0 1). feature character vector categorical feature values. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum proportion total observations category avoid grouped \"Rare\" category (default: 0.05). max_n_prebins Maximum number pre-bins optimization process (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mblp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Categorical Variables using Minimum Binning Loss Principle (MBLP) — optimal_binning_categorical_mblp","text":"list containing two elements: woefeature: numeric vector Weight Evidence (WoE) values observation. woebin: data frame following columns: bin: Character vector bin names (categories groups categories). woe: Numeric vector WoE values bin. iv: Numeric vector Information Value (IV) bin. count: Integer vector total observations bin. count_pos: Integer vector positive target observations bin. count_neg: Integer vector negative target observations bin.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mblp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Categorical Variables using Minimum Binning Loss Principle (MBLP) — optimal_binning_categorical_mblp","text":"Optimal Binning algorithm using Minimum Binning Loss Principle (MBLP) designed create optimal bins categorical variables relation binary target variable. algorithm works follows: Preprocess data: Calculate frequency positive/negative counts category. Merge rare categories (proportion less bin_cutoff) single \"Rare\" category. Calculate Weight Evidence (WoE) category: $$WoE = \\ln(\\frac{\\text{Positive Rate}}{\\text{Negative Rate}}) = \\ln(\\frac{\\frac{n_{}^{+}}{N^{+}}}{\\frac{n_{}^{-}}{N^{-}}})$$ \\(n_{}^{+}\\) \\(n_{}^{-}\\) number positive negative samples category \\(\\), \\(N^{+}\\) \\(N^{-}\\) total number positive negative samples. Sort categories WoE values. Initialize bins individual categories. Merge adjacent bins respecting following constraints: number bins min_bins max_bins. Bins merged minimize loss Information Value (IV). Calculate Information Value (IV) bin: $$IV = (\\text{Positive Rate} - \\text{Negative Rate}) \\times WoE$$ algorithm aims create bins maximize predictive power categorical variable adhering specified constraints. uses Minimum Binning Loss Principle determine optimal merging adjacent bins, ensuring loss information minimized binning process. implementation uses OpenMP parallel processing available, can significantly speed computation large datasets.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mblp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Categorical Variables using Minimum Binning Loss Principle (MBLP) — optimal_binning_categorical_mblp","text":"Mironchyk, P., Tchistiakov, V. (2017). Monotone optimal binning algorithm credit risk modeling. SSRN Electronic Journal. DOI: 10.2139/ssrn.2978774 Zhu, H., Liu, Y., Zhu, X., Lu, J. (2019). Minimum loss principle application credit scoring. Journal Risk Model Validation, 13(1), 57-85.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mblp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Categorical Variables using Minimum Binning Loss Principle (MBLP) — optimal_binning_categorical_mblp","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mblp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Categorical Variables using Minimum Binning Loss Principle (MBLP) — optimal_binning_categorical_mblp","text":"","code":"if (FALSE) { # \\dontrun{ # Create sample data set.seed(123) n <- 1000 target <- sample(0:1, n, replace = TRUE) feature <- sample(LETTERS[1:5], n, replace = TRUE) # Run optimal binning result <- optimal_binning_categorical_mblp(target, feature, min_bins = 2, max_bins = 4) # Print results print(result$woebin) # Plot WoE values barplot(result$woebin$woe, names.arg = result$woebin$bin,         main = \"Weight of Evidence by Bin\", xlab = \"Bins\", ylab = \"WoE\") } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_milp.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Categorical Variables using MILP — optimal_binning_categorical_milp","title":"Optimal Binning for Categorical Variables using MILP — optimal_binning_categorical_milp","text":"function performs optimal binning categorical variables using Mixed Integer Linear Programming (MILP) inspired approach. creates optimal bins categorical feature based relationship binary target variable, maximizing predictive power respecting user-defined constraints.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_milp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Categorical Variables using MILP — optimal_binning_categorical_milp","text":"","code":"optimal_binning_categorical_milp(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_milp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Categorical Variables using MILP — optimal_binning_categorical_milp","text":"target integer vector binary target values (0 1). feature character vector feature values. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum proportion total observations bin avoid merged (default: 0.05). max_n_prebins Maximum number pre-bins optimization process (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_milp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Categorical Variables using MILP — optimal_binning_categorical_milp","text":"list containing two elements: woefeature numeric vector Weight Evidence (WoE) values observation. woebin data frame following columns: bin: Character vector bin categories. woe: Numeric vector WoE values bin. iv: Numeric vector Information Value (IV) bin. count: Integer vector total observations bin. count_pos: Integer vector positive target observations bin. count_neg: Integer vector negative target observations bin.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_milp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Categorical Variables using MILP — optimal_binning_categorical_milp","text":"Optimal Binning algorithm categorical variables using MILP-inspired approach works follows: Create initial bins unique category. Merge bins counts cutoff. Calculate initial Weight Evidence (WoE) Information Value (IV) bin. Optimize bins merging categories maximize total IV respecting constraints. Ensure number bins min_bins max_bins. Recalculate WoE IV final bins. algorithm aims create bins maximize predictive power categorical variable adhering specified constraints. Weight Evidence (WoE) calculated : $$WoE = \\ln(\\frac{\\text{Positive Rate}}{\\text{Negative Rate}})$$ Information Value (IV) calculated : $$IV = (\\text{Positive Rate} - \\text{Negative Rate}) \\times WoE$$","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_milp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Categorical Variables using MILP — optimal_binning_categorical_milp","text":"Belotti, P., Kirches, C., Leyffer, S., Linderoth, J., Luedtke, J., & Mahajan, . (2013). Mixed-integer nonlinear optimization. Acta Numerica, 22, 1-131. Mironchyk, P., & Tchistiakov, V. (2017). Monotone optimal binning algorithm credit risk modeling. SSRN Electronic Journal. doi:10.2139/ssrn.2978774","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_milp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Categorical Variables using MILP — optimal_binning_categorical_milp","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_milp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Categorical Variables using MILP — optimal_binning_categorical_milp","text":"","code":"if (FALSE) { # \\dontrun{ # Create sample data set.seed(123) n <- 1000 target <- sample(0:1, n, replace = TRUE) feature <- sample(LETTERS[1:10], n, replace = TRUE)  # Run optimal binning result <- optimal_binning_categorical_milp(target, feature, min_bins = 2, max_bins = 4)  # Print results print(result$woebin)  # Plot WoE values barplot(result$woebin$woe, names.arg = result$woebin$bin,         xlab = \"Bins\", ylab = \"WoE\", main = \"Weight of Evidence by Bin\") } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mob.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Categorical Variables using Monotonic Optimal Binning (MOB) — optimal_binning_categorical_mob","title":"Optimal Binning for Categorical Variables using Monotonic Optimal Binning (MOB) — optimal_binning_categorical_mob","text":"function performs optimal binning categorical variables using Monotonic Optimal Binning (MOB) approach.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mob.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Categorical Variables using Monotonic Optimal Binning (MOB) — optimal_binning_categorical_mob","text":"","code":"optimal_binning_categorical_mob(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mob.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Categorical Variables using Monotonic Optimal Binning (MOB) — optimal_binning_categorical_mob","text":"target integer vector binary target values (0 1). feature character vector categorical feature values. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum proportion observations bin (default: 0.05). max_n_prebins Maximum number pre-bins (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mob.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Categorical Variables using Monotonic Optimal Binning (MOB) — optimal_binning_categorical_mob","text":"list containing two elements: woefeature: numeric vector Weight Evidence (WoE) values observation woebin: data frame containing binning information, including bin names, WoE, Information Value (IV), counts","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mob.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Categorical Variables using Monotonic Optimal Binning (MOB) — optimal_binning_categorical_mob","text":"algorithm performs optimal binning categorical variables using Monotonic Optimal Binning (MOB) approach. process aims maximize Information Value (IV) maintaining monotonicity Weight Evidence (WoE) across bins. algorithm works follows: Category Statistics Calculation: category , calculate: ni: total count ni+: count positive instances (target = 1) ni-: count negative instances (target = 0) Rare Categories Merging: Categories frequency bin_cutoff threshold merged \"\" category. Let tau bin_cutoff, N total number observations. category merged : ni < tau * N Initial Binning: Categories sorted based initial Weight Evidence (WoE): WoE_i = ln((ni+ / N+) / (ni- / N-)) N+ N- total counts positive negative instances respectively. Monotonicity Enforcement: algorithm enforces decreasing monotonicity WoE across bins. two adjacent bins j, < j: WoE_i >= WoE_j condition violated, bins j merged. Bin Limiting: number bins limited specified max_bins. merging necessary, algorithm chooses two adjacent bins smallest WoE difference. Information Value (IV) Computation: bin , IV calculated : IV_i = (P(X=|Y=1) - P(X=|Y=0)) * WoE_i total IV sum IVs across bins: IV_total = sum(IV_i) MOB approach ensures resulting bins monotonic WoE values, often desirable credit scoring risk modeling applications. monotonicity property ensures relationship binned variable target variable (e.g., default probability) consistent interpretable.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mob.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Categorical Variables using Monotonic Optimal Binning (MOB) — optimal_binning_categorical_mob","text":"Belotti, T., Crook, J. (2009). Credit Scoring Macroeconomic Variables Using Survival Analysis. Journal Operational Research Society, 60(12), 1699-1707. Mironchyk, P., Tchistiakov, V. (2017). Monotone optimal binning algorithm credit risk modeling. arXiv preprint arXiv:1711.05095.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mob.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Categorical Variables using Monotonic Optimal Binning (MOB) — optimal_binning_categorical_mob","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mob.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Categorical Variables using Monotonic Optimal Binning (MOB) — optimal_binning_categorical_mob","text":"","code":"if (FALSE) { # \\dontrun{ # Create sample data set.seed(123) target <- sample(0:1, 1000, replace = TRUE) feature <- sample(LETTERS[1:5], 1000, replace = TRUE)  # Run optimal binning result <- optimal_binning_categorical_mob(target, feature)  # View results print(result$woebin) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_obnp.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Categorical Variables using OBNP — optimal_binning_categorical_obnp","title":"Optimal Binning for Categorical Variables using OBNP — optimal_binning_categorical_obnp","text":"function performs optimal binning categorical variables using Optimal Binning Numerical Procedures (OBNP) approach. process aims maximize Information Value (IV) maintaining specified number bins.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_obnp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Categorical Variables using OBNP — optimal_binning_categorical_obnp","text":"","code":"optimal_binning_categorical_obnp(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_obnp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Categorical Variables using OBNP — optimal_binning_categorical_obnp","text":"target integer vector binary target values (0 1). feature character vector categorical feature values. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum proportion observations bin (default: 0.05). max_n_prebins Maximum number pre-bins (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_obnp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Categorical Variables using OBNP — optimal_binning_categorical_obnp","text":"list containing two elements: woefeature: numeric vector Weight Evidence (WoE) values observation woebin: data frame containing binning information, including bin names, WoE, Information Value (IV), counts","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_obnp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Categorical Variables using OBNP — optimal_binning_categorical_obnp","text":"algorithm works follows: Merge rare categories: Categories fewer observations specified bin_cutoff merged \"\" category. Create initial bins: unique category assigned bin, max_n_prebins. Optimize bins: . number bins exceeds max_bins, merge two bins lowest IV. b. Calculate WoE IV bin. Transform feature: Assign WoE values observation based category. Weight Evidence (WoE) calculated : $$WoE = \\ln\\left(\\frac{\\text{\\% events}}{\\text{\\% non-events}}\\right)$$ Information Value (IV) calculated : $$IV = (\\text{\\% events} - \\text{\\% non-events}) \\times WoE$$ algorithm uses OpenMP parallel processing improve performance.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_obnp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Categorical Variables using OBNP — optimal_binning_categorical_obnp","text":"Belotti, T., Crook, J. (2009). Credit Scoring Macroeconomic Variables Using Survival Analysis. Journal Operational Research Society, 60(12), 1699-1707. Thomas, L. C. (2000). survey credit behavioural scoring: forecasting financial risk lending consumers. International Journal Forecasting, 16(2), 149-172.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_obnp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Categorical Variables using OBNP — optimal_binning_categorical_obnp","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_obnp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Categorical Variables using OBNP — optimal_binning_categorical_obnp","text":"","code":"if (FALSE) { # \\dontrun{ # Create sample data target <- sample(0:1, 1000, replace = TRUE) feature <- sample(LETTERS[1:5], 1000, replace = TRUE)  # Run optimal binning result <- optimal_binning_categorical_obnp(target, feature)  # View results print(result$woebin) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_sab.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Categorical Variables using Simulated Annealing — optimal_binning_categorical_sab","title":"Optimal Binning for Categorical Variables using Simulated Annealing — optimal_binning_categorical_sab","text":"function performs optimal binning categorical variables using Simulated Annealing approach.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_sab.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Categorical Variables using Simulated Annealing — optimal_binning_categorical_sab","text":"","code":"optimal_binning_categorical_sab(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   initial_temperature = 1,   cooling_rate = 0.995,   max_iterations = 1000L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_sab.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Categorical Variables using Simulated Annealing — optimal_binning_categorical_sab","text":"target integer vector binary target values (0 1). feature character vector categorical feature values. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum proportion observations bin (default: 0.05). max_n_prebins Maximum number pre-bins (default: 20). initial_temperature Initial temperature Simulated Annealing (default: 1.0). cooling_rate Cooling rate Simulated Annealing (default: 0.995). max_iterations Maximum number iterations Simulated Annealing (default: 1000).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_sab.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Categorical Variables using Simulated Annealing — optimal_binning_categorical_sab","text":"list containing two elements: woefeature: numeric vector Weight Evidence (WoE) values observation woebin: data frame containing binning information, including bin names, WoE, Information Value (IV), counts","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_sab.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Categorical Variables using Simulated Annealing — optimal_binning_categorical_sab","text":"algorithm performs optimal binning categorical variables using Simulated Annealing (SA). process aims maximize Information Value (IV) maintaining monotonicity bins. algorithm works follows: Initialize assigning unique category random bin. Calculate initial IV. iteration SA: Generate neighbor solution randomly reassigning category different bin. Calculate IV new solution. Accept new solution improves IV maintains monotonicity. new solution worse, accept probability based current temperature. Repeat step 3 specified number iterations, reducing temperature time. Ensure final solution monotonic. Information Value (IV) calculated : $$IV = \\sum(\\text{\\% non-events} - \\text{\\% events}) \\times WoE$$ Weight Evidence (WoE) : $$WoE = \\ln(\\frac{\\text{\\% events}}{\\text{\\% non-events}})$$ algorithm uses OpenMP parallel processing improve performance.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_sab.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Categorical Variables using Simulated Annealing — optimal_binning_categorical_sab","text":"Bertsimas, D., & Dunn, J. (2017). Optimal classification trees. Machine Learning, 106(7), 1039-1082. Mironchyk, P., & Tchistiakov, V. (2017). Monotone optimal binning algorithm credit risk modeling. Workshop Data Science Advanced Analytics (DSAA).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_sab.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Categorical Variables using Simulated Annealing — optimal_binning_categorical_sab","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_sab.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Categorical Variables using Simulated Annealing — optimal_binning_categorical_sab","text":"","code":"if (FALSE) { # \\dontrun{ # Create sample data set.seed(123) target <- sample(0:1, 1000, replace = TRUE) feature <- sample(LETTERS[1:5], 1000, replace = TRUE)  # Run optimal binning result <- optimal_binning_categorical_sab(target, feature)  # View results print(result$woebin) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_sblp.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Categorical Variables using Similarity-Based Logistic Partitioning (SBLP) — optimal_binning_categorical_sblp","title":"Optimal Binning for Categorical Variables using Similarity-Based Logistic Partitioning (SBLP) — optimal_binning_categorical_sblp","text":"function performs optimal binning categorical variables using Similarity-Based Logistic Partitioning (SBLP) approach, combines Weight Evidence (WOE) Information Value (IV) methods similarity-based merging strategy.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_sblp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Categorical Variables using Similarity-Based Logistic Partitioning (SBLP) — optimal_binning_categorical_sblp","text":"","code":"optimal_binning_categorical_sblp(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_sblp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Categorical Variables using Similarity-Based Logistic Partitioning (SBLP) — optimal_binning_categorical_sblp","text":"target integer vector binary target values (0 1). feature character vector categorical feature values. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum frequency category considered separate bin (default: 0.05). max_n_prebins Maximum number pre-bins merging (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_sblp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Categorical Variables using Similarity-Based Logistic Partitioning (SBLP) — optimal_binning_categorical_sblp","text":"list containing two elements: woefeature: numeric vector WOE values input feature value woebin: data frame containing bin information, including bin labels, WOE, IV, counts","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_sblp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Categorical Variables using Similarity-Based Logistic Partitioning (SBLP) — optimal_binning_categorical_sblp","text":"algorithm performs following steps: Compute initial counts target rates category Handle rare categories merging based similarity target rates Compute initial Weight Evidence (WOE) Information Value (IV) Perform iterative binning merging similar categories Apply final binning calculate WOE IV bin Weight Evidence (WOE) calculated : $$WOE = \\ln(\\frac{\\text{Proportion Events}}{\\text{Proportion Non-Events}})$$ Information Value (IV) bin calculated : $$IV = (\\text{Proportion Events} - \\text{Proportion Non-Events}) \\times WOE$$","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_sblp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Categorical Variables using Similarity-Based Logistic Partitioning (SBLP) — optimal_binning_categorical_sblp","text":"Blanco-Justicia, ., & Domingo-Ferrer, J. (2019). Machine learning explainability microaggregation shallow decision trees. Knowledge-Based Systems, 174, 200-212. Zhu, L., Qiu, D., Ergu, D., Ying, C., & Liu, K. (2019). study predicting loan default based random forest algorithm. Procedia Computer Science, 162, 503-513.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_sblp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Categorical Variables using Similarity-Based Logistic Partitioning (SBLP) — optimal_binning_categorical_sblp","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_sblp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Categorical Variables using Similarity-Based Logistic Partitioning (SBLP) — optimal_binning_categorical_sblp","text":"","code":"if (FALSE) { # \\dontrun{ # Create sample data set.seed(123) target <- sample(0:1, 1000, replace = TRUE) feature <- sample(LETTERS[1:5], 1000, replace = TRUE)  # Run optimal binning result <- optimal_binning_categorical_sblp(target, feature)  # View results print(result$woebin) hist(result$woefeature) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_swb.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Categorical Variables using Sliding Window Binning (SWB) — optimal_binning_categorical_swb","title":"Optimal Binning for Categorical Variables using Sliding Window Binning (SWB) — optimal_binning_categorical_swb","text":"function performs optimal binning categorical variables using Sliding Window Binning (SWB) approach, combines Weight Evidence (WOE) Information Value (IV) methods monotonicity constraints.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_swb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Categorical Variables using Sliding Window Binning (SWB) — optimal_binning_categorical_swb","text":"","code":"optimal_binning_categorical_swb(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_swb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Categorical Variables using Sliding Window Binning (SWB) — optimal_binning_categorical_swb","text":"target integer vector binary target values (0 1). feature character vector categorical feature values. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum frequency category considered separate bin (default: 0.05). max_n_prebins Maximum number pre-bins merging (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_swb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Categorical Variables using Sliding Window Binning (SWB) — optimal_binning_categorical_swb","text":"list containing two elements: woefeature numeric vector WOE values input feature value woebin data frame containing bin information, including bin labels, WOE, IV, counts","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_swb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Categorical Variables using Sliding Window Binning (SWB) — optimal_binning_categorical_swb","text":"algorithm performs following steps: Initialize bins unique category Sort bins WOE values Merge adjacent bins iteratively, minimizing information loss Optimize number bins maintaining monotonicity Calculate final WOE IV values bin Weight Evidence (WOE) calculated : $$WOE = \\ln\\left(\\frac{\\text{Proportion Events}}{\\text{Proportion Non-Events}}\\right)$$ Information Value (IV) bin calculated : $$IV = (\\text{Proportion Events} - \\text{Proportion Non-Events}) \\times WOE$$","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_swb.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Categorical Variables using Sliding Window Binning (SWB) — optimal_binning_categorical_swb","text":"Saleem, S. M., & Jain, . K. (2017). comprehensive review supervised binning techniques credit scoring. Journal Risk Model Validation, 11(3), 1-35. Thomas, L. C., Edelman, D. B., & Crook, J. N. (2002). Credit scoring applications. SIAM.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_swb.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Categorical Variables using Sliding Window Binning (SWB) — optimal_binning_categorical_swb","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_swb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Categorical Variables using Sliding Window Binning (SWB) — optimal_binning_categorical_swb","text":"","code":"if (FALSE) { # \\dontrun{ # Create sample data set.seed(123) target <- sample(0:1, 1000, replace = TRUE) feature <- sample(LETTERS[1:5], 1000, replace = TRUE)  # Run optimal binning result <- optimal_binning_categorical_swb(target, feature)  # View results print(result$woebin) hist(result$woefeature) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_udt.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Categorical Variables using Unsupervised Decision Tree (UDT) — optimal_binning_categorical_udt","title":"Optimal Binning for Categorical Variables using Unsupervised Decision Tree (UDT) — optimal_binning_categorical_udt","text":"function performs optimal binning categorical variables using Unsupervised Decision Tree (UDT) approach, combines Weight Evidence (WOE) Information Value (IV) methods.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_udt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Categorical Variables using Unsupervised Decision Tree (UDT) — optimal_binning_categorical_udt","text":"","code":"optimal_binning_categorical_udt(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_udt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Categorical Variables using Unsupervised Decision Tree (UDT) — optimal_binning_categorical_udt","text":"target integer vector binary target values (0 1). feature character vector categorical feature values. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum frequency category considered separate bin (default: 0.05). max_n_prebins Maximum number pre-bins merging (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_udt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Categorical Variables using Unsupervised Decision Tree (UDT) — optimal_binning_categorical_udt","text":"list containing two elements: woefeature numeric vector WOE values input feature value woebin data frame containing bin information, including bin labels, WOE, IV, counts","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_udt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Categorical Variables using Unsupervised Decision Tree (UDT) — optimal_binning_categorical_udt","text":"algorithm performs following steps: Rare category handling: Categories frequency bin_cutoff merged \"Rare\" bin. Pre-binning: number bins exceeds max_n_prebins, least frequent categories merged \"\" bin. Calculate initial WOE IV bin. Iterative merging: Bins merged based minimum combined IV number bins reaches max_bins. Weight Evidence (WOE) calculated : WOE = ln((Distribution Good) / (Distribution Bad)) Information Value (IV) bin calculated : IV = (Distribution Good - Distribution Bad) * WOE","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_udt.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Categorical Variables using Unsupervised Decision Tree (UDT) — optimal_binning_categorical_udt","text":"Saleem, S. M., & Jain, . K. (2017). comprehensive review supervised binning techniques credit scoring. Journal Risk Model Validation, 11(3), 1-35. Thomas, L. C., Edelman, D. B., & Crook, J. N. (2002). Credit scoring applications. SIAM.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_udt.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Categorical Variables using Unsupervised Decision Tree (UDT) — optimal_binning_categorical_udt","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_udt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Categorical Variables using Unsupervised Decision Tree (UDT) — optimal_binning_categorical_udt","text":"","code":"if (FALSE) { # \\dontrun{ # Create sample data set.seed(123) target <- sample(0:1, 1000, replace = TRUE) feature <- sample(LETTERS[1:5], 1000, replace = TRUE)  # Run optimal binning result <- optimal_binning_categorical_udt(target, feature)  # View results print(result$woebin) hist(result$woefeature) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_bb.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using Branch and Bound — optimal_binning_numerical_bb","title":"Optimal Binning for Numerical Variables using Branch and Bound — optimal_binning_numerical_bb","text":"function implements optimal binning algorithm numerical variables using Branch Bound approach Weight Evidence (WoE) Information Value (IV) criteria.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_bb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using Branch and Bound — optimal_binning_numerical_bb","text":"","code":"optimal_binning_numerical_bb(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   is_monotonic = TRUE )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_bb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using Branch and Bound — optimal_binning_numerical_bb","text":"target integer vector binary target values (0 1). feature numeric vector feature values binned. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum frequency observations bin (default: 0.05). max_n_prebins Maximum number pre-bins initial quantile-based discretization (default: 20). is_monotonic Boolean indicating whether enforce monotonicity WoE across bins (default: TRUE).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_bb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using Branch and Bound — optimal_binning_numerical_bb","text":"list containing two elements: woefeature numeric vector WoE-transformed feature values. woebin data frame binning details, including bin boundaries, WoE, IV, count statistics.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_bb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using Branch and Bound — optimal_binning_numerical_bb","text":"optimal binning algorithm numerical variables uses Branch Bound approach Weight Evidence (WoE) Information Value (IV) create bins maximize predictive power feature maintaining interpretability. algorithm follows steps: Initial discretization using quantile-based binning Merging rare bins Calculation WoE IV bin Enforcing monotonicity WoE across bins (is_monotonic TRUE) Adjusting number bins within specified range using Branch Bound approach Weight Evidence (WoE) calculated bin : $$WoE_i = \\ln\\left(\\frac{P(X_i|Y=1)}{P(X_i|Y=0)}\\right)$$ \\(P(X_i|Y=1)\\) proportion positive cases bin , \\(P(X_i|Y=0)\\) proportion negative cases bin . Information Value (IV) bin calculated : $$IV_i = (P(X_i|Y=1) - P(X_i|Y=0)) \\times WoE_i$$ total IV feature sum IVs across bins: $$IV_{total} = \\sum_{=1}^{n} IV_i$$ Branch Bound approach iteratively merges bins lowest IV contribution respecting constraints number bins minimum bin frequency. process ensures resulting binning maximizes total IV maintaining desired number bins.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_bb.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using Branch and Bound — optimal_binning_numerical_bb","text":"Farooq, B., & Miller, E. J. (2015). Optimal Binning Continuous Variables Credit Scoring. Journal Risk Model Validation, 9(1), 1-21. Kotsiantis, S., & Kanellopoulos, D. (2006). Discretization Techniques: Recent Survey. GESTS International Transactions Computer Science Engineering, 32(1), 47-58.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_bb.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Numerical Variables using Branch and Bound — optimal_binning_numerical_bb","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_bb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using Branch and Bound — optimal_binning_numerical_bb","text":"","code":"if (FALSE) { # \\dontrun{ # Generate sample data set.seed(123) n <- 10000 feature <- rnorm(n) target <- rbinom(n, 1, plogis(0.5 * feature))  # Apply optimal binning result <- optimal_binning_numerical_bb(target, feature, min_bins = 3, max_bins = 5)  # View binning results print(result$woebin)  # Plot WoE transformation plot(feature, result$woefeature, main = \"WoE Transformation\",  xlab = \"Original Feature\", ylab = \"WoE\") } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_bs.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using Binary Search — optimal_binning_numerical_bs","title":"Optimal Binning for Numerical Variables using Binary Search — optimal_binning_numerical_bs","text":"function implements optimal binning algorithm numerical variables using Binary Search approach Weight Evidence (WoE) Information Value (IV) criteria.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_bs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using Binary Search — optimal_binning_numerical_bs","text":"","code":"optimal_binning_numerical_bs(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_bs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using Binary Search — optimal_binning_numerical_bs","text":"target integer vector binary target values (0 1). feature numeric vector feature values binned. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum frequency observations bin (default: 0.05). max_n_prebins Maximum number pre-bins initial quantile-based discretization (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_bs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using Binary Search — optimal_binning_numerical_bs","text":"list containing two elements: woefeature numeric vector WoE-transformed feature values. woebin data frame binning details, including bin boundaries, WoE, IV, count statistics.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_bs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using Binary Search — optimal_binning_numerical_bs","text":"optimal binning algorithm numerical variables uses Binary Search approach Weight Evidence (WoE) Information Value (IV) create bins maximize predictive power feature maintaining interpretability. algorithm follows steps: Initial discretization using quantile-based binning Calculation WoE IV bin Enforcing monotonicity WoE across bins Merging rare bins based bin_cutoff parameter Adjusting number bins within specified range using Binary Search approach Weight Evidence (WoE) calculated bin : $$WoE_i = \\ln\\left(\\frac{P(X_i|Y=1)}{P(X_i|Y=0)}\\right)$$ \\(P(X_i|Y=1)\\) proportion positive cases bin , \\(P(X_i|Y=0)\\) proportion negative cases bin . Information Value (IV) bin calculated : $$IV_i = (P(X_i|Y=1) - P(X_i|Y=0)) \\times WoE_i$$ total IV feature sum IVs across bins: $$IV_{total} = \\sum_{=1}^{n} IV_i$$ Binary Search approach efficiently adjusts number bins iteratively merging bins lowest IV contribution splitting bins highest count, respecting constraints number bins minimum bin frequency. process ensures resulting binning maximizes total IV maintaining desired number bins.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_bs.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using Binary Search — optimal_binning_numerical_bs","text":"Mironchyk, P., & Tchistiakov, V. (2017). Monotone optimal binning algorithm credit risk modeling. arXiv preprint arXiv:1711.05095. Beltratti, ., Margarita, S., & Terna, P. (1996). Neural networks economic financial modelling. International Thomson Computer Press.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_bs.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Numerical Variables using Binary Search — optimal_binning_numerical_bs","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_bs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using Binary Search — optimal_binning_numerical_bs","text":"","code":"if (FALSE) { # \\dontrun{ # Generate sample data set.seed(123) n <- 10000 feature <- rnorm(n) target <- rbinom(n, 1, plogis(0.5 * feature))  # Apply optimal binning result <- optimal_binning_numerical_bs(target, feature, min_bins = 3, max_bins = 5)  # View binning results print(result$woebin)  # Plot WoE transformation plot(feature, result$woefeature, main = \"WoE Transformation\",  xlab = \"Original Feature\", ylab = \"WoE\") } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_cart.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using CART-based approach — optimal_binning_numerical_cart","title":"Optimal Binning for Numerical Variables using CART-based approach — optimal_binning_numerical_cart","text":"function implements optimal binning algorithm numerical variables using CART-based (Classification Regression Trees) approach Weight Evidence (WoE) Information Value (IV) criteria.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_cart.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using CART-based approach — optimal_binning_numerical_cart","text":"","code":"optimal_binning_numerical_cart(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   is_monotonic = TRUE )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_cart.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using CART-based approach — optimal_binning_numerical_cart","text":"target integer vector binary target values (0 1). feature numeric vector feature values binned. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum frequency observations bin (default: 0.05). max_n_prebins Maximum number pre-bins initial quantile-based discretization (default: 20). is_monotonic Boolean indicating whether enforce monotonicity WoE across bins (default: TRUE).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_cart.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using CART-based approach — optimal_binning_numerical_cart","text":"list containing three elements: woefeature numeric vector WoE-transformed feature values. woebin data frame binning details, including bin boundaries, WoE, IV, count statistics. total_iv total Information Value binned feature.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_cart.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using CART-based approach — optimal_binning_numerical_cart","text":"optimal binning algorithm numerical variables uses CART-based approach Weight Evidence (WoE) Information Value (IV) create bins maximize predictive power feature maintaining interpretability. algorithm follows steps: Initial discretization using quantile-based binning Calculation WoE IV bin Merging bins based minimizing IV differences Enforcing minimum bin frequency (bin_cutoff) Enforcing monotonicity WoE across bins (is_monotonic TRUE) Weight Evidence (WoE) calculated bin : $$WoE_i = \\ln\\left(\\frac{P(X_i|Y=1)}{P(X_i|Y=0)}\\right)$$ \\(P(X_i|Y=1)\\) proportion positive cases bin , \\(P(X_i|Y=0)\\) proportion negative cases bin . Information Value (IV) bin calculated : $$IV_i = (P(X_i|Y=1) - P(X_i|Y=0)) \\times WoE_i$$ total IV feature sum IVs across bins: $$IV_{total} = \\sum_{=1}^{n} IV_i$$ CART-based approach iteratively merges bins smallest IV difference, ensuring resulting binning maximizes total IV maintaining desired number bins respecting minimum bin frequency constraint.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_cart.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using CART-based approach — optimal_binning_numerical_cart","text":"Breiman, L., Friedman, J., Stone, C. J., & Olshen, R. . (1984). Classification regression trees. CRC press. Zeng, G. (2014). necessary condition good binning algorithm credit scoring. Applied Mathematical Sciences, 8(65), 3229-3242.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_cart.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Numerical Variables using CART-based approach — optimal_binning_numerical_cart","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_cart.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using CART-based approach — optimal_binning_numerical_cart","text":"","code":"if (FALSE) { # \\dontrun{ # Generate sample data set.seed(123) n <- 10000 feature <- rnorm(n) target <- rbinom(n, 1, plogis(0.5 * feature))  # Apply optimal binning result <- optimal_binning_numerical_cart(target, feature, min_bins = 3, max_bins = 5)  # View binning results print(result$woebin)  # Plot WoE transformation plot(feature, result$woefeature, main = \"WoE Transformation\",  xlab = \"Original Feature\", ylab = \"WoE\")  # Print total Information Value cat(\"Total IV:\", result$total_iv, \"\\n\") } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_cm.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using ChiMerge — optimal_binning_numerical_cm","title":"Optimal Binning for Numerical Variables using ChiMerge — optimal_binning_numerical_cm","text":"function implements optimal binning algorithm numerical variables using ChiMerge approach Weight Evidence (WoE) Information Value (IV) criteria.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_cm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using ChiMerge — optimal_binning_numerical_cm","text":"","code":"optimal_binning_numerical_cm(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_cm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using ChiMerge — optimal_binning_numerical_cm","text":"target integer vector binary target values (0 1). feature numeric vector feature values binned. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum frequency observations bin (default: 0.05). max_n_prebins Maximum number pre-bins initial discretization (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_cm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using ChiMerge — optimal_binning_numerical_cm","text":"list containing two elements: woefeature numeric vector WoE-transformed feature values. woebin data frame binning details, including bin boundaries, WoE, IV, count statistics.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_cm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using ChiMerge — optimal_binning_numerical_cm","text":"optimal binning algorithm numerical variables uses ChiMerge approach Weight Evidence (WoE) Information Value (IV) create bins maximize predictive power feature maintaining interpretability. algorithm follows steps: Initial discretization max_n_prebins Iterative merging adjacent bins based chi-square statistic Merging rare bins based bin_cutoff parameter Calculation WoE IV final bin chi-square statistic two adjacent bins calculated : $$\\chi^2 = \\sum_{=1}^{2} \\sum_{j=1}^{2} \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}$$ \\(O_{ij}\\) observed frequency \\(E_{ij}\\) expected frequency bin class j. Weight Evidence (WoE) calculated bin : $$WoE_i = \\ln\\left(\\frac{P(X_i|Y=1)}{P(X_i|Y=0)}\\right)$$ \\(P(X_i|Y=1)\\) proportion positive cases bin , \\(P(X_i|Y=0)\\) proportion negative cases bin . Information Value (IV) bin calculated : $$IV_i = (P(X_i|Y=1) - P(X_i|Y=0)) \\times WoE_i$$ total IV feature sum IVs across bins: $$IV_{total} = \\sum_{=1}^{n} IV_i$$ ChiMerge approach ensures resulting binning maximizes separation classes maintaining desired number bins respecting minimum bin frequency constraint.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_cm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using ChiMerge — optimal_binning_numerical_cm","text":"Kerber, R. (1992). ChiMerge: Discretization Numeric Attributes. Proceedings tenth national conference Artificial intelligence (pp. 123-128). AAAI Press. Zeng, G. (2014). necessary condition good binning algorithm credit scoring. Applied Mathematical Sciences, 8(65), 3229-3242.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_cm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Numerical Variables using ChiMerge — optimal_binning_numerical_cm","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_cm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using ChiMerge — optimal_binning_numerical_cm","text":"","code":"if (FALSE) { # \\dontrun{ # Generate sample data set.seed(123) n <- 10000 feature <- rnorm(n) target <- rbinom(n, 1, plogis(0.5 * feature))  # Apply optimal binning result <- optimal_binning_numerical_cm(target, feature, min_bins = 3, max_bins = 5)  # View binning results print(result$woebin)  # Plot WoE transformation plot(feature, result$woefeature, main = \"WoE Transformation\",  xlab = \"Original Feature\", ylab = \"WoE\") } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_dpb.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using Dynamic Programming — optimal_binning_numerical_dpb","title":"Optimal Binning for Numerical Variables using Dynamic Programming — optimal_binning_numerical_dpb","text":"function implements optimal binning algorithm numerical variables using Dynamic Programming Weight Evidence (WoE) Information Value (IV) criteria.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_dpb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using Dynamic Programming — optimal_binning_numerical_dpb","text":"","code":"optimal_binning_numerical_dpb(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   n_threads = 1L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_dpb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using Dynamic Programming — optimal_binning_numerical_dpb","text":"target integer vector binary target values (0 1). feature numeric vector feature values binned. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum frequency observations bin (default: 0.05). max_n_prebins Maximum number pre-bins initial quantile-based discretization (default: 20). n_threads Number threads parallel processing (default: 1).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_dpb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using Dynamic Programming — optimal_binning_numerical_dpb","text":"list containing two elements: woefeature numeric vector WoE-transformed feature values. woebin data frame binning details, including bin boundaries, WoE, IV, count statistics.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_dpb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using Dynamic Programming — optimal_binning_numerical_dpb","text":"optimal binning algorithm numerical variables uses Dynamic Programming find optimal binning solution maximizes total Information Value (IV) respecting constraints number bins minimum bin frequency. algorithm follows steps: Initial discretization using quantile-based binning Dynamic programming find optimal bins Enforcement monotonicity WoE across bins Calculation final WoE IV bin Application WoE transformation original feature Weight Evidence (WoE) calculated bin : $$WoE_i = \\ln\\left(\\frac{P(X_i|Y=1)}{P(X_i|Y=0)}\\right)$$ \\(P(X_i|Y=1)\\) proportion positive cases bin , \\(P(X_i|Y=0)\\) proportion negative cases bin . Information Value (IV) bin calculated : $$IV_i = (P(X_i|Y=1) - P(X_i|Y=0)) * WoE_i$$ total IV feature sum IVs across bins: $$IV_{total} = \\sum_{=1}^{n} IV_i$$ Dynamic Programming approach ensures resulting binning maximizes total IV respecting constraints number bins minimum bin frequency.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_dpb.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using Dynamic Programming — optimal_binning_numerical_dpb","text":"Wilks, S. S. (1938). Large-Sample Distribution Likelihood Ratio Testing Composite Hypotheses. Annals Mathematical Statistics, 9(1), 60-62. Bellman, R. (1954). theory dynamic programming. Bulletin American Mathematical Society, 60(6), 503-515.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_dpb.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Numerical Variables using Dynamic Programming — optimal_binning_numerical_dpb","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_dpb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using Dynamic Programming — optimal_binning_numerical_dpb","text":"","code":"if (FALSE) { # \\dontrun{ # Generate sample data set.seed(123) n <- 10000 feature <- rnorm(n) target <- rbinom(n, 1, plogis(0.5 * feature))  # Apply optimal binning result <- optimal_binning_numerical_dpb(target, feature, min_bins = 3, max_bins = 5)  # View binning results print(result$woebin)  # Plot WoE transformation plot(feature, result$woefeature, main = \"WoE Transformation\",      xlab = \"Original Feature\", ylab = \"WoE\") } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_dplc.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using Dynamic Programming with Local Constraints (DPLC) — optimal_binning_numerical_dplc","title":"Optimal Binning for Numerical Variables using Dynamic Programming with Local Constraints (DPLC) — optimal_binning_numerical_dplc","text":"function performs optimal binning numerical variables using Dynamic Programming Local Constraints (DPLC) approach. creates optimal bins numerical feature based relationship binary target variable, maximizing predictive power respecting user-defined constraints enforcing monotonicity.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_dplc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using Dynamic Programming with Local Constraints (DPLC) — optimal_binning_numerical_dplc","text":"","code":"optimal_binning_numerical_dplc(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_dplc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using Dynamic Programming with Local Constraints (DPLC) — optimal_binning_numerical_dplc","text":"target integer vector binary target values (0 1). feature numeric vector feature values. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum proportion total observations bin avoid merged (default: 0.05). max_n_prebins Maximum number pre-bins optimization process (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_dplc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using Dynamic Programming with Local Constraints (DPLC) — optimal_binning_numerical_dplc","text":"list containing two elements: woefeature numeric vector Weight Evidence (WoE) values observation. woebin data frame following columns: bin: Character vector bin ranges. woe: Numeric vector WoE values bin. iv: Numeric vector Information Value (IV) bin. count: Numeric vector total observations bin. count_pos: Numeric vector positive target observations bin. count_neg: Numeric vector negative target observations bin.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_dplc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using Dynamic Programming with Local Constraints (DPLC) — optimal_binning_numerical_dplc","text":"Dynamic Programming Local Constraints (DPLC) algorithm numerical variables works follows: Perform initial pre-binning based quantiles feature distribution. Calculate initial counts Weight Evidence (WoE) bin. Enforce monotonicity WoE values across bins merging adjacent non-monotonic bins. Ensure number bins min_bins max_bins: Merge bins smallest IV difference max_bins. Handle rare bins merging bin_cutoff threshold. Calculate final Information Value (IV) bin. algorithm aims create bins maximize predictive power numerical variable adhering specified constraints. enforces monotonicity WoE values, particularly useful credit scoring risk modeling applications. Weight Evidence (WoE) calculated : $$WoE = \\ln\\left(\\frac{\\text{Positive Rate}}{\\text{Negative Rate}}\\right)$$ Information Value (IV) calculated : $$IV = (\\text{Positive Rate} - \\text{Negative Rate}) \\times WoE$$ implementation uses OpenMP parallel processing available, can significantly speed computation large datasets.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_dplc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using Dynamic Programming with Local Constraints (DPLC) — optimal_binning_numerical_dplc","text":"Mironchyk, P., & Tchistiakov, V. (2017). Monotone optimal binning algorithm credit risk modeling. SSRN Electronic Journal. DOI: 10.2139/ssrn.2978774 Bellman, R. (1952). theory dynamic programming. Proceedings National Academy Sciences, 38(8), 716-719.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_dplc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Numerical Variables using Dynamic Programming with Local Constraints (DPLC) — optimal_binning_numerical_dplc","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_dplc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using Dynamic Programming with Local Constraints (DPLC) — optimal_binning_numerical_dplc","text":"","code":"if (FALSE) { # \\dontrun{ # Create sample data set.seed(123) n <- 1000 target <- sample(0:1, n, replace = TRUE) feature <- rnorm(n)  # Run optimal binning result <- optimal_binning_numerical_dplc(target, feature, min_bins = 2, max_bins = 4)  # Print results print(result$woebin)  # Plot WoE values plot(result$woebin$woe, type = \"s\", xaxt = \"n\", xlab = \"Bins\", ylab = \"WoE\",      main = \"Weight of Evidence by Bin\") axis(1, at = 1:nrow(result$woebin), labels = result$woebin$bin, las = 2) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_eb.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using Entropy-Based Approach — optimal_binning_numerical_eb","title":"Optimal Binning for Numerical Variables using Entropy-Based Approach — optimal_binning_numerical_eb","text":"function implements optimal binning algorithm numerical variables using entropy-based approach. creates bins maximize predictive power feature respect binary target variable, ensuring monotonicity Weight Evidence (WoE) values.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_eb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using Entropy-Based Approach — optimal_binning_numerical_eb","text":"","code":"optimal_binning_numerical_eb(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   n_threads = 1L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_eb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using Entropy-Based Approach — optimal_binning_numerical_eb","text":"target integer vector binary target values (0 1). feature numeric vector feature values binned. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum frequency observations bin proportion total observations (default: 0.05). max_n_prebins Maximum number initial bins merging (default: 20). n_threads Number threads parallel processing (default: 1).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_eb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using Entropy-Based Approach — optimal_binning_numerical_eb","text":"list containing two elements: woefeature numeric vector WoE values assigned observation input feature. woebin data frame containing binning details, including bin boundaries, WoE values, Information Value (IV), counts.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_eb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using Entropy-Based Approach — optimal_binning_numerical_eb","text":"optimal binning algorithm numerical variables using entropy-based approach works follows: Initial Binning: algorithm starts creating max_n_prebins equally spaced quantiles input feature. Merging Small Bins: Bins frequency bin_cutoff merged adjacent bins ensure statistical significance. Calculating WoE IV: bin, Weight Evidence (WoE) Information Value (IV) calculated using following formulas: $$WoE_i = \\ln\\left(\\frac{P(X_i|Y=1)}{P(X_i|Y=0)}\\right)$$ $$IV_i = (P(X_i|Y=1) - P(X_i|Y=0)) \\times WoE_i$$ \\(X_i\\) represents -th bin \\(Y\\) binary target variable. 4. Enforcing Monotonicity: algorithm ensures WoE values monotonic across bins merging adjacent bins violate condition. 5. Adjusting Bin Count: number bins exceeds max_bins, algorithm merges bins smallest total count desired number bins achieved. 6. Final Output: algorithm assigns WoE values observation input feature provides detailed binning information. approach aims maximize predictive power feature maintaining interpretability robustness binning process.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_eb.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using Entropy-Based Approach — optimal_binning_numerical_eb","text":"Beltratti, ., Margarita, S., & Terna, P. (1996). Neural networks economic financial modelling. International Thomson Computer Press. Kotsiantis, S., & Kanellopoulos, D. (2006). Discretization techniques: recent survey. GESTS International Transactions Computer Science Engineering, 32(1), 47-58.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_eb.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Numerical Variables using Entropy-Based Approach — optimal_binning_numerical_eb","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_eb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using Entropy-Based Approach — optimal_binning_numerical_eb","text":"","code":"if (FALSE) { # \\dontrun{ # Generate sample data set.seed(42) target <- sample(0:1, 1000, replace = TRUE) feature <- rnorm(1000) # Run optimal binning result <- optimal_binning_numerical_eb(target, feature) # View WoE-transformed feature head(result$woefeature) # View binning details print(result$woebin) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_eblc.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using Equal-Frequency Binning with Local Convergence — optimal_binning_numerical_eblc","title":"Optimal Binning for Numerical Variables using Equal-Frequency Binning with Local Convergence — optimal_binning_numerical_eblc","text":"function implements optimal binning algorithm numerical variables using Equal-Frequency Binning approach Local Convergence. aims find good binning strategy balances interpretability, predictive power, monotonicity Weight Evidence (WoE).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_eblc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using Equal-Frequency Binning with Local Convergence — optimal_binning_numerical_eblc","text":"","code":"optimal_binning_numerical_eblc(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_eblc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using Equal-Frequency Binning with Local Convergence — optimal_binning_numerical_eblc","text":"target integer vector binary target values (0 1). feature numeric vector feature values binned. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum fraction total observations bin (default: 0.05). max_n_prebins Maximum number pre-bins (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_eblc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using Equal-Frequency Binning with Local Convergence — optimal_binning_numerical_eblc","text":"list containing: woefeature numeric vector Weight Evidence (WoE) values observation woebin data frame binning information, including bin ranges, WoE, IV, counts","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_eblc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using Equal-Frequency Binning with Local Convergence — optimal_binning_numerical_eblc","text":"optimal binning algorithm using Equal-Frequency Binning Local Convergence consists several steps: Initial binning: feature divided max_n_prebins bins, containing approximately number observations. Merging rare bins: Bins fraction observations less bin_cutoff merged adjacent bins. Ensuring minimum bins: number bins less min_bins, largest bin split median. Enforcing maximum bins: number bins exceeds max_bins, adjacent bins lowest combined Information Value (IV) merged. WoE IV calculation: Weight Evidence (WoE) Information Value (IV) calculated bin. Enforcing monotonicity: Adjacent bins merged ensure monotonicity WoE values maintaining minimum number bins. Assigning WoE feature: feature value assigned WoE corresponding bin. Weight Evidence (WoE) bin calculated : $$WoE = \\ln\\left(\\frac{P(X|Y=1)}{P(X|Y=0)}\\right)$$ \\(P(X|Y=1)\\) probability feature particular bin given positive target, \\(P(X|Y=0)\\) probability given negative target. Information Value (IV) bin calculated : $$IV = (P(X|Y=1) - P(X|Y=0)) * WoE$$ approach provides balance simplicity, effectiveness, interpretability. creates bins equal frequency initially adjusts based data distribution, target variable relationship, monotonicity constraints. local convergence ensures final binning maximizes predictive power respecting specified constraints maintaining monotonicity WoE values.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_eblc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using Equal-Frequency Binning with Local Convergence — optimal_binning_numerical_eblc","text":"Belotti, P., & Carrasco, M. (2017). Optimal binning: mathematical programming formulation solution approach. arXiv preprint arXiv:1705.03287. Mironchyk, P., & Tchistiakov, V. (2017). Monotone optimal binning algorithm credit risk modeling. arXiv preprint arXiv:1711.06692.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_eblc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Numerical Variables using Equal-Frequency Binning with Local Convergence — optimal_binning_numerical_eblc","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_eblc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using Equal-Frequency Binning with Local Convergence — optimal_binning_numerical_eblc","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(123) target <- sample(0:1, 1000, replace = TRUE) feature <- rnorm(1000) result <- optimal_binning_numerical_eblc(target, feature) print(result$woebin) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_efb.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using Equal-Frequency Binning — optimal_binning_numerical_efb","title":"Optimal Binning for Numerical Variables using Equal-Frequency Binning — optimal_binning_numerical_efb","text":"function implements optimal binning algorithm numerical variables using Equal-Frequency Binning approach subsequent optimization. aims find good binning strategy balances interpretability predictive power.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_efb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using Equal-Frequency Binning — optimal_binning_numerical_efb","text":"","code":"optimal_binning_numerical_efb(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_efb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using Equal-Frequency Binning — optimal_binning_numerical_efb","text":"target integer vector binary target values (0 1). feature numeric vector feature values binned. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum fraction total observations bin (default: 0.05). max_n_prebins Maximum number pre-bins (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_efb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using Equal-Frequency Binning — optimal_binning_numerical_efb","text":"list containing: woefeature numeric vector Weight Evidence (WoE) values observation woebin data frame binning information, including bin ranges, WoE, IV, counts","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_efb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using Equal-Frequency Binning — optimal_binning_numerical_efb","text":"optimal binning algorithm using Equal-Frequency Binning consists several steps: Initial binning: feature divided max_n_prebins bins, containing approximately number observations. Merging rare bins: Bins fraction observations less bin_cutoff merged adjacent bins. Optimizing bins: number bins exceeds max_bins, adjacent bins merged iteratively minimize loss Information Value (IV). WoE IV calculation: Weight Evidence (WoE) Information Value (IV) calculated bin. Weight Evidence (WoE) bin calculated : $$WoE = \\ln\\left(\\frac{P(X|Y=1)}{P(X|Y=0)}\\right)$$ \\(P(X|Y=1)\\) probability feature particular bin given positive target, \\(P(X|Y=0)\\) probability given negative target. Information Value (IV) bin calculated : $$IV = (P(X|Y=1) - P(X|Y=0)) * WoE$$ total IV sum IVs bins: $$Total IV = \\sum_{=1}^{n} IV_i$$ approach provides balance simplicity effectiveness, creating bins equal frequency initially adjusting based data distribution target variable relationship. optimization step ensures final binning maximizes predictive power respecting specified constraints.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_efb.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using Equal-Frequency Binning — optimal_binning_numerical_efb","text":"Dougherty, J., Kohavi, R., & Sahami, M. (1995). Supervised unsupervised discretization continuous features. Machine Learning Proceedings 1995 (pp. 194-202). Morgan Kaufmann. Liu, H., Hussain, F., Tan, C. L., & Dash, M. (2002). Discretization: enabling technique. Data mining knowledge discovery, 6(4), 393-423.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_efb.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Numerical Variables using Equal-Frequency Binning — optimal_binning_numerical_efb","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_efb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using Equal-Frequency Binning — optimal_binning_numerical_efb","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(123) target <- sample(0:1, 1000, replace = TRUE) feature <- rnorm(1000) result <- optimal_binning_numerical_efb(target, feature) print(result$woebin) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ewb.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using Equal-Width Binning — optimal_binning_numerical_ewb","title":"Optimal Binning for Numerical Variables using Equal-Width Binning — optimal_binning_numerical_ewb","text":"function implements optimal binning algorithm numerical variables using Equal-Width Binning approach subsequent merging adjustment. aims find good binning strategy balances interpretability predictive power.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ewb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using Equal-Width Binning — optimal_binning_numerical_ewb","text":"","code":"optimal_binning_numerical_ewb(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ewb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using Equal-Width Binning — optimal_binning_numerical_ewb","text":"target integer vector binary target values (0 1). feature numeric vector feature values binned. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum fraction total observations bin (default: 0.05). max_n_prebins Maximum number pre-bins (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ewb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using Equal-Width Binning — optimal_binning_numerical_ewb","text":"list containing: woefeature numeric vector Weight Evidence (WoE) values observation woebin data frame binning information, including bin ranges, WoE, IV, counts","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ewb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using Equal-Width Binning — optimal_binning_numerical_ewb","text":"optimal binning algorithm using Equal-Width Binning consists several steps: Initial binning: feature range divided max_n_prebins bins equal width. Merging rare bins: Bins fraction observations less bin_cutoff merged adjacent bins. Adjusting number bins: number bins exceeds max_bins, adjacent bins similar WoE values merged max_bins reached. WoE IV calculation: Weight Evidence (WoE) Information Value (IV) calculated bin. Weight Evidence (WoE) bin calculated : $$WoE = \\ln\\left(\\frac{P(X|Y=1)}{P(X|Y=0)}\\right)$$ \\(P(X|Y=1)\\) probability feature particular bin given positive target, \\(P(X|Y=0)\\) probability given negative target. Information Value (IV) bin calculated : $$IV = (P(X|Y=1) - P(X|Y=0)) * WoE$$ total IV sum IVs bins: $$Total IV = \\sum_{=1}^{n} IV_i$$ approach provides balance simplicity effectiveness, creating bins equal width initially adjusting based data distribution target variable relationship.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ewb.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using Equal-Width Binning — optimal_binning_numerical_ewb","text":"Dougherty, J., Kohavi, R., & Sahami, M. (1995). Supervised unsupervised discretization continuous features. Machine Learning Proceedings 1995 (pp. 194-202). Morgan Kaufmann. Liu, H., Hussain, F., Tan, C. L., & Dash, M. (2002). Discretization: enabling technique. Data mining knowledge discovery, 6(4), 393-423.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ewb.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Numerical Variables using Equal-Width Binning — optimal_binning_numerical_ewb","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ewb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using Equal-Width Binning — optimal_binning_numerical_ewb","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(123) target <- sample(0:1, 1000, replace = TRUE) feature <- rnorm(1000) result <- optimal_binning_numerical_ewb(target, feature) print(result$woebin) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_fetb.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using Fisher's Exact Test — optimal_binning_numerical_fetb","title":"Optimal Binning for Numerical Variables using Fisher's Exact Test — optimal_binning_numerical_fetb","text":"function implements optimal binning algorithm numerical variables using Fisher's Exact Test. aims find best binning strategy maximizes predictive power ensuring statistical significance adjacent bins.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_fetb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using Fisher's Exact Test — optimal_binning_numerical_fetb","text":"","code":"optimal_binning_numerical_fetb(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_fetb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using Fisher's Exact Test — optimal_binning_numerical_fetb","text":"target numeric vector binary target values (0 1). feature numeric vector feature values binned. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff P-value threshold merging bins (default: 0.05). max_n_prebins Maximum number pre-bins (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_fetb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using Fisher's Exact Test — optimal_binning_numerical_fetb","text":"list containing: woefeature numeric vector Weight Evidence (WoE) values observation woebin data frame binning information, including bin ranges, WoE, IV, counts totalIV total Information Value binning","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_fetb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using Fisher's Exact Test — optimal_binning_numerical_fetb","text":"optimal binning algorithm using Fisher's Exact Test consists several steps: Pre-binning: feature initially divided maximum number bins specified max_n_prebins. Bin merging: Adjacent bins iteratively merged based p-value Fisher's Exact Test. Monotonicity enforcement: Ensures Weight Evidence (WoE) values monotonic across bins. WoE IV calculation: Calculates Weight Evidence Information Value bin. Fisher's Exact Test used determine significant difference proportion positive cases adjacent bins. test performed 2x2 contingency table: $$ \\begin{array}{|c|c|c|} \\hline  & \\text{Positive} & \\text{Negative} \\\\ \\hline \\text{Bin 1} & & b \\\\ \\hline \\text{Bin 2} & c & d \\\\ \\hline \\end{array} $$ p-value test used decide whether merge adjacent bins. Weight Evidence (WoE) bin calculated : $$WoE = \\ln\\left(\\frac{P(X|Y=1)}{P(X|Y=0)}\\right)$$ \\(P(X|Y=1)\\) probability feature particular bin given positive target, \\(P(X|Y=0)\\) probability given negative target. Information Value (IV) bin calculated : $$IV = (P(X|Y=1) - P(X|Y=0)) * WoE$$ total IV sum IVs bins: $$Total IV = \\sum_{=1}^{n} IV_i$$ approach ensures resulting bins statistically different , potentially leading robust meaningful binning.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_fetb.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using Fisher's Exact Test — optimal_binning_numerical_fetb","text":"Fisher, R. . (1922). interpretation χ2 contingency tables, calculation P. Journal Royal Statistical Society, 85(1), 87-94. Belotti, P., & Carrasco, M. (2017). Optimal binning: mathematical programming formulation solution approach. arXiv preprint arXiv:1705.03287.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_fetb.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Numerical Variables using Fisher's Exact Test — optimal_binning_numerical_fetb","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_fetb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using Fisher's Exact Test — optimal_binning_numerical_fetb","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(123) target <- sample(0:1, 1000, replace = TRUE) feature <- rnorm(1000) result <- optimal_binning_numerical_fetb(target, feature) print(result$woebin) print(result$totalIV) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_gab.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using Genetic Algorithm — optimal_binning_numerical_gab","title":"Optimal Binning for Numerical Variables using Genetic Algorithm — optimal_binning_numerical_gab","text":"function implements optimal binning algorithm numerical variables using genetic algorithm approach. aims find best binning strategy maximizes Information Value (IV) ensuring monotonicity Weight Evidence (WoE) values.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_gab.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using Genetic Algorithm — optimal_binning_numerical_gab","text":"","code":"optimal_binning_numerical_gab(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_gab.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using Genetic Algorithm — optimal_binning_numerical_gab","text":"target numeric vector binary target values (0 1). feature numeric vector feature values binned. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum fraction total observations bin (default: 0.05). max_n_prebins Maximum number pre-bins (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_gab.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using Genetic Algorithm — optimal_binning_numerical_gab","text":"list containing: woefeature numeric vector Weight Evidence (WoE) values observation woebin data frame binning information, including bin ranges, WoE, IV, counts","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_gab.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using Genetic Algorithm — optimal_binning_numerical_gab","text":"optimal binning algorithm using genetic algorithm approach consists several steps: Pre-binning: feature initially divided maximum number bins specified max_n_prebins. Genetic Algorithm: . Initialization: Create population potential binning solutions. b. Evaluation: Calculate fitness (Information Value) solution. c. Selection: Choose best solutions reproduction. d. Crossover: Create new solutions combining existing ones. e. Mutation: Introduce small random changes maintain diversity. f. Repeat b-e specified number generations. Monotonicity check: Ensure WoE values either monotonically increasing decreasing across bins. Bin adjustment: Merge bins fewer observations specified bin_cutoff. Weight Evidence (WoE) bin calculated : $$WoE = \\ln\\left(\\frac{P(X|Y=1)}{P(X|Y=0)}\\right)$$ \\(P(X|Y=1)\\) probability feature particular bin given positive target, \\(P(X|Y=0)\\) probability given negative target. Information Value (IV) bin calculated : $$IV = (P(X|Y=1) - P(X|Y=0)) * WoE$$ total IV, used fitness function genetic algorithm, sum IVs bins: $$Total IV = \\sum_{=1}^{n} IV_i$$ genetic algorithm approach allows global optimization binning strategy, potentially finding better solutions greedy local search methods.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_gab.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using Genetic Algorithm — optimal_binning_numerical_gab","text":"Kotsiantis, S., & Kanellopoulos, D. (2006). Discretization techniques: recent survey. GESTS International Transactions Computer Science Engineering, 32(1), 47-58. Dougherty, J., Kohavi, R., & Sahami, M. (1995). Supervised unsupervised discretization continuous features. Machine Learning Proceedings 1995 (pp. 194-202). Morgan Kaufmann.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_gab.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Numerical Variables using Genetic Algorithm — optimal_binning_numerical_gab","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_gab.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using Genetic Algorithm — optimal_binning_numerical_gab","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(123) target <- sample(0:1, 1000, replace = TRUE) feature <- rnorm(1000) result <- optimal_binning_numerical_gab(target, feature) print(result$woebin) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_gmb.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using Greedy Monotonic Binning — optimal_binning_numerical_gmb","title":"Optimal Binning for Numerical Variables using Greedy Monotonic Binning — optimal_binning_numerical_gmb","text":"function implements optimal binning algorithm numerical variables using greedy monotonic binning approach. aims find best binning strategy maximizes predictive power ensuring monotonicity Weight Evidence (WoE) values.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_gmb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using Greedy Monotonic Binning — optimal_binning_numerical_gmb","text":"","code":"optimal_binning_numerical_gmb(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_gmb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using Greedy Monotonic Binning — optimal_binning_numerical_gmb","text":"target integer vector binary target values (0 1). feature numeric vector feature values binned. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum fraction total observations bin (default: 0.05). max_n_prebins Maximum number pre-bins (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_gmb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using Greedy Monotonic Binning — optimal_binning_numerical_gmb","text":"list containing: woefeature numeric vector Weight Evidence (WoE) values observation woebin data frame binning information, including bin ranges, WoE, IV, counts","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_gmb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using Greedy Monotonic Binning — optimal_binning_numerical_gmb","text":"optimal binning algorithm using greedy monotonic binning consists several steps: Initial binning: feature initially divided maximum number bins specified max_n_prebins. Merging low-frequency bins: Bins fraction observations less bin_cutoff merged adjacent bins. Calculating WoE IV: Weight Evidence (WoE) Information Value (IV) calculated bin. Enforcing monotonicity: algorithm ensures WoE values either monotonically increasing decreasing across bins. Weight Evidence (WoE) bin calculated : $$WoE = \\ln\\left(\\frac{P(X|Y=1)}{P(X|Y=0)}\\right)$$ \\(P(X|Y=1)\\) probability feature particular bin given positive target, \\(P(X|Y=0)\\) probability given negative target. Information Value (IV) bin calculated : $$IV = (P(X|Y=1) - P(X|Y=0)) * WoE$$ algorithm uses greedy approach enforce monotonicity: Check initial WoE values monotonic (increasing decreasing). monotonic, iteratively merge adjacent bins smallest WoE difference monotonicity achieved minimum number bins reached. merge, recalculate WoE IV values check monotonicity. approach ensures final binning solution monotonic WoE values, often desirable interpretability stability binning.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_gmb.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using Greedy Monotonic Binning — optimal_binning_numerical_gmb","text":"Belotti, P., & Carrasco, M. (2017). Optimal binning: mathematical programming formulation solution approach. arXiv preprint arXiv:1705.03287. Mironchyk, P., & Tchistiakov, V. (2017). Monotone optimal binning algorithm credit risk modeling. arXiv preprint arXiv:1711.06692.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_gmb.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Numerical Variables using Greedy Monotonic Binning — optimal_binning_numerical_gmb","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_gmb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using Greedy Monotonic Binning — optimal_binning_numerical_gmb","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(123) target <- sample(0:1, 1000, replace = TRUE) feature <- rnorm(1000) result <- optimal_binning_numerical_gmb(target, feature) print(result$woebin) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ir.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using Isotonic Regression — optimal_binning_numerical_ir","title":"Optimal Binning for Numerical Variables using Isotonic Regression — optimal_binning_numerical_ir","text":"function performs optimal binning numerical variables using isotonic regression. creates optimal bins numerical feature based relationship binary target variable, maximizing predictive power respecting user-defined constraints.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ir.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using Isotonic Regression — optimal_binning_numerical_ir","text":"","code":"optimal_binning_numerical_ir(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ir.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using Isotonic Regression — optimal_binning_numerical_ir","text":"target integer vector binary target values (0 1). feature numeric vector feature values. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum proportion total observations bin avoid merged (default: 0.05). max_n_prebins Maximum number pre-bins optimization process (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ir.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using Isotonic Regression — optimal_binning_numerical_ir","text":"list containing two elements: woefeature numeric vector Weight Evidence (WoE) values observation. woebin data frame following columns: bin: Character vector bin ranges. woe: Numeric vector WoE values bin. iv: Numeric vector Information Value (IV) bin. count: Integer vector total observations bin. count_pos: Integer vector positive target observations bin. count_neg: Integer vector negative target observations bin.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ir.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using Isotonic Regression — optimal_binning_numerical_ir","text":"Optimal Binning algorithm numerical variables using isotonic regression works follows: Create initial bins using equal-frequency binning. Merge low-frequency bins (proportion less bin_cutoff). Ensure number bins min_bins max_bins splitting merging bins. Apply isotonic regression smooth positive rates across bins. Calculate Weight Evidence (WoE) Information Value (IV) bin. Weight Evidence (WoE) calculated bin : $$WoE_i = \\ln\\left(\\frac{P(X_i|Y=1)}{P(X_i|Y=0)}\\right)$$ \\(P(X_i|Y=1)\\) proportion positive cases bin , \\(P(X_i|Y=0)\\) proportion negative cases bin . Information Value (IV) bin calculated : $$IV_i = (P(X_i|Y=1) - P(X_i|Y=0)) * WoE_i$$ algorithm aims create monotonic bins maximize predictive power numerical variable adhering specified constraints. Isotonic regression ensures positive rates non-decreasing across bins, particularly useful credit scoring risk modeling applications. implementation uses OpenMP parallel processing available, can significantly speed computation large datasets.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ir.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using Isotonic Regression — optimal_binning_numerical_ir","text":"Barlow, R. E., Bartholomew, D. J., Bremner, J. M., & Brunk, H. D. (1972). Statistical inference order restrictions: theory application isotonic regression. Wiley. Mironchyk, P., & Tchistiakov, V. (2017). Monotone optimal binning algorithm credit risk modeling. SSRN Electronic Journal. DOI: 10.2139/ssrn.2978774","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ir.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Numerical Variables using Isotonic Regression — optimal_binning_numerical_ir","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ir.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using Isotonic Regression — optimal_binning_numerical_ir","text":"","code":"if (FALSE) { # \\dontrun{ # Create sample data set.seed(123) n <- 1000 target <- sample(0:1, n, replace = TRUE) feature <- rnorm(n) # Run optimal binning result <- optimal_binning_numerical_ir(target, feature, min_bins = 2, max_bins = 4) # Print results print(result$woebin) # Plot WoE values plot(result$woebin$woe, type = \"s\", xaxt = \"n\", xlab = \"Bins\", ylab = \"WoE\",      main = \"Weight of Evidence by Bin\") axis(1, at = 1:nrow(result$woebin), labels = result$woebin$bin) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_jnbo.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using Dynamic Programming — optimal_binning_numerical_jnbo","title":"Optimal Binning for Numerical Variables using Dynamic Programming — optimal_binning_numerical_jnbo","text":"function implements optimal binning algorithm numerical variables using dynamic programming. aims find best binning strategy maximizes Information Value (IV) respecting specified constraints.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_jnbo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using Dynamic Programming — optimal_binning_numerical_jnbo","text":"","code":"optimal_binning_numerical_jnbo(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_jnbo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using Dynamic Programming — optimal_binning_numerical_jnbo","text":"target integer vector binary target values (0 1). feature numeric vector feature values binned. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum fraction total observations bin (default: 0.05). max_n_prebins Maximum number pre-bins (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_jnbo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using Dynamic Programming — optimal_binning_numerical_jnbo","text":"list containing: woefeature numeric vector Weight Evidence (WoE) values observation woebin data frame binning information, including bin ranges, WoE, IV, counts total_iv total Information Value binning","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_jnbo.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using Dynamic Programming — optimal_binning_numerical_jnbo","text":"optimal binning algorithm uses dynamic programming find best binning strategy maximizes Information Value (IV) respecting specified constraints. algorithm consists several steps: Pre-binning: feature initially divided maximum number bins specified max_n_prebins. Merging rare bins: Bins fraction observations less bin_cutoff merged adjacent bins. Dynamic programming optimization: algorithm uses dynamic programming find optimal binning strategy maximizes total IV. Weight Evidence (WoE) bin calculated : $$WoE = \\ln\\left(\\frac{P(X|Y=1)}{P(X|Y=0)}\\right)$$ \\(P(X|Y=1)\\) probability feature particular bin given positive target, \\(P(X|Y=0)\\) probability given negative target. Information Value (IV) bin calculated : $$IV = (P(X|Y=1) - P(X|Y=0)) \\times WoE$$ total IV sum IVs bins: $$\\text{Total IV} = \\sum_{=1}^{n} IV_i$$ dynamic programming approach ensures global optimum found within constraints minimum maximum number bins.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_jnbo.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using Dynamic Programming — optimal_binning_numerical_jnbo","text":"Belotti, P., & Carrasco, M. (2016). Optimal Binning: Mathematical Programming Formulation Solution Approach. arXiv preprint arXiv:1605.05710. Gutiérrez, P. ., Pérez-Ortiz, M., Sánchez-Monedero, J., Fernández-Navarro, F., & Hervás-Martínez, C. (2016). Ordinal regression methods: survey experimental study. IEEE Transactions Knowledge Data Engineering, 28(1), 127-146.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_jnbo.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Numerical Variables using Dynamic Programming — optimal_binning_numerical_jnbo","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_jnbo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using Dynamic Programming — optimal_binning_numerical_jnbo","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(123) target <- sample(0:1, 1000, replace = TRUE) feature <- rnorm(1000) result <- optimal_binning_numerical_jnbo(target, feature) print(result$woebin) print(result$total_iv) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_kmb.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using K-means Binning (KMB) — optimal_binning_numerical_kmb","title":"Optimal Binning for Numerical Variables using K-means Binning (KMB) — optimal_binning_numerical_kmb","text":"function implements K-means Binning (KMB) algorithm optimal binning numerical variables.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_kmb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using K-means Binning (KMB) — optimal_binning_numerical_kmb","text":"","code":"optimal_binning_numerical_kmb(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_kmb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using K-means Binning (KMB) — optimal_binning_numerical_kmb","text":"target integer vector binary target values (0 1). feature numeric vector feature values binned. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum frequency bin (default: 0.05). max_n_prebins Maximum number pre-bins (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_kmb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using K-means Binning (KMB) — optimal_binning_numerical_kmb","text":"list containing two elements: woefeature numeric vector Weight Evidence (WoE) transformed feature values. woebin data frame containing bin information, including bin labels, WoE, Information Value (IV), counts.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_kmb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using K-means Binning (KMB) — optimal_binning_numerical_kmb","text":"K-means Binning (KMB) algorithm advanced method optimal binning numerical variables. combines elements k-means clustering traditional binning techniques create bins maximize predictive power feature respecting user-defined constraints. algorithm works several steps: Initial Binning: Creates initial bins based unique values feature, respecting max_n_prebins constraint. Data Assignment: Assigns data points appropriate bins. Low Frequency Merging: Merges bins frequencies bin_cutoff threshold. Bin Count Adjustment: Adjusts number bins fall within specified range (min_bins max_bins). Statistics Calculation: Computes Weight Evidence (WoE) Information Value (IV) bin. KMB method uses modified version Weight Evidence (WoE) calculation incorporates Laplace smoothing handle cases zero counts: $$WoE_i = \\ln\\left(\\frac{(n_{1i} + 0.5) / (N_1 + 1)}{(n_{0i} + 0.5) / (N_0 + 1)}\\right)$$ \\(n_{1i}\\) \\(n_{0i}\\) number events non-events bin , \\(N_1\\) \\(N_0\\) total number events non-events. Information Value (IV) bin calculated : $$IV_i = \\left(\\frac{n_{1i}}{N_1} - \\frac{n_{0i}}{N_0}\\right) \\times WoE_i$$ KMB method aims create bins maximize overall IV respecting user-defined constraints. uses greedy approach merge bins necessary, choosing merge bins smallest difference IV. adjusting number bins, algorithm either merges bins similar IVs (many bins) splits bin largest range (bins). KMB method provides balance predictive power model interpretability, allowing users control trade-parameters min_bins, max_bins, bin_cutoff.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_kmb.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using K-means Binning (KMB) — optimal_binning_numerical_kmb","text":"Fayyad, U., & Irani, K. (1993). Multi-interval discretization continuous-valued attributes classification learning. Proceedings 13th International Joint Conference Artificial Intelligence (pp. 1022-1027). Thomas, L. C., Edelman, D. B., & Crook, J. N. (2002). Credit Scoring Applications. SIAM Monographs Mathematical Modeling Computation.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_kmb.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Numerical Variables using K-means Binning (KMB) — optimal_binning_numerical_kmb","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_kmb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using K-means Binning (KMB) — optimal_binning_numerical_kmb","text":"","code":"if (FALSE) { # \\dontrun{ # Create sample data set.seed(123) target <- sample(0:1, 1000, replace = TRUE) feature <- rnorm(1000)  # Run optimal binning result <- optimal_binning_numerical_kmb(target, feature)  # View results head(result$woefeature) print(result$woebin) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ldb.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using Local Density Binning (LDB) — optimal_binning_numerical_ldb","title":"Optimal Binning for Numerical Variables using Local Density Binning (LDB) — optimal_binning_numerical_ldb","text":"function implements Local Density Binning (LDB) algorithm optimal binning numerical variables.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ldb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using Local Density Binning (LDB) — optimal_binning_numerical_ldb","text":"","code":"optimal_binning_numerical_ldb(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ldb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using Local Density Binning (LDB) — optimal_binning_numerical_ldb","text":"target integer vector binary target values (0 1). feature numeric vector feature values binned. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum frequency bin (default: 0.05). max_n_prebins Maximum number pre-bins (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ldb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using Local Density Binning (LDB) — optimal_binning_numerical_ldb","text":"list containing three elements: woefeature numeric vector Weight Evidence (WoE) transformed feature values. woebin data frame containing bin information, including bin labels, WoE, Information Value (IV), counts. iv_total total Information Value binned feature.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ldb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using Local Density Binning (LDB) — optimal_binning_numerical_ldb","text":"Local Density Binning (LDB) algorithm advanced method optimal binning numerical variables. aims create bins maximize predictive power feature maintaining monotonicity Weight Evidence (WoE) values respecting user-defined constraints. algorithm works several steps: Pre-binning: Initially divides feature large number bins (max_n_prebins) using quantiles. WoE IV Calculation: bin, computes Weight Evidence (WoE) Information Value (IV): $$WoE_i = \\ln\\left(\\frac{P(X_i|Y=1)}{P(X_i|Y=0)}\\right) = \\ln\\left(\\frac{n_{1i}/N_1}{n_{0i}/N_0}\\right)$$ $$IV_i = (P(X_i|Y=1) - P(X_i|Y=0)) \\times WoE_i$$ \\(n_{1i}\\) \\(n_{0i}\\) number events non-events bin , \\(N_1\\) \\(N_0\\) total number events non-events. Monotonicity Enforcement: Merges adjacent bins ensure monotonic WoE values. direction monotonicity determined overall trend WoE values across bins. Bin Merging: Merges bins frequencies bin_cutoff threshold ensures number bins within specified range (min_bins max_bins). LDB method incorporates local density estimation better capture underlying distribution data. approach can particularly effective dealing complex, non-linear relationships feature target variable. algorithm uses Information Value (IV) criterion merging bins, aiming minimize IV loss step. approach helps preserve predictive power feature creating optimal bins. total Information Value (IV) calculated sum IVs bins: $$IV_{total} = \\sum_{=1}^{n} IV_i$$ LDB method provides balance predictive power model interpretability, allowing users control trade-parameters min_bins, max_bins, bin_cutoff.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ldb.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using Local Density Binning (LDB) — optimal_binning_numerical_ldb","text":"Belotti, P., Bonami, P., Fischetti, M., Lodi, ., Monaci, M., Nogales-Gomez, ., & Salvagnin, D. (2016). handling indicator constraints mixed integer programming. Computational Optimization Applications, 65(3), 545-566. Thomas, L. C., Edelman, D. B., & Crook, J. N. (2002). Credit Scoring Applications. SIAM Monographs Mathematical Modeling Computation.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ldb.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Numerical Variables using Local Density Binning (LDB) — optimal_binning_numerical_ldb","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ldb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using Local Density Binning (LDB) — optimal_binning_numerical_ldb","text":"","code":"if (FALSE) { # \\dontrun{ # Create sample data set.seed(123) target <- sample(0:1, 1000, replace = TRUE) feature <- rnorm(1000)  # Run optimal binning result <- optimal_binning_numerical_ldb(target, feature)  # View results head(result$woefeature) print(result$woebin) print(result$iv_total) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_lpdb.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using Local Polynomial Density Binning (LPDB) — optimal_binning_numerical_lpdb","title":"Optimal Binning for Numerical Variables using Local Polynomial Density Binning (LPDB) — optimal_binning_numerical_lpdb","text":"function implements Local Polynomial Density Binning (LPDB) algorithm optimal binning numerical variables.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_lpdb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using Local Polynomial Density Binning (LPDB) — optimal_binning_numerical_lpdb","text":"","code":"optimal_binning_numerical_lpdb(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_lpdb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using Local Polynomial Density Binning (LPDB) — optimal_binning_numerical_lpdb","text":"target integer vector binary target values (0 1). feature numeric vector feature values binned. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum frequency bin (default: 0.05). max_n_prebins Maximum number pre-bins (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_lpdb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using Local Polynomial Density Binning (LPDB) — optimal_binning_numerical_lpdb","text":"list containing two elements: woefeature numeric vector Weight Evidence (WoE) transformed feature values. woebin data frame containing bin information, including bin labels, WoE, Information Value (IV), counts.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_lpdb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using Local Polynomial Density Binning (LPDB) — optimal_binning_numerical_lpdb","text":"Local Polynomial Density Binning (LPDB) algorithm advanced method optimal binning numerical variables. aims create bins maximize predictive power feature maintaining monotonicity Weight Evidence (WoE) values respecting user-defined constraints. algorithm works several steps: Pre-binning: Initially divides feature large number bins (max_n_prebins) using quantiles. Merging rare bins: Combines bins frequencies bin_cutoff threshold ensure statistical significance. Enforcing monotonicity: Merges adjacent bins ensure monotonic WoE values. direction monotonicity determined correlation bin means WoE values. Respecting bin constraints: Ensures final number bins min_bins max_bins. algorithm uses Weight Evidence (WoE) Information Value (IV) key metrics: WoE calculated : $$WoE = \\ln\\left(\\frac{\\text{\\% positive cases}}{\\text{\\% negative cases}}\\right)$$ IV calculated : $$IV = (\\text{\\% positive cases} - \\text{\\% negative cases}) \\times WoE$$ LPDB method incorporates local polynomial density estimation better capture underlying distribution data. approach can particularly effective dealing complex, non-linear relationships feature target variable. algorithm uses correlation-based approach determine direction monotonicity: $$\\rho = \\frac{\\sum_{=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{=1}^{n} (x_i - \\bar{x})^2 \\sum_{=1}^{n} (y_i - \\bar{y})^2}}$$ \\(x_i\\) bin means \\(y_i\\) corresponding WoE values. binning process iteratively merges adjacent bins smallest WoE difference monotonicity achieved minimum number bins reached. approach ensures resulting bins monotonic WoE values, often desirable credit scoring risk modeling applications. LPDB method provides balance predictive power model interpretability, allowing users control trade-parameters min_bins, max_bins, bin_cutoff.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_lpdb.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using Local Polynomial Density Binning (LPDB) — optimal_binning_numerical_lpdb","text":"Belotti, P., & Bonami, P. (2013). Two-Phase Local Search Method Nonconvex Mixed-Integer Quadratic Programming. Journal Global Optimization, 57(1), 121-141. Thomas, L. C., Edelman, D. B., & Crook, J. N. (2002). Credit Scoring Applications. SIAM Monographs Mathematical Modeling Computation.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_lpdb.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Numerical Variables using Local Polynomial Density Binning (LPDB) — optimal_binning_numerical_lpdb","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_lpdb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using Local Polynomial Density Binning (LPDB) — optimal_binning_numerical_lpdb","text":"","code":"if (FALSE) { # \\dontrun{ # Create sample data set.seed(123) target <- sample(0:1, 1000, replace = TRUE) feature <- rnorm(1000)  # Run optimal binning result <- optimal_binning_numerical_lpdb(target, feature)  # View results head(result$woefeature) print(result$woebin) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mba.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using Modified Binning Algorithm (MBA) — optimal_binning_numerical_mba","title":"Optimal Binning for Numerical Variables using Modified Binning Algorithm (MBA) — optimal_binning_numerical_mba","text":"function implements optimal binning algorithm numerical variables using Modified Binning Algorithm (MBA) approach.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mba.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using Modified Binning Algorithm (MBA) — optimal_binning_numerical_mba","text":"","code":"optimal_binning_numerical_mba(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   n_threads = 1L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mba.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using Modified Binning Algorithm (MBA) — optimal_binning_numerical_mba","text":"target integer vector binary target values (0 1). feature numeric vector feature values binned. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum frequency bin (default: 0.05). max_n_prebins Maximum number pre-bins (default: 20). n_threads Number threads use parallel processing (default: 1).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mba.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using Modified Binning Algorithm (MBA) — optimal_binning_numerical_mba","text":"list containing two elements: woefeature numeric vector Weight Evidence (WoE) transformed feature values. woebin data frame containing bin information, including bin labels, WoE, Information Value (IV), counts.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mba.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using Modified Binning Algorithm (MBA) — optimal_binning_numerical_mba","text":"Modified Binning Algorithm (MBA) advanced method optimal binning numerical variables. aims create bins maximize predictive power feature maintaining monotonicity Weight Evidence (WoE) values respecting user-defined constraints. algorithm works several steps: Pre-binning: Initially divides feature large number bins (max_n_prebins) using quantiles. Merging rare bins: Combines bins frequencies bin_cutoff threshold. Monotonic binning: Merges adjacent bins ensure monotonic WoE values. Respecting bin constraints: Ensures final number bins min_bins max_bins. algorithm uses difference Weight Evidence (WoE) values criterion merging bins, aiming maintain monotonicity preserving predictive power feature. Weight Evidence (WoE) calculated : $$WoE = \\ln\\left(\\frac{\\text{\\% positive cases}}{\\text{\\% negative cases}}\\right)$$ Information Value (IV) calculated : $$IV = (\\text{\\% positive cases} - \\text{\\% negative cases}) \\times WoE$$ MBA method ensures resulting bins monotonic WoE values, often desirable credit scoring risk modeling applications. also provides flexibility terms number bins minimum bin frequency, allowing users balance predictive power model interpretability.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mba.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using Modified Binning Algorithm (MBA) — optimal_binning_numerical_mba","text":"Mironchyk, P., & Tchistiakov, V. (2017). Monotone optimal binning algorithm credit scoring modeling. arXiv preprint arXiv:1711.07139. Thomas, L. C., Edelman, D. B., & Crook, J. N. (2002). Credit scoring applications. SIAM.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mba.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Numerical Variables using Modified Binning Algorithm (MBA) — optimal_binning_numerical_mba","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mba.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using Modified Binning Algorithm (MBA) — optimal_binning_numerical_mba","text":"","code":"if (FALSE) { # \\dontrun{ # Create sample data set.seed(123) target <- sample(0:1, 1000, replace = TRUE) feature <- rnorm(1000)  # Run optimal binning result <- optimal_binning_numerical_mba(target, feature)  # View results head(result$woefeature) print(result$woebin) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mblp.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using Monotonic Binning via Linear Programming (MBLP) — optimal_binning_numerical_mblp","title":"Optimal Binning for Numerical Variables using Monotonic Binning via Linear Programming (MBLP) — optimal_binning_numerical_mblp","text":"function implements optimal binning algorithm numerical variables using Monotonic Binning via Linear Programming (MBLP).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mblp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using Monotonic Binning via Linear Programming (MBLP) — optimal_binning_numerical_mblp","text":"","code":"optimal_binning_numerical_mblp(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mblp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using Monotonic Binning via Linear Programming (MBLP) — optimal_binning_numerical_mblp","text":"target integer vector binary target values (0 1). feature numeric vector feature values binned. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum frequency bin (default: 0.05). max_n_prebins Maximum number pre-bins (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mblp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using Monotonic Binning via Linear Programming (MBLP) — optimal_binning_numerical_mblp","text":"list containing two elements: woefeature numeric vector Weight Evidence (WoE) transformed feature values. woebin data frame containing bin information, including bin labels, WoE, Information Value (IV), counts.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mblp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using Monotonic Binning via Linear Programming (MBLP) — optimal_binning_numerical_mblp","text":"Monotonic Binning via Linear Programming (MBLP) algorithm advanced method optimal binning numerical variables. aims create bins maximize predictive power feature maintaining monotonicity Weight Evidence (WoE) values. algorithm works several steps: Pre-binning: Initially divides feature large number bins (max_n_prebins). Merging rare bins: Combines bins frequencies bin_cutoff threshold. Enforcing monotonicity: Merges adjacent bins ensure monotonic WoE values. Respecting bin constraints: Ensures final number bins min_bins max_bins. algorithm uses Information Value (IV) criterion merging bins, aiming minimize IV loss step. approach helps preserve predictive power feature creating optimal bins. Weight Evidence (WoE) calculated : $$WoE = \\ln\\left(\\frac{\\text{\\% positive cases}}{\\text{\\% negative cases}}\\right)$$ Information Value (IV) calculated : $$IV = (\\text{\\% positive cases} - \\text{\\% negative cases}) \\times WoE$$ MBLP method ensures resulting bins monotonic WoE values, often desirable credit scoring risk modeling applications.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mblp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using Monotonic Binning via Linear Programming (MBLP) — optimal_binning_numerical_mblp","text":"Belotti, P., Bonami, P., Fischetti, M., Lodi, ., Monaci, M., Nogales-Gomez, ., & Salvagnin, D. (2016). handling indicator constraints mixed integer programming. Computational Optimization Applications, 65(3), 545-566. Mironchyk, P., & Tchistiakov, V. (2017). Monotone optimal binning algorithm credit scoring modeling. arXiv preprint arXiv:1711.07139.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mblp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Numerical Variables using Monotonic Binning via Linear Programming (MBLP) — optimal_binning_numerical_mblp","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mblp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using Monotonic Binning via Linear Programming (MBLP) — optimal_binning_numerical_mblp","text":"","code":"if (FALSE) { # \\dontrun{ # Create sample data set.seed(123) target <- sample(0:1, 1000, replace = TRUE) feature <- rnorm(1000)  # Run optimal binning result <- optimal_binning_numerical_mblp(target, feature)  # View results head(result$woefeature) print(result$woebin) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mdlp.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using MDLP — optimal_binning_numerical_mdlp","title":"Optimal Binning for Numerical Variables using MDLP — optimal_binning_numerical_mdlp","text":"function performs optimal binning numerical variables using Minimum Description Length Principle (MDLP). creates optimal bins numerical feature based relationship binary target variable, maximizing predictive power respecting user-defined constraints.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mdlp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using MDLP — optimal_binning_numerical_mdlp","text":"","code":"optimal_binning_numerical_mdlp(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mdlp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using MDLP — optimal_binning_numerical_mdlp","text":"target integer vector binary target values (0 1). feature numeric vector feature values. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum proportion total observations bin avoid merged (default: 0.05). max_n_prebins Maximum number pre-bins optimization process (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mdlp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using MDLP — optimal_binning_numerical_mdlp","text":"list containing two elements: woefeature numeric vector Weight Evidence (WoE) values observation. woebin data frame following columns: bin: Character vector bin ranges. woe: Numeric vector WoE values bin. iv: Numeric vector Information Value (IV) bin. count: Integer vector total observations bin. count_pos: Integer vector positive target observations bin. count_neg: Integer vector negative target observations bin.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mdlp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using MDLP — optimal_binning_numerical_mdlp","text":"Optimal Binning algorithm numerical variables using MDLP works follows: Create initial bins using equal-frequency binning. Apply MDLP algorithm merge bins: Calculate current MDL cost. pair adjacent bins, calculate MDL cost merged. Merge pair lowest MDL cost. Repeat merging reduces MDL cost minimum number bins reached. Merge rare bins (proportion less bin_cutoff). Calculate Weight Evidence (WoE) Information Value (IV) bin: $$WoE = \\ln\\left(\\frac{\\text{Positive Rate}}{\\text{Negative Rate}}\\right)$$ $$IV = (\\text{Positive Rate} - \\text{Negative Rate}) \\times WoE$$ MDLP algorithm aims find optimal trade-model complexity (number bins) goodness fit. uses principle minimum description length, states best model one provides shortest description data. MDL cost calculated : $$MDL = \\log_2(k - 1) + n \\times H(S) - \\sum_{=1}^k n_i \\times H(S_i)$$ k number bins, n total number instances, H(S) entropy entire dataset, H(S_i) entropy -th bin. implementation uses OpenMP parallel processing available, can significantly speed computation large datasets.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mdlp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using MDLP — optimal_binning_numerical_mdlp","text":"Fayyad, U. M., & Irani, K. B. (1993). Multi-interval discretization continuous-valued attributes classification learning. Proceedings 13th International Joint Conference Artificial Intelligence (pp. 1022-1027). Rissanen, J. (1978). Modeling shortest data description. Automatica, 14(5), 465-471.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mdlp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Numerical Variables using MDLP — optimal_binning_numerical_mdlp","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mdlp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using MDLP — optimal_binning_numerical_mdlp","text":"","code":"if (FALSE) { # \\dontrun{ # Create sample data set.seed(123) n <- 1000 target <- sample(0:1, n, replace = TRUE) feature <- rnorm(n)  # Run optimal binning result <- optimal_binning_numerical_mdlp(target, feature, min_bins = 2, max_bins = 4)  # Print results print(result$woebin)  # Plot WoE values plot(result$woebin$woe, type = \"s\", xaxt = \"n\", xlab = \"Bins\", ylab = \"WoE\",      main = \"Weight of Evidence by Bin\") axis(1, at = 1:nrow(result$woebin), labels = result$woebin$bin) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_milp.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using MILP — optimal_binning_numerical_milp","title":"Optimal Binning for Numerical Variables using MILP — optimal_binning_numerical_milp","text":"function performs optimal binning numerical variables using Mixed Integer Linear Programming (MILP) inspired approach. creates optimal bins numerical feature based relationship binary target variable, maximizing predictive power respecting user-defined constraints.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_milp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using MILP — optimal_binning_numerical_milp","text":"","code":"optimal_binning_numerical_milp(target, feature, min_bins = 3, max_bins = 5,                                bin_cutoff = 0.05, max_n_prebins = 20, n_threads = 1)"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_milp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using MILP — optimal_binning_numerical_milp","text":"target integer vector binary target values (0 1). feature numeric vector feature values. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum proportion total observations bin avoid merged (default: 0.05). max_n_prebins Maximum number pre-bins optimization process (default: 20). n_threads Number threads use parallel processing (default: 1).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_milp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using MILP — optimal_binning_numerical_milp","text":"list containing two elements: woefeature numeric vector Weight Evidence (WoE) values observation. woebin data frame following columns: bin: Character vector bin ranges. woe: Numeric vector WoE values bin. iv: Numeric vector Information Value (IV) bin. count: Integer vector total observations bin. count_pos: Integer vector positive target observations bin. count_neg: Integer vector negative target observations bin.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_milp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using MILP — optimal_binning_numerical_milp","text":"Optimal Binning algorithm numerical variables using MILP-inspired approach works follows: Create initial pre-bins using equal-frequency binning. Merge bins counts cutoff. Calculate initial Weight Evidence (WoE) Information Value (IV) bin. Enforce monotonicity WoE values across bins. Merge bins meet max_bins constraint. Split bins necessary meet min_bins constraint. Recalculate WoE IV final bins. algorithm aims create bins maximize predictive power numerical variable adhering specified constraints. enforces monotonicity WoE values, particularly useful credit scoring risk modeling applications. Weight Evidence (WoE) calculated : $$WoE = \\ln(\\frac{\\text{Positive Rate}}{\\text{Negative Rate}})$$ Information Value (IV) calculated : $$IV = (\\text{Positive Rate} - \\text{Negative Rate}) \\times WoE$$ implementation uses OpenMP parallel processing available, can significantly speed computation large datasets.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_milp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using MILP — optimal_binning_numerical_milp","text":"Belotti, P., Kirches, C., Leyffer, S., Linderoth, J., Luedtke, J., & Mahajan, . (2013). Mixed-integer nonlinear optimization. Acta Numerica, 22, 1-131. Mironchyk, P., & Tchistiakov, V. (2017). Monotone optimal binning algorithm credit risk modeling. SSRN Electronic Journal. doi:10.2139/ssrn.2978774","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_milp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Numerical Variables using MILP — optimal_binning_numerical_milp","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_milp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using MILP — optimal_binning_numerical_milp","text":"","code":"if (FALSE) { # \\dontrun{ # Create sample data set.seed(123) n <- 1000 target <- sample(0:1, n, replace = TRUE) feature <- rnorm(n)  # Run optimal binning result <- optimal_binning_numerical_milp(target, feature, min_bins = 2, max_bins = 4)  # Print results print(result$woebin)  # Plot WoE values plot(result$woebin$woe, type = \"s\", xaxt = \"n\", xlab = \"Bins\", ylab = \"WoE\",      main = \"Weight of Evidence by Bin\") axis(1, at = 1:nrow(result$woebin), labels = result$woebin$bin, las = 2) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mob.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using Monotonic Optimal Binning (MOB) — optimal_binning_numerical_mob","title":"Optimal Binning for Numerical Variables using Monotonic Optimal Binning (MOB) — optimal_binning_numerical_mob","text":"function performs optimal binning numerical variables using Monotonic Optimal Binning (MOB) approach. creates optimal bins numerical feature based relationship binary target variable, maximizing predictive power respecting user-defined constraints enforcing monotonicity.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mob.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using Monotonic Optimal Binning (MOB) — optimal_binning_numerical_mob","text":"","code":"optimal_binning_numerical_mob(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mob.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using Monotonic Optimal Binning (MOB) — optimal_binning_numerical_mob","text":"target integer vector binary target values (0 1). feature numeric vector feature values. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum proportion total observations bin avoid merged (default: 0.05). max_n_prebins Maximum number pre-bins optimization process (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mob.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using Monotonic Optimal Binning (MOB) — optimal_binning_numerical_mob","text":"list containing two elements: woefeature numeric vector Weight Evidence (WoE) values observation. woebin data frame following columns: bin: Character vector bin ranges. woe: Numeric vector WoE values bin. iv: Numeric vector Information Value (IV) bin. count: Integer vector total observations bin. count_pos: Integer vector positive target observations bin. count_neg: Integer vector negative target observations bin.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mob.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using Monotonic Optimal Binning (MOB) — optimal_binning_numerical_mob","text":"Monotonic Optimal Binning (MOB) algorithm numerical variables works follows: Create initial pre-bins using equal-frequency binning. Calculate initial Weight Evidence (WoE) Information Value (IV) bin. Merge bins enforce monotonicity respect bin_cutoff constraint. merge bins necessary meet max_bins constraint. Split bins necessary meet min_bins constraint. Recalculate WoE IV final bins. algorithm aims create bins maximize predictive power numerical variable adhering specified constraints. enforces monotonicity WoE values, particularly useful credit scoring risk modeling applications. Weight Evidence (WoE) calculated : $$WoE = \\ln(\\frac{\\text{Positive Rate}}{\\text{Negative Rate}})$$ Information Value (IV) calculated : $$IV = (\\text{Positive Rate} - \\text{Negative Rate}) \\times WoE$$ implementation uses OpenMP parallel processing available, can significantly speed computation large datasets.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mob.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using Monotonic Optimal Binning (MOB) — optimal_binning_numerical_mob","text":"Mironchyk, P., & Tchistiakov, V. (2017). Monotone optimal binning algorithm credit risk modeling. SSRN Electronic Journal. doi:10.2139/ssrn.2978774 Belotti, P., Kirches, C., Leyffer, S., Linderoth, J., Luedtke, J., & Mahajan, . (2013). Mixed-integer nonlinear optimization. Acta Numerica, 22, 1-131.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mob.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Numerical Variables using Monotonic Optimal Binning (MOB) — optimal_binning_numerical_mob","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mob.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using Monotonic Optimal Binning (MOB) — optimal_binning_numerical_mob","text":"","code":"if (FALSE) { # \\dontrun{ # Create sample data set.seed(123) n <- 1000 target <- sample(0:1, n, replace = TRUE) feature <- rnorm(n)  # Run optimal binning result <- optimal_binning_numerical_mob(target, feature, min_bins = 2, max_bins = 4)  # Print results print(result$woebin)  # Plot WoE values plot(result$woebin$woe, type = \"s\", xaxt = \"n\", xlab = \"Bins\", ylab = \"WoE\",      main = \"Weight of Evidence by Bin\") axis(1, at = 1:nrow(result$woebin), labels = result$woebin$bin, las = 2) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mrblp.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using Monotonic Risk Binning with Likelihood Ratio Pre-binning (MRBLP) — optimal_binning_numerical_mrblp","title":"Optimal Binning for Numerical Variables using Monotonic Risk Binning with Likelihood Ratio Pre-binning (MRBLP) — optimal_binning_numerical_mrblp","text":"function implements optimal binning algorithm numerical variables using Monotonic Risk Binning Likelihood Ratio Pre-binning (MRBLP). transforms continuous feature discrete bins preserving monotonic relationship target variable maximizing predictive power.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mrblp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using Monotonic Risk Binning with Likelihood Ratio Pre-binning (MRBLP) — optimal_binning_numerical_mrblp","text":"","code":"optimal_binning_numerical_mrblp(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   n_threads = 1L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mrblp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using Monotonic Risk Binning with Likelihood Ratio Pre-binning (MRBLP) — optimal_binning_numerical_mrblp","text":"target integer vector binary target values (0 1). feature numeric vector continuous feature binned. min_bins Integer. minimum number bins create (default: 3). max_bins Integer. maximum number bins create (default: 5). bin_cutoff Numeric. minimum proportion observations bin (default: 0.05). max_n_prebins Integer. maximum number pre-bins create initial binning step (default: 20). n_threads Integer. number threads use parallel processing (default: 1).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mrblp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using Monotonic Risk Binning with Likelihood Ratio Pre-binning (MRBLP) — optimal_binning_numerical_mrblp","text":"list containing two elements: woefeature numeric vector Weight Evidence (WoE) transformed values input feature. woebin data frame containing binning information, including bin boundaries, WoE values, Information Value (IV), count statistics.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mrblp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using Monotonic Risk Binning with Likelihood Ratio Pre-binning (MRBLP) — optimal_binning_numerical_mrblp","text":"MRBLP algorithm combines pre-binning, small bin merging, monotonic binning create optimal binning solution numerical variables. process involves following steps: Pre-binning: algorithm starts creating initial bins using equal-frequency binning. number pre-bins determined max_n_prebins parameter. Small bin merging: Bins proportion observations less bin_cutoff merged adjacent bins ensure statistical significance. Monotonic binning: algorithm enforces monotonic relationship bin order Weight Evidence (WoE) values. step ensures binning preserves original relationship feature target variable. Bin count adjustment: number bins exceeds max_bins, algorithm merges bins smallest difference Information Value (IV). number bins less min_bins, largest bin split. Weight Evidence (WoE) bin calculated : $$WoE = \\ln\\left(\\frac{P(X|Y=1)}{P(X|Y=0)}\\right) = \\ln\\left(\\frac{\\frac{n_{1i}}{n_1}}{\\frac{n_{0i}}{n_0}}\\right)$$ \\(n_{1i}\\) \\(n_{0i}\\) number events non-events bin , respectively, \\(n_1\\) \\(n_0\\) total number events non-events. Information Value (IV) bin calculated : $$IV_i = \\left(\\frac{n_{1i}}{n_1} - \\frac{n_{0i}}{n_0}\\right) \\times WoE_i$$ total Information Value binning solution sum IVs across bins: $$IV_{total} = \\sum_{=1}^{k} IV_i$$ k number bins. implementation uses OpenMP parallel processing improve performance multi-core systems.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mrblp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using Monotonic Risk Binning with Likelihood Ratio Pre-binning (MRBLP) — optimal_binning_numerical_mrblp","text":"Belcastro, L., Marozzo, F., Talia, D., & Trunfio, P. (2020). \"Big Data Analytics Clouds.\" Handbook Big Data Technologies (pp. 101-142). Springer, Cham. Zeng, Y. (2014). \"Optimal Binning Scoring Modeling.\" Computational Economics, 44(1), 137-149.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mrblp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Numerical Variables using Monotonic Risk Binning with Likelihood Ratio Pre-binning (MRBLP) — optimal_binning_numerical_mrblp","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mrblp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using Monotonic Risk Binning with Likelihood Ratio Pre-binning (MRBLP) — optimal_binning_numerical_mrblp","text":"","code":"if (FALSE) { # \\dontrun{ # Generate sample data set.seed(42) n <- 10000 feature <- rnorm(n) target <- rbinom(n, 1, plogis(0.5 + 0.5 * feature))  # Run optimal binning result <- optimal_binning_numerical_mrblp(target, feature)  # View binning results print(result$woebin)  # Use WoE-transformed feature woe_feature <- result$woefeature } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_obnp.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using OBNP — optimal_binning_numerical_obnp","title":"Optimal Binning for Numerical Variables using OBNP — optimal_binning_numerical_obnp","text":"function performs optimal binning numerical variables using Optimal Binning Non-Parametric Transformations (OBNP) approach. creates optimal bins numerical feature based relationship binary target variable, maximizing predictive power respecting user-defined constraints enforcing monotonicity.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_obnp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using OBNP — optimal_binning_numerical_obnp","text":"","code":"optimal_binning_numerical_obnp(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_obnp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using OBNP — optimal_binning_numerical_obnp","text":"target numeric vector binary target values (0 1). feature numeric vector feature values. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum proportion total observations bin avoid merged (default: 0.05). max_n_prebins Maximum number pre-bins optimization process (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_obnp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using OBNP — optimal_binning_numerical_obnp","text":"list containing two elements: woefeature numeric vector Weight Evidence (WoE) values observation. woebin data frame following columns: bin: Character vector bin ranges. woe: Numeric vector WoE values bin. iv: Numeric vector Information Value (IV) bin. count: Numeric vector total observations bin. count_pos: Numeric vector positive target observations bin. count_neg: Numeric vector negative target observations bin.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_obnp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using OBNP — optimal_binning_numerical_obnp","text":"Optimal Binning Non-Parametric Transformations (OBNP) algorithm numerical variables works follows: Pre-bin feature max_n_prebins using quantiles. Determine monotonic trend (increasing decreasing) based correlation feature target. Optimize bins merging pre-bins, respecting monotonicity constraint parameters. Apply bin_cutoff merge bins low frequency. Ensure number bins min_bins max_bins. Compute Weight Evidence (WoE) Information Value (IV) bin. algorithm aims create bins maximize predictive power numerical variable adhering specified constraints. enforces monotonicity WoE values, particularly useful credit scoring risk modeling applications. Weight Evidence (WoE) calculated : $$WoE = \\ln(\\frac{\\text{Positive Rate}}{\\text{Negative Rate}})$$ Information Value (IV) calculated : $$IV = (\\text{Positive Rate} - \\text{Negative Rate}) \\times WoE$$ implementation uses OpenMP parallel processing available, can significantly speed computation large datasets.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_obnp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using OBNP — optimal_binning_numerical_obnp","text":"Mironchyk, P., & Tchistiakov, V. (2017). Monotone optimal binning algorithm credit risk modeling. SSRN Electronic Journal. doi:10.2139/ssrn.2978774 Bellotti, T., & Crook, J. (2012). Loss given default models incorporating macroeconomic variables credit cards. International Journal Forecasting, 28(1), 171-182.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_obnp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Numerical Variables using OBNP — optimal_binning_numerical_obnp","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_obnp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using OBNP — optimal_binning_numerical_obnp","text":"","code":"if (FALSE) { # \\dontrun{ # Create sample data set.seed(123) n <- 1000 target <- sample(0:1, n, replace = TRUE) feature <- rnorm(n)  # Run optimal binning result <- optimal_binning_numerical_obnp(target, feature, min_bins = 2, max_bins = 4)  # Print results print(result$woebin)  # Plot WoE values plot(result$woebin$woe, type = \"s\", xaxt = \"n\", xlab = \"Bins\", ylab = \"WoE\",      main = \"Weight of Evidence by Bin\") axis(1, at = 1:nrow(result$woebin), labels = result$woebin$bin, las = 2) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_oslp.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using OSLP — optimal_binning_numerical_oslp","title":"Optimal Binning for Numerical Variables using OSLP — optimal_binning_numerical_oslp","text":"function performs optimal binning numerical variables using Optimal Supervised Learning Partitioning (OSLP) approach. creates optimal bins numerical feature based relationship binary target variable, maximizing predictive power respecting user-defined constraints enforcing monotonicity.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_oslp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using OSLP — optimal_binning_numerical_oslp","text":"","code":"optimal_binning_numerical_oslp(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_oslp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using OSLP — optimal_binning_numerical_oslp","text":"target numeric vector binary target values (0 1). feature numeric vector feature values. min_bins Minimum number bins (default: 3, must >= 2). max_bins Maximum number bins (default: 5, must > min_bins). bin_cutoff Minimum proportion total observations bin avoid merged (default: 0.05, must (0, 1)). max_n_prebins Maximum number pre-bins optimization process (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_oslp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using OSLP — optimal_binning_numerical_oslp","text":"list containing two elements: woefeature numeric vector Weight Evidence (WoE) values observation. woebin data frame following columns: bin: Character vector bin ranges. woe: Numeric vector WoE values bin. iv: Numeric vector Information Value (IV) bin. count: Integer vector total observations bin. count_pos: Integer vector positive target observations bin. count_neg: Integer vector negative target observations bin.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_oslp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using OSLP — optimal_binning_numerical_oslp","text":"Optimal Supervised Learning Partitioning (OSLP) algorithm numerical variables works follows: Prebin data max_n_prebins using quantiles. Merge adjacent bins meet max_bins constraint bin_cutoff requirement. Calculate Weight Evidence (WoE) Information Value (IV) bin. Enforce monotonicity WoE values across bins. Recalculate IV values based monotonic WoE. algorithm aims create bins maximize predictive power numerical variable adhering specified constraints. enforces monotonicity WoE values, particularly useful credit scoring risk modeling applications. Weight Evidence (WoE) calculated : $$WoE = \\ln(\\frac{\\text{Positive Rate}}{\\text{Negative Rate}})$$ Information Value (IV) calculated : $$IV = (\\text{Positive Rate} - \\text{Negative Rate}) \\times WoE$$","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_oslp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using OSLP — optimal_binning_numerical_oslp","text":"Mironchyk, P., & Tchistiakov, V. (2017). Monotone optimal binning algorithm credit risk modeling. SSRN Electronic Journal. doi:10.2139/ssrn.2978774 Thomas, L. C. (2009). Consumer credit models: Pricing, profit portfolios. Oxford University Press.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_oslp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Numerical Variables using OSLP — optimal_binning_numerical_oslp","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_oslp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using OSLP — optimal_binning_numerical_oslp","text":"","code":"if (FALSE) { # \\dontrun{ # Create sample data set.seed(123) n <- 1000 target <- sample(0:1, n, replace = TRUE) feature <- rnorm(n)  # Run optimal binning result <- optimal_binning_numerical_oslp(target, feature, min_bins = 2, max_bins = 4)  # Print results print(result$woebin)  # Plot WoE values plot(result$woebin$woe, type = \"s\", xaxt = \"n\", xlab = \"Bins\", ylab = \"WoE\",      main = \"Weight of Evidence by Bin\") axis(1, at = 1:nrow(result$woebin), labels = result$woebin$bin, las = 2) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_plaob.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using PLAOB — optimal_binning_numerical_plaob","title":"Optimal Binning for Numerical Variables using PLAOB — optimal_binning_numerical_plaob","text":"function performs optimal binning numerical variables using Piecewise Linear Approximation Optimal Binning (PLAOB) approach. creates optimal bins numerical feature based relationship binary target variable, maximizing predictive power respecting user-defined constraints enforcing monotonicity.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_plaob.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using PLAOB — optimal_binning_numerical_plaob","text":"","code":"optimal_binning_numerical_plaob(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_plaob.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using PLAOB — optimal_binning_numerical_plaob","text":"target integer vector binary target values (0 1). feature numeric vector feature values. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum proportion total observations bin avoid merged (default: 0.05). max_n_prebins Maximum number pre-bins optimization process (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_plaob.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using PLAOB — optimal_binning_numerical_plaob","text":"list containing two elements: woefeature numeric vector Weight Evidence (WoE) values observation. woebin data frame following columns: bin: Character vector bin ranges. woe: Numeric vector WoE values bin. iv: Numeric vector Information Value (IV) bin. count: Integer vector total observations bin. count_pos: Integer vector positive target observations bin. count_neg: Integer vector negative target observations bin.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_plaob.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using PLAOB — optimal_binning_numerical_plaob","text":"Piecewise Linear Approximation Optimal Binning (PLAOB) algorithm numerical variables works follows: Create initial bins using equal-frequency binning. Merge low-frequency bins meet bin_cutoff requirement. Iteratively refine binning: Calculate Weight Evidence (WoE) Information Value (IV) bin. Enforce monotonicity WoE values across bins. Ensure number bins min_bins max_bins. Adjust bin boundaries maximize total IV. Repeat refinement process convergence maximum number iterations reached. algorithm aims create bins maximize predictive power numerical variable adhering specified constraints. enforces monotonicity WoE values, particularly useful credit scoring risk modeling applications. Weight Evidence (WoE) calculated : $$WoE = \\ln(\\frac{\\text{Positive Rate}}{\\text{Negative Rate}})$$ Information Value (IV) calculated : $$IV = (\\text{Positive Rate} - \\text{Negative Rate}) \\times WoE$$ implementation uses OpenMP parallel processing available, can significantly speed computation large datasets.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_plaob.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using PLAOB — optimal_binning_numerical_plaob","text":"Mironchyk, P., & Tchistiakov, V. (2017). Monotone optimal binning algorithm credit risk modeling. SSRN Electronic Journal. DOI: 10.2139/ssrn.2978774 Kotsiantis, S., & Kanellopoulos, D. (2006). Discretization techniques: recent survey. GESTS International Transactions Computer Science Engineering, 32(1), 47-58.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_plaob.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Numerical Variables using PLAOB — optimal_binning_numerical_plaob","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_plaob.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using PLAOB — optimal_binning_numerical_plaob","text":"","code":"if (FALSE) { # \\dontrun{ # Create sample data set.seed(123) n <- 1000 target <- sample(0:1, n, replace = TRUE) feature <- rnorm(n)  # Run optimal binning result <- optimal_binning_numerical_plaob(target, feature, min_bins = 2, max_bins = 4)  # Print results print(result$woebin)  # Plot WoE values plot(result$woebin$woe, type = \"s\", xaxt = \"n\", xlab = \"Bins\", ylab = \"WoE\",      main = \"Weight of Evidence by Bin\") axis(1, at = 1:nrow(result$woebin), labels = result$woebin$bin, las = 2) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_qb.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using Quantile-based Binning (QB) — optimal_binning_numerical_qb","title":"Optimal Binning for Numerical Variables using Quantile-based Binning (QB) — optimal_binning_numerical_qb","text":"function performs optimal binning numerical variables using Quantile-based Binning (QB) approach. creates optimal bins numerical feature based relationship binary target variable, maximizing predictive power respecting user-defined constraints enforcing monotonicity.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_qb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using Quantile-based Binning (QB) — optimal_binning_numerical_qb","text":"","code":"optimal_binning_numerical_qb(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_qb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using Quantile-based Binning (QB) — optimal_binning_numerical_qb","text":"target integer vector binary target values (0 1). feature numeric vector feature values. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum proportion total observations bin avoid merged (default: 0.05). max_n_prebins Maximum number pre-bins optimization process (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_qb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using Quantile-based Binning (QB) — optimal_binning_numerical_qb","text":"list containing two elements: woefeature numeric vector Weight Evidence (WoE) values observation. woebin data frame following columns: bin: Character vector bin ranges. woe: Numeric vector WoE values bin. iv: Numeric vector Information Value (IV) bin. count: Integer vector total observations bin. count_pos: Integer vector positive target observations bin. count_neg: Integer vector negative target observations bin.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_qb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using Quantile-based Binning (QB) — optimal_binning_numerical_qb","text":"Quantile-based Binning (QB) algorithm numerical variables works follows: Perform initial binning based quantiles feature distribution. Merge rare bins meet bin_cutoff requirement. Enforce monotonicity Weight Evidence (WoE) across bins. Ensure number bins min_bins max_bins. Calculate final WoE Information Value (IV) bin. algorithm aims create bins maximize predictive power numerical variable adhering specified constraints. enforces monotonicity WoE values, particularly useful credit scoring risk modeling applications. Weight Evidence (WoE) calculated : $$WoE = \\ln(\\frac{\\text{Positive Rate}}{\\text{Negative Rate}})$$ Information Value (IV) calculated : $$IV = (\\text{Positive Rate} - \\text{Negative Rate}) \\times WoE$$ implementation uses OpenMP parallel processing available, can significantly speed computation large datasets.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_qb.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using Quantile-based Binning (QB) — optimal_binning_numerical_qb","text":"Mironchyk, P., & Tchistiakov, V. (2017). Monotone optimal binning algorithm credit risk modeling. SSRN Electronic Journal. DOI: 10.2139/ssrn.2978774 Liu, X., & Wu, Y. (2019). Supervised Discretization Credit Scoring. Journal Credit Risk, 15(2), 55-87.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_qb.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Numerical Variables using Quantile-based Binning (QB) — optimal_binning_numerical_qb","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_qb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using Quantile-based Binning (QB) — optimal_binning_numerical_qb","text":"","code":"if (FALSE) { # \\dontrun{ # Create sample data set.seed(123) n <- 1000 target <- sample(0:1, n, replace = TRUE) feature <- rnorm(n)  # Run optimal binning result <- optimal_binning_numerical_qb(target, feature, min_bins = 2, max_bins = 4)  # Print results print(result$woebin)  # Plot WoE values plot(result$woebin$woe, type = \"s\", xaxt = \"n\", xlab = \"Bins\", ylab = \"WoE\",      main = \"Weight of Evidence by Bin\") axis(1, at = 1:nrow(result$woebin), labels = result$woebin$bin, las = 2) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_sab.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using Simulated Annealing Binning (SAB) — optimal_binning_numerical_sab","title":"Optimal Binning for Numerical Variables using Simulated Annealing Binning (SAB) — optimal_binning_numerical_sab","text":"function performs optimal binning numerical variables using Simulated Annealing Binning (SAB) approach. creates optimal bins numerical feature based relationship binary target variable, maximizing predictive power respecting user-defined constraints.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_sab.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using Simulated Annealing Binning (SAB) — optimal_binning_numerical_sab","text":"","code":"optimal_binning_numerical_sab(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_sab.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using Simulated Annealing Binning (SAB) — optimal_binning_numerical_sab","text":"target integer vector binary target values (0 1). feature numeric vector feature values. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum proportion total observations bin avoid merged (default: 0.05). max_n_prebins Maximum number pre-bins optimization process (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_sab.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using Simulated Annealing Binning (SAB) — optimal_binning_numerical_sab","text":"list containing two elements: woefeature numeric vector Weight Evidence (WoE) values observation. woebin data frame following columns: bin: Character vector bin ranges. woe: Numeric vector WoE values bin. iv: Numeric vector Information Value (IV) bin. count: Integer vector total observations bin. count_pos: Integer vector positive target observations bin. count_neg: Integer vector negative target observations bin.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_sab.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using Simulated Annealing Binning (SAB) — optimal_binning_numerical_sab","text":"Simulated Annealing Binning (SAB) algorithm numerical variables works follows: Perform initial pre-binning based quantiles. Use simulated annealing optimize bin cut points: Generate neighbor solutions adding, removing, modifying cut points. Accept reject new solutions based change Information Value (IV) current temperature. Gradually decrease temperature converge optimal solution. Merge low-frequency bins meet bin_cutoff requirement. Calculate final Weight Evidence (WoE) Information Value (IV) bin. algorithm aims create bins maximize predictive power numerical variable adhering specified constraints. Simulated annealing allows algorithm escape local optima potentially find globally optimal binning solution. Weight Evidence (WoE) calculated : $$WoE = \\ln(\\frac{\\text{Positive Rate}}{\\text{Negative Rate}})$$ Information Value (IV) calculated : $$IV = (\\text{Positive Rate} - \\text{Negative Rate}) \\times WoE$$ implementation uses OpenMP parallel processing available, can significantly speed computation large datasets.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_sab.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using Simulated Annealing Binning (SAB) — optimal_binning_numerical_sab","text":"Kirkpatrick, S., Gelatt, C. D., & Vecchi, M. P. (1983). Optimization simulated annealing. Science, 220(4598), 671-680. Mironchyk, P., & Tchistiakov, V. (2017). Monotone optimal binning algorithm credit risk modeling. SSRN Electronic Journal. DOI: 10.2139/ssrn.2978774","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_sab.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Numerical Variables using Simulated Annealing Binning (SAB) — optimal_binning_numerical_sab","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_sab.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using Simulated Annealing Binning (SAB) — optimal_binning_numerical_sab","text":"","code":"if (FALSE) { # \\dontrun{ # Create sample data set.seed(123) n <- 1000 target <- sample(0:1, n, replace = TRUE) feature <- rnorm(n)  # Run optimal binning result <- optimal_binning_numerical_sab(target, feature, min_bins = 2, max_bins = 4)  # Print results print(result$woebin)  # Plot WoE values plot(result$woebin$woe, type = \"s\", xaxt = \"n\", xlab = \"Bins\", ylab = \"WoE\",      main = \"Weight of Evidence by Bin\") axis(1, at = 1:nrow(result$woebin), labels = result$woebin$bin, las = 2) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_sbb.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using Supervised Boundary Binning (SBB) — optimal_binning_numerical_sbb","title":"Optimal Binning for Numerical Variables using Supervised Boundary Binning (SBB) — optimal_binning_numerical_sbb","text":"function implements optimal binning algorithm numerical variables using Supervised Boundary Binning (SBB). transforms continuous feature discrete bins preserving monotonic relationship target variable maximizing predictive power.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_sbb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using Supervised Boundary Binning (SBB) — optimal_binning_numerical_sbb","text":"","code":"optimal_binning_numerical_sbb(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_sbb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using Supervised Boundary Binning (SBB) — optimal_binning_numerical_sbb","text":"target integer vector binary target values (0 1). feature numeric vector continuous feature binned. min_bins Integer. minimum number bins create (default: 3). max_bins Integer. maximum number bins create (default: 5). bin_cutoff Numeric. minimum proportion observations bin (default: 0.05). max_n_prebins Integer. maximum number pre-bins create initial binning step (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_sbb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using Supervised Boundary Binning (SBB) — optimal_binning_numerical_sbb","text":"list containing two elements: woefeature numeric vector Weight Evidence (WoE) transformed values input feature. woebin data frame containing binning information, including bin boundaries, WoE values, Information Value (IV), count statistics.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_sbb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using Supervised Boundary Binning (SBB) — optimal_binning_numerical_sbb","text":"SBB algorithm combines pre-binning, small bin merging, monotonic binning create optimal binning solution numerical variables. process involves following steps: Pre-binning: algorithm starts creating initial bins using equal-frequency binning. number pre-bins determined max_n_prebins parameter. Small bin merging: Bins proportion observations less bin_cutoff merged adjacent bins ensure statistical significance. Monotonic binning: algorithm enforces monotonic relationship bin order Weight Evidence (WoE) values. step ensures binning preserves original relationship feature target variable. Bin count adjustment: number bins exceeds max_bins, algorithm merges bins smallest Information Value (IV). number bins less min_bins, smallest bins merged. Weight Evidence (WoE) bin calculated : $$WoE = \\ln\\left(\\frac{P(X|Y=1)}{P(X|Y=0)}\\right) = \\ln\\left(\\frac{\\frac{n_{1i}}{n_1}}{\\frac{n_{0i}}{n_0}}\\right)$$ \\(n_{1i}\\) \\(n_{0i}\\) number events non-events bin , respectively, \\(n_1\\) \\(n_0\\) total number events non-events. Information Value (IV) bin calculated : $$IV_i = \\left(\\frac{n_{1i}}{n_1} - \\frac{n_{0i}}{n_0}\\right) \\times WoE_i$$ total Information Value binning solution sum IVs across bins: $$IV_{total} = \\sum_{=1}^{k} IV_i$$ k number bins. implementation uses OpenMP parallel processing improve performance multi-core systems.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_sbb.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using Supervised Boundary Binning (SBB) — optimal_binning_numerical_sbb","text":"Mironchyk, P., & Tchistiakov, V. (2017). \"Monotone optimal binning algorithm credit risk modeling.\" arXiv preprint arXiv:1711.05095. Thomas, L. C. (2000). \"survey credit behavioural scoring: forecasting financial risk lending consumers.\" International journal forecasting, 16(2), 149-172.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_sbb.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Numerical Variables using Supervised Boundary Binning (SBB) — optimal_binning_numerical_sbb","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_sbb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using Supervised Boundary Binning (SBB) — optimal_binning_numerical_sbb","text":"","code":"if (FALSE) { # \\dontrun{ # Generate sample data set.seed(42) n <- 10000 feature <- rnorm(n) target <- rbinom(n, 1, plogis(0.5 + 0.5 * feature))  # Run optimal binning result <- optimal_binning_numerical_sbb(target, feature)  # View binning results print(result$woebin)  # Use WoE-transformed feature woe_feature <- result$woefeature } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_swb.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using Sliding Window Binning — optimal_binning_numerical_swb","title":"Optimal Binning for Numerical Variables using Sliding Window Binning — optimal_binning_numerical_swb","text":"function implements optimal binning algorithm numerical variables using Sliding Window Binning (SWB) approach Weight Evidence (WoE) Information Value (IV) criteria.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_swb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using Sliding Window Binning — optimal_binning_numerical_swb","text":"","code":"optimal_binning_numerical_swb(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_swb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using Sliding Window Binning — optimal_binning_numerical_swb","text":"target integer vector binary target values (0 1). feature numeric vector feature values binned. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum frequency observations bin (default: 0.05). max_n_prebins Maximum number pre-bins initial quantile-based discretization (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_swb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using Sliding Window Binning — optimal_binning_numerical_swb","text":"list containing two elements: woefeature numeric vector WoE-transformed feature values. woebin data frame binning details, including bin boundaries, WoE, IV, count statistics.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_swb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using Sliding Window Binning — optimal_binning_numerical_swb","text":"optimal binning algorithm numerical variables uses Sliding Window Binning approach Weight Evidence (WoE) Information Value (IV) create bins maximize predictive power feature maintaining interpretability. algorithm follows steps: Initial discretization using quantile-based binning Merging rare bins based bin_cutoff parameter Adjustment bin count within specified range (min_bins max_bins) Calculation WoE IV bin Enforcement monotonicity WoE across bins Final adjustment ensure number bins exceed max_bins Weight Evidence (WoE) calculated bin : $$WoE_i = \\ln\\left(\\frac{P(X_i|Y=1)}{P(X_i|Y=0)}\\right)$$ \\(P(X_i|Y=1)\\) proportion positive cases bin , \\(P(X_i|Y=0)\\) proportion negative cases bin . Information Value (IV) bin calculated : $$IV_i = (P(X_i|Y=1) - P(X_i|Y=0)) * WoE_i$$ total IV feature sum IVs across bins: $$IV_{total} = \\sum_{=1}^{n} IV_i$$ SWB approach ensures resulting binning maximizes separation classes maintaining desired number bins respecting minimum bin frequency constraint.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_swb.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using Sliding Window Binning — optimal_binning_numerical_swb","text":"Mironchyk, P., & Tchistiakov, V. (2017). Monotone optimal binning algorithm credit risk modeling. arXiv preprint arXiv:1711.05095. Beltratti, ., Margarita, S., & Terna, P. (1996). Neural networks economic financial modelling. International Thomson Computer Press.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_swb.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Numerical Variables using Sliding Window Binning — optimal_binning_numerical_swb","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_swb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using Sliding Window Binning — optimal_binning_numerical_swb","text":"","code":"if (FALSE) { # \\dontrun{ # Generate sample data set.seed(123) n <- 10000 feature <- rnorm(n) target <- rbinom(n, 1, plogis(0.5 * feature))  # Apply optimal binning result <- optimal_binning_numerical_swb(target, feature, min_bins = 3, max_bins = 5)  # View binning results print(result$woebin)  # Plot WoE transformation plot(feature, result$woefeature, main = \"WoE Transformation\",       xlab = \"Original Feature\", ylab = \"WoE\") } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ubsd.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using Unsupervised Binning with Standard Deviation — optimal_binning_numerical_ubsd","title":"Optimal Binning for Numerical Variables using Unsupervised Binning with Standard Deviation — optimal_binning_numerical_ubsd","text":"function implements optimal binning algorithm numerical variables using Unsupervised Binning approach based Standard Deviation (UBSD) Weight Evidence (WoE) Information Value (IV) criteria.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ubsd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using Unsupervised Binning with Standard Deviation — optimal_binning_numerical_ubsd","text":"","code":"optimal_binning_numerical_ubsd(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ubsd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using Unsupervised Binning with Standard Deviation — optimal_binning_numerical_ubsd","text":"target numeric vector binary target values (contain exactly two unique values). feature numeric vector feature values binned. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum frequency observations bin (default: 0.05). max_n_prebins Maximum number pre-bins initial standard deviation-based discretization (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ubsd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using Unsupervised Binning with Standard Deviation — optimal_binning_numerical_ubsd","text":"list containing two elements: woefeature numeric vector WoE-transformed feature values. woebin data frame binning details, including bin boundaries, WoE, IV, count statistics.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ubsd.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using Unsupervised Binning with Standard Deviation — optimal_binning_numerical_ubsd","text":"optimal binning algorithm numerical variables uses Unsupervised Binning approach based Standard Deviation (UBSD) Weight Evidence (WoE) Information Value (IV) create bins maximize predictive power feature maintaining interpretability. algorithm follows steps: Initial binning based standard deviations around mean Assignment data points bins Merging rare bins based bin_cutoff parameter Calculation WoE IV bin Enforcement monotonicity WoE across bins merging bins ensure number bins within specified range Application WoE transformation original feature Weight Evidence (WoE) calculated bin : $$WoE_i = \\ln\\left(\\frac{P(X_i|Y=1)}{P(X_i|Y=0)}\\right)$$ \\(P(X_i|Y=1)\\) proportion positive cases bin , \\(P(X_i|Y=0)\\) proportion negative cases bin . Information Value (IV) bin calculated : $$IV_i = (P(X_i|Y=1) - P(X_i|Y=0)) * WoE_i$$ total IV feature sum IVs across bins: $$IV_{total} = \\sum_{=1}^{n} IV_i$$ UBSD approach ensures resulting binning maximizes separation classes maintaining desired number bins respecting minimum bin frequency constraint.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ubsd.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using Unsupervised Binning with Standard Deviation — optimal_binning_numerical_ubsd","text":"Kotsiantis, S., & Kanellopoulos, D. (2006). Discretization techniques: recent survey. GESTS International Transactions Computer Science Engineering, 32(1), 47-58. Dougherty, J., Kohavi, R., & Sahami, M. (1995). Supervised unsupervised discretization continuous features. Machine Learning Proceedings 1995 (pp. 194-202). Morgan Kaufmann.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ubsd.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Numerical Variables using Unsupervised Binning with Standard Deviation — optimal_binning_numerical_ubsd","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ubsd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using Unsupervised Binning with Standard Deviation — optimal_binning_numerical_ubsd","text":"","code":"if (FALSE) { # \\dontrun{ # Generate sample data set.seed(123) n <- 10000 feature <- rnorm(n) target <- rbinom(n, 1, plogis(0.5 * feature))  # Apply optimal binning result <- optimal_binning_numerical_ubsd(target, feature, min_bins = 3, max_bins = 5)  # View binning results print(result$woebin)  # Plot WoE transformation plot(feature, result$woefeature, main = \"WoE Transformation\",       xlab = \"Original Feature\", ylab = \"WoE\") } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_udt.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using Unsupervised Decision Trees — optimal_binning_numerical_udt","title":"Optimal Binning for Numerical Variables using Unsupervised Decision Trees — optimal_binning_numerical_udt","text":"function implements optimal binning algorithm numerical variables using Unsupervised Decision Tree (UDT) approach Weight Evidence (WoE) Information Value (IV) criteria.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_udt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using Unsupervised Decision Trees — optimal_binning_numerical_udt","text":"","code":"optimal_binning_numerical_udt(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_udt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using Unsupervised Decision Trees — optimal_binning_numerical_udt","text":"target integer vector binary target values (0 1). feature numeric vector feature values binned. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum frequency observations bin (default: 0.05). max_n_prebins Maximum number pre-bins initial quantile-based discretization (default: 20).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_udt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using Unsupervised Decision Trees — optimal_binning_numerical_udt","text":"list containing two elements: woefeature numeric vector WoE-transformed feature values. woebin data frame binning details, including bin boundaries, WoE, IV, count statistics.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_udt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using Unsupervised Decision Trees — optimal_binning_numerical_udt","text":"optimal binning algorithm numerical variables uses Unsupervised Decision Tree approach Weight Evidence (WoE) Information Value (IV) create bins maximize predictive power feature maintaining interpretability. algorithm follows steps: Initial discretization using quantile-based binning Merging rare bins based bin_cutoff parameter Bin optimization using IV WoE criteria Enforcement monotonicity WoE across bins Adjustment number bins within specified range Weight Evidence (WoE) calculated bin : $$WoE_i = \\ln\\left(\\frac{P(X_i|Y=1)}{P(X_i|Y=0)}\\right)$$ \\(P(X_i|Y=1)\\) proportion positive cases bin , \\(P(X_i|Y=0)\\) proportion negative cases bin . Information Value (IV) bin calculated : $$IV_i = (P(X_i|Y=1) - P(X_i|Y=0)) * WoE_i$$ total IV feature sum IVs across bins: $$IV_{total} = \\sum_{=1}^{n} IV_i$$ UDT approach ensures resulting binning maximizes separation classes maintaining desired number bins respecting minimum bin frequency constraint.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_udt.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using Unsupervised Decision Trees — optimal_binning_numerical_udt","text":"Fayyad, U. M., & Irani, K. B. (1993). Multi-interval discretization continuous-valued attributes classification learning. Proceedings 13th International Joint Conference Artificial Intelligence (pp. 1022-1027). Dougherty, J., Kohavi, R., & Sahami, M. (1995). Supervised unsupervised discretization continuous features. Machine Learning Proceedings 1995 (pp. 194-202). Morgan Kaufmann.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_udt.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Numerical Variables using Unsupervised Decision Trees — optimal_binning_numerical_udt","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_udt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using Unsupervised Decision Trees — optimal_binning_numerical_udt","text":"","code":"if (FALSE) { # \\dontrun{ # Generate sample data set.seed(123) n <- 10000 feature <- rnorm(n) target <- rbinom(n, 1, plogis(0.5 * feature))  # Apply optimal binning result <- optimal_binning_numerical_udt(target, feature, min_bins = 3, max_bins = 5)  # View binning results print(result$woebin)  # Plot WoE transformation plot(feature, result$woefeature, main = \"WoE Transformation\",       xlab = \"Original Feature\", ylab = \"WoE\") } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""}]

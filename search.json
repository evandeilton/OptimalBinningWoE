[{"path":"https://evandeilton.github.io/OptimalBinningWoE/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 OptimalBinningWoE authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Lopes J. E. Author, maintainer.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"J. E L (2024). OptimalBinningWoE: Advanced Feature Binning Weight Evidence Calculation Predictive Modeling. R package version 0.1.6.9004, https://evandeilton.github.io/OptimalBinningWoE/.","code":"@Manual{,   title = {OptimalBinningWoE: Advanced Feature Binning and Weight of Evidence Calculation for Predictive Modeling},   author = {Lopes {J. E}},   year = {2024},   note = {R package version 0.1.6.9004},   url = {https://evandeilton.github.io/OptimalBinningWoE/}, }"},{"path":[]},{"path":"https://evandeilton.github.io/OptimalBinningWoE/index.html","id":"introduction","dir":"","previous_headings":"","what":"Introduction","title":"Advanced Feature Binning and Weight of Evidence Calculation for Predictive Modeling","text":"OptimalBinningWoE R package designed perform optimal binning calculate Weight Evidence (WoE) numerical categorical features. implements variety advanced binning algorithms discretize continuous variables optimize categorical variables predictive modeling, particularly credit scoring risk assessment applications. package supports automatic method selection, data preprocessing, handles numerical categorical features. aims maximize predictive power features maintaining interpretability monotonic binning information value optimization.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/OptimalBinningWoE/index.html","id":"weight-of-evidence-woe","dir":"","previous_headings":"Key Concepts","what":"Weight of Evidence (WoE)","title":"Advanced Feature Binning and Weight of Evidence Calculation for Predictive Modeling","text":"Weight Evidence measure used encode categorical variables logistic regression, particularly credit scoring. quantifies predictive power feature comparing distribution good bad cases across bins. bin ii: WoEi=ln(P(Xi|Y=1)P(Xi|Y=0)) \\text{WoE}_i = \\ln\\left(\\frac{P(X_i | Y = 1)}{P(X_i | Y = 0)}\\right) : - P(Xi|Y=1)P(X_i | Y = 1) proportion positive cases (e.g., defaults) bin ii, - P(Xi|Y=0)P(X_i | Y = 0) proportion negative cases (e.g., non-defaults) bin ii.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/index.html","id":"information-value-iv","dir":"","previous_headings":"Key Concepts","what":"Information Value (IV)","title":"Advanced Feature Binning and Weight of Evidence Calculation for Predictive Modeling","text":"Information Value quantifies overall predictive power feature. calculated sum WoE differences good bad cases across bins. bin ii: IVi=(P(Xi|Y=1)−P(Xi|Y=0))×WoEi \\text{IV}_i = \\left(P(X_i | Y = 1) - P(X_i | Y = 0)\\right) \\times \\text{WoE}_i total Information Value : IVtotal=∑=1nIVi \\text{IV}_{\\text{total}} = \\sum_{=1}^{n} \\text{IV}_i Interpretation IV values: IV < 0.02: Predictive 0.02 ≤ IV < 0.1: Weak Predictive Power 0.1 ≤ IV < 0.3: Medium Predictive Power 0.3 ≤ IV < 0.5: Strong Predictive Power IV ≥ 0.5: Suspicious Overfitting","code":""},{"path":[]},{"path":"https://evandeilton.github.io/OptimalBinningWoE/index.html","id":"for-categorical-variables","dir":"","previous_headings":"Supported Algorithms","what":"For Categorical Variables","title":"Advanced Feature Binning and Weight of Evidence Calculation for Predictive Modeling","text":"Fisher’s Exact Test Binning (FETB): Uses Fisher’s exact test merge categories similar target distributions. ChiMerge (CM): Merges categories based chi-square statistics ensure homogeneous bins. Unsupervised Decision Trees (UDT): Applies decision tree algorithms unsupervised categorical binning. Information Value Binning (IVB): Bins categories based maximizing Information Value. Greedy Monotonic Binning (GMB): Creates monotonic bins using greedy approach. Sliding Window Binning (SWB): Adapts sliding window method categorical variables. Dynamic Programming Local Constraints (DPLC): Applies dynamic programming optimal binning local constraints. Monotonic Optimal Binning (MOB): Ensures monotonicity WoE across categories. Modified Binning Algorithm (MBA): modified approach tailored categorical variable binning. Mixed Integer Linear Programming (MILP): Uses MILP find optimal binning solution. Simulated Annealing Binning (SAB): Applies simulated annealing binning optimization.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/index.html","id":"for-numerical-variables","dir":"","previous_headings":"Supported Algorithms","what":"For Numerical Variables","title":"Advanced Feature Binning and Weight of Evidence Calculation for Predictive Modeling","text":"Unsupervised Decision Trees (UDT): Utilizes decision tree algorithms unsupervised manner. Minimum Description Length Principle (MDLP): Implements MDLP criterion optimal binning. Monotonic Optimal Binning (MOB): Ensures monotonicity WoE across bins. Monotonic Binning via Linear Programming (MBLP): Uses linear programming achieve monotonic binning. Dynamic Programming Local Constraints (DPLC): Employs dynamic programming numerical variables. Local Polynomial Density Binning (LPDB): Uses local polynomial density estimation. Unsupervised Binning Standard Deviation (UBSD): Bins based standard deviation intervals. Fisher’s Exact Test Binning (FETB): Applies Fisher’s exact test numerical variables. Equal Width Binning (EWB): Creates bins equal width across variable’s range. K-means Binning (KMB): Uses k-means clustering binning. Optimal Supervised Learning Path (OSLP): Finds optimal bins using supervised learning paths. Monotonic Regression-Based Linear Programming (MRBLP): Combines monotonic regression linear programming. Isotonic Regression (IR): Uses isotonic regression binning. Branch Bound (BB): Employs branch bound algorithm optimal binning. Local Density Binning (LDB): Utilizes local density estimation binning.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Advanced Feature Binning and Weight of Evidence Calculation for Predictive Modeling","text":"Install development version GitHub:","code":"# install.packages(\"devtools\") devtools::install_github(\"evandeilton/OptimalBinningWoE\")"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Advanced Feature Binning and Weight of Evidence Calculation for Predictive Modeling","text":"main function provided package obwoe(), performs optimal binning WoE calculation.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/index.html","id":"function-signature","dir":"","previous_headings":"Usage","what":"Function Signature","title":"Advanced Feature Binning and Weight of Evidence Calculation for Predictive Modeling","text":"","code":"obwoe(   dt,   target,   features = NULL,   method = \"auto\",   preprocess = TRUE,   outputall = TRUE,   min_bins = 3,   max_bins = 4,   positive = \"bad|1\",   progress = TRUE,   trace = TRUE,   control = list(...) )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/index.html","id":"arguments","dir":"","previous_headings":"Usage","what":"Arguments","title":"Advanced Feature Binning and Weight of Evidence Calculation for Predictive Modeling","text":"dt: data.table containing dataset. target: name binary target variable. features: Vector feature names process. NULL, features except target processed. method: binning method use. Can \"auto\" one methods listed Supported Algorithms section. preprocess: Logical. Whether preprocess data binning (default: TRUE). outputall: Logical. TRUE, returns detailed output including data, binning information, reports (default: TRUE). min_bins: Minimum number bins (default: 3). max_bins: Maximum number bins (default: 4). positive: Specifies category considered positive (e.g., \"bad|1\" \"good|1\"). progress: Logical. Whether display progress bar (default: TRUE). trace: Logical. Whether generate error logs testing existing methods (default: TRUE). control: list additional control parameters (see ).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/index.html","id":"control-parameters","dir":"","previous_headings":"Usage","what":"Control Parameters","title":"Advanced Feature Binning and Weight of Evidence Calculation for Predictive Modeling","text":"control list allows fine-tuning binning process: cat_cutoff: Minimum frequency category (default: 0.05). bin_cutoff: Minimum frequency bin (default: 0.05). min_bads: Minimum proportion bad cases bin (default: 0.05). pvalue_threshold: P-value threshold statistical tests (default: 0.05). max_n_prebins: Maximum number pre-bins (default: 20). monotonicity_direction: Direction monotonicity (“increase” “decrease”). lambda: Regularization parameter algorithms (default: 0.1). min_bin_size: Minimum bin size proportion total observations (default: 0.05). min_iv_gain: Minimum IV gain bin splitting (default: 0.01). max_depth: Maximum depth tree-based algorithms (default: 10). num_miss_value: Value replace missing numeric values (default: -999.0). char_miss_value: Value replace missing categorical values (default: \"N/\"). outlier_method: Method outlier detection (\"iqr\", \"zscore\", \"grubbs\"). outlier_process: Whether process outliers (default: FALSE). iqr_k: IQR multiplier outlier detection (default: 1.5). zscore_threshold: Z-score threshold outlier detection (default: 3). grubbs_alpha: Significance level Grubbs’ test (default: 0.05). n_threads: Number threads parallel processing (default: 1). is_monotonic: Whether enforce monotonicity binning (default: TRUE). population_size: Population size genetic algorithm (default: 50). max_generations: Maximum number generations genetic algorithm (default: 100). mutation_rate: Mutation rate genetic algorithm (default: 0.1). initial_temperature: Initial temperature simulated annealing (default: 1). cooling_rate: Cooling rate simulated annealing (default: 0.995). max_iterations: Maximum number iterations iterative algorithms (default: 1000). include_upper_bound: Include upper bound numeric bins (default: TRUE). bin_separator: Separator bins categorical variables (default: \"%;%\").","code":""},{"path":[]},{"path":"https://evandeilton.github.io/OptimalBinningWoE/index.html","id":"example-1-using-the-german-credit-data","dir":"","previous_headings":"Examples","what":"Example 1: Using the German Credit Data","title":"Advanced Feature Binning and Weight of Evidence Calculation for Predictive Modeling","text":"","code":"library(OptimalBinningWoE) library(data.table) library(scorecard)  # Load the German Credit dataset data(germancredit, package = \"scorecard\") dt <- as.data.table(germancredit)  # Process all features with Monotonic Binning via Linear Programming (MBLP) method result <- obwoe(   dt,   target = \"creditability\",   method = \"auto\",   min_bins = 3,   max_bins = 3,   positive = \"bad|1\",   features = c(\"age.in.years\", \"purpose\"),   control = list(bin_separator = \"'+'\") )  # View WoE binning information result$woebin[, 1:7] %>%   knitr::kable()"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/index.html","id":"example-2-detailed-output-with-numeric-features","dir":"","previous_headings":"Examples","what":"Example 2: Detailed Output with Numeric Features","title":"Advanced Feature Binning and Weight of Evidence Calculation for Predictive Modeling","text":"","code":"# Select numeric features excluding the target numeric_features <- names(dt)[sapply(dt, is.numeric)] numeric_features <- setdiff(numeric_features, \"creditability\")  # Process numeric features with detailed output result_detailed <- obwoe(   dt,   target = \"creditability\",   features = numeric_features,   method = \"auto\",   preprocess = TRUE,   outputall = TRUE,   min_bins = 3,   max_bins = 3,   positive = \"bad|1\" )  # View WoE-transformed data result_detailed$data[, 1:4] %>%   head(5) %>%   knitr::kable()  # View best model report result_detailed$report_best_model[, 1:5] %>%   head(5) %>%   knitr::kable()  # View preprocessing report # print(result_detailed$report_preprocess)"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/index.html","id":"example-3-processing-categorical-features-with-unsupervised-decision-trees","dir":"","previous_headings":"Examples","what":"Example 3: Processing Categorical Features with Unsupervised Decision Trees","title":"Advanced Feature Binning and Weight of Evidence Calculation for Predictive Modeling","text":"","code":"# Select categorical features excluding the target categoric_features <- names(dt)[sapply(dt, function(i) !is.numeric(i))] categoric_features <- setdiff(categoric_features, \"creditability\")  # Process categorical features with UDT method result_cat <- obwoe(   dt,   target = \"creditability\",   features = categoric_features,   method = \"udt\",   preprocess = TRUE,   min_bins = 3,   max_bins = 4,   positive = \"bad|1\" )  # View binning information for categorical features result_cat$woebin[, 1:7] %>% knitr::kable()"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/index.html","id":"use-recommendations","dir":"","previous_headings":"","what":"Use Recommendations","title":"Advanced Feature Binning and Weight of Evidence Calculation for Predictive Modeling","text":"Method Selection: method = \"auto\", function tests multiple algorithms selects one produces highest total Information Value respecting specified constraints. Monotonicity: Enforcing monotonicity binning (is_monotonic = TRUE) recommended credit scoring models ensure interpretability. Preprocessing: ’s advisable preprocess data (preprocess = TRUE) handle missing values outliers effectively. Bin Constraints: Adjust min_bins max_bins according feature’s characteristics desired level granularity. Control Parameters: Fine-tune control parameters optimize binning process specific dataset.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Advanced Feature Binning and Weight of Evidence Calculation for Predictive Modeling","text":"Siddiqi, N. (2006). Credit Risk Scorecards: Developing Implementing Intelligent Credit Scoring. John Wiley & Sons. Hand, D. J., & Henley, W. E. (1997). Statistical classification methods consumer credit scoring: review. Journal Royal Statistical Society: Series (Statistics Society), 160(3), 523-541. Thomas, L. C., Edelman, D. B., & Crook, J. N. (2002). Credit Scoring Applications. SIAM.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/index.html","id":"contributing","dir":"","previous_headings":"","what":"Contributing","title":"Advanced Feature Binning and Weight of Evidence Calculation for Predictive Modeling","text":"Contributions welcome! Please open issue submit pull request GitHub.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"Advanced Feature Binning and Weight of Evidence Calculation for Predictive Modeling","text":"project licensed MIT License - see LICENSE details.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/AIC.oblr.html","id":null,"dir":"Reference","previous_headings":"","what":"AIC Method for oblr Objects — AIC.oblr","title":"AIC Method for oblr Objects — AIC.oblr","text":"Calculates Akaike Information Criterion (AIC) oblr model.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/AIC.oblr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"AIC Method for oblr Objects — AIC.oblr","text":"","code":"# S3 method for class 'oblr' AIC(object, ..., k = 2)"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/AIC.oblr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"AIC Method for oblr Objects — AIC.oblr","text":"object object class oblr. ... Additional arguments passed methods. k penalty per parameter used AIC calculation. Default 2.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/AIC.oblr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"AIC Method for oblr Objects — AIC.oblr","text":"numeric value representing AIC.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/BIC.html","id":null,"dir":"Reference","previous_headings":"","what":"Register the S3 method — BIC","title":"Register the S3 method — BIC","text":"Register S3 method","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/BIC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Register the S3 method — BIC","text":"","code":"BIC(object, ...)"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/BIC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Register the S3 method — BIC","text":"object obrl class fit ... Additional arguments passed methods.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/BIC.oblr.html","id":null,"dir":"Reference","previous_headings":"","what":"BIC Method for oblr Objects — BIC.oblr","title":"BIC Method for oblr Objects — BIC.oblr","text":"Calculates Bayesian Information Criterion (BIC) oblr model.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/BIC.oblr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"BIC Method for oblr Objects — BIC.oblr","text":"","code":"# S3 method for class 'oblr' BIC(object, ...)"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/BIC.oblr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"BIC Method for oblr Objects — BIC.oblr","text":"object object class oblr. ... Additional arguments passed methods.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/BIC.oblr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"BIC Method for oblr Objects — BIC.oblr","text":"numeric value representing BIC.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningApplyWoECat.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply Optimal Weight of Evidence (WoE) to a Categorical Feature — OptimalBinningApplyWoECat","title":"Apply Optimal Weight of Evidence (WoE) to a Categorical Feature — OptimalBinningApplyWoECat","text":"function applies optimal Weight Evidence (WoE) values original categorical feature based results optimal binning algorithm. assigns category feature corresponding optimal bin maps associated WoE value.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningApplyWoECat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply Optimal Weight of Evidence (WoE) to a Categorical Feature — OptimalBinningApplyWoECat","text":"","code":"OptimalBinningApplyWoECat(obresults, feature, bin_separator = \"%;%\")"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningApplyWoECat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply Optimal Weight of Evidence (WoE) to a Categorical Feature — OptimalBinningApplyWoECat","text":"obresults list containing output optimal binning algorithm categorical variables. must include least following elements: feature character vector containing original categorical feature data WoE values applied. bin_separator string representing separator used bins separate categories within merged bins (default: \"%;%\").","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningApplyWoECat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply Optimal Weight of Evidence (WoE) to a Categorical Feature — OptimalBinningApplyWoECat","text":"data frame three columns: feature: Original feature values. bin: Optimal merged bins feature value belongs. woe: Optimal WoE values corresponding feature value.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningApplyWoECat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Apply Optimal Weight of Evidence (WoE) to a Categorical Feature — OptimalBinningApplyWoECat","text":"function processes bin obresults splitting merged bin individual categories using bin_separator. creates mapping category corresponding bin index WoE value. value feature, function assigns appropriate bin WoE value based category--bin mapping. category feature found bin, NA assigned bin woe. function handles missing values (NA) feature assigning NA bin woe entries.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningApplyWoECat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply Optimal Weight of Evidence (WoE) to a Categorical Feature — OptimalBinningApplyWoECat","text":"","code":"if (FALSE) { # \\dontrun{ # Example usage with hypothetical obresults and feature vector obresults <- list(   bin = c(\"business;repairs;car (used);retraining\",            \"car (new);furniture/equipment;domestic appliances;education;others\",            \"radio/television\"),   woe = c(-0.2000211, 0.2892885, -0.4100628) ) feature <- c(\"business\", \"education\", \"radio/television\", \"unknown_category\") result <- OptimalBinningApplyWoECat(obresults, feature, bin_separator = \";\") print(result) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningApplyWoENum.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply Optimal Weight of Evidence (WoE) to a Numerical Feature — OptimalBinningApplyWoENum","title":"Apply Optimal Weight of Evidence (WoE) to a Numerical Feature — OptimalBinningApplyWoENum","text":"function applies optimal Weight Evidence (WoE) values original numerical feature based results optimal binning algorithm. assigns value feature bin according specified cutpoints interval inclusion rule, maps corresponding WoE value .","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningApplyWoENum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply Optimal Weight of Evidence (WoE) to a Numerical Feature — OptimalBinningApplyWoENum","text":"","code":"OptimalBinningApplyWoENum(obresults, feature, include_upper_bound = TRUE)"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningApplyWoENum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply Optimal Weight of Evidence (WoE) to a Numerical Feature — OptimalBinningApplyWoENum","text":"obresults list containing output optimal binning algorithm numerical variables. must include least following elements: cutpoints: numeric vector cutpoints used define bins. woe: numeric vector WoE values corresponding bin. feature numeric vector containing original feature data WoE values applied. include_upper_bound logical value indicating whether upper bound interval included (default TRUE).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningApplyWoENum.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply Optimal Weight of Evidence (WoE) to a Numerical Feature — OptimalBinningApplyWoENum","text":"data frame three columns: feature: Original feature values. featurebins: Optimal bins represented interval notation. featurewoe: Optimal WoE values corresponding feature value.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningApplyWoENum.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Apply Optimal Weight of Evidence (WoE) to a Numerical Feature — OptimalBinningApplyWoENum","text":"function assigns value feature bin based cutpoints include_upper_bound parameter. intervals defined mathematically follows: Let \\(C = \\{c_1, c_2, ..., c_n\\}\\) set cutpoints. include_upper_bound = TRUE: $$ I_1 = (-\\infty, c_1] $$ $$ I_i = (c_{-1}, c_i], \\quad \\text{} = 2, ..., n $$ $$ I_{n+1} = (c_n, +\\infty) $$ include_upper_bound = FALSE: $$ I_1 = (-\\infty, c_1) $$ $$ I_i = [c_{-1}, c_i), \\quad \\text{} = 2, ..., n $$ $$ I_{n+1} = [c_n, +\\infty) $$ function uses efficient algorithms data structures handle large datasets. implements binary search assign bins, minimizing computational complexity.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningApplyWoENum.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply Optimal Weight of Evidence (WoE) to a Numerical Feature — OptimalBinningApplyWoENum","text":"","code":"if (FALSE) { # \\dontrun{ # Example usage with hypothetical obresults and feature vector obresults <- list(   cutpoints = c(1.5, 3.0, 4.5),   woe = c(-0.2, 0.0, 0.2, 0.4) ) feature <- c(1.0, 2.0, 3.5, 5.0) result <- OptimalBinningApplyWoENum(obresults, feature, include_upper_bound = TRUE) print(result) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningCalculateSpecialWoE.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Special WoE — OptimalBinningCalculateSpecialWoE","title":"Calculate Special WoE — OptimalBinningCalculateSpecialWoE","text":"Calculate Special WoE","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningCalculateSpecialWoE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Special WoE — OptimalBinningCalculateSpecialWoE","text":"","code":"OptimalBinningCalculateSpecialWoE(target)"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningCalculateSpecialWoE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Special WoE — OptimalBinningCalculateSpecialWoE","text":"target Target values special cases","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningCalculateSpecialWoE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Special WoE — OptimalBinningCalculateSpecialWoE","text":"WoE value special cases","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningCreateSpecialBin.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Special Bin — OptimalBinningCreateSpecialBin","title":"Create Special Bin — OptimalBinningCreateSpecialBin","text":"Create Special Bin","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningCreateSpecialBin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Special Bin — OptimalBinningCreateSpecialBin","text":"","code":"OptimalBinningCreateSpecialBin(dt_special, woebin, special_woe)"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningCreateSpecialBin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Special Bin — OptimalBinningCreateSpecialBin","text":"dt_special Data special cases woebin Existing WoE bins special_woe WoE value special cases","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningCreateSpecialBin.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Special Bin — OptimalBinningCreateSpecialBin","text":"Special bin information","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningDataPreprocessor.html","id":null,"dir":"Reference","previous_headings":"","what":"Preprocesses a numeric or categorical variable for optimal binning with handling of missing values and outliers — OptimalBinningDataPreprocessor","title":"Preprocesses a numeric or categorical variable for optimal binning with handling of missing values and outliers — OptimalBinningDataPreprocessor","text":"function preprocesses given numeric categorical feature, handling missing values outliers based specified method. can process numeric categorical features supports outlier detection various methods, including IQR, Z-score, Grubbs' test. function also generates summary statistics preprocessing.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningDataPreprocessor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preprocesses a numeric or categorical variable for optimal binning with handling of missing values and outliers — OptimalBinningDataPreprocessor","text":"","code":"OptimalBinningDataPreprocessor(   target,   feature,   num_miss_value = -999,   char_miss_value = \"N/A\",   outlier_method = \"iqr\",   outlier_process = FALSE,   preprocess = as.character(c(\"both\")),   iqr_k = 1.5,   zscore_threshold = 3,   grubbs_alpha = 0.05 )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningDataPreprocessor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preprocesses a numeric or categorical variable for optimal binning with handling of missing values and outliers — OptimalBinningDataPreprocessor","text":"target Numeric vector representing binary target variable, 1 indicates positive event (e.g., default) 0 indicates negative event (e.g., non-default). feature Numeric character vector representing feature binned. num_miss_value (Optional) Numeric value replace missing values numeric features. Default -999.0. char_miss_value (Optional) String value replace missing values categorical features. Default \"N/\". outlier_method (Optional) Method detect outliers. Choose \"iqr\", \"zscore\", \"grubbs\". Default \"iqr\". outlier_process (Optional) Boolean flag indicating whether outliers processed. Default FALSE. preprocess (Optional) Character vector specifying return: \"feature\", \"report\", \"\". Default \"\". iqr_k (Optional) multiplier interquartile range (IQR) using IQR method detect outliers. Default 1.5. zscore_threshold (Optional) threshold Z-score detect outliers. Default 3.0. grubbs_alpha (Optional) significance level Grubbs' test detect outliers. Default 0.05.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningDataPreprocessor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preprocesses a numeric or categorical variable for optimal binning with handling of missing values and outliers — OptimalBinningDataPreprocessor","text":"list containing following elements based preprocess parameter: preprocess: DataFrame containing original preprocessed feature values. report: DataFrame summarizing variable type, number missing values, number outliers (numeric features), statistics preprocessing.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningDataPreprocessor.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Preprocesses a numeric or categorical variable for optimal binning with handling of missing values and outliers — OptimalBinningDataPreprocessor","text":"function can handle numeric categorical features. numeric features, replaces missing values num_miss_value can apply outlier detection using different methods. categorical features, replaces missing values char_miss_value. function can return preprocessed feature /report summary statistics.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningDataPreprocessor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Preprocesses a numeric or categorical variable for optimal binning with handling of missing values and outliers — OptimalBinningDataPreprocessor","text":"","code":"if (FALSE) { # \\dontrun{ target <- c(0, 1, 1, 0, 1) feature_numeric <- c(10, 20, NA, 40, 50) feature_categorical <- c(\"A\", \"B\", NA, \"B\", \"A\") result <- OptimalBinningDataPreprocessor(target, feature_numeric, outlier_process = TRUE) result <- OptimalBinningDataPreprocessor(target, feature_categorical) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningGainsTable.html","id":null,"dir":"Reference","previous_headings":"","what":"Generates a Comprehensive Gains Table from Optimal Binning Results — OptimalBinningGainsTable","title":"Generates a Comprehensive Gains Table from Optimal Binning Results — OptimalBinningGainsTable","text":"function takes result optimal binning process generates detailed gains table. table includes various metrics assess performance characteristics bin.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningGainsTable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generates a Comprehensive Gains Table from Optimal Binning Results — OptimalBinningGainsTable","text":"","code":"OptimalBinningGainsTable(binning_result)"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningGainsTable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generates a Comprehensive Gains Table from Optimal Binning Results — OptimalBinningGainsTable","text":"binning_result list containing binning results, must include data frame following columns: \"bin\", \"count\", \"count_pos\", \"count_neg\", \"woe\".","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningGainsTable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generates a Comprehensive Gains Table from Optimal Binning Results — OptimalBinningGainsTable","text":"data frame containing following columns bin: bin: bin labels. count: Total count observations bin. pos: Count positive events bin. neg: Count negative events bin. woe: Weight Evidence (WoE) bin. iv: Information Value (IV) contribution bin. total_iv: Total Information Value (IV) across bins. cum_pos: Cumulative count positive events current bin. cum_neg: Cumulative count negative events current bin. pos_rate: Rate positive events within bin. neg_rate: Rate negative events within bin. pos_perc: Percentage positive events relative total positive events. neg_perc: Percentage negative events relative total negative events. count_perc: Percentage total observations bin. cum_count_perc: Cumulative percentage observations current bin. cum_pos_perc: Cumulative percentage positive events current bin. cum_neg_perc: Cumulative percentage negative events current bin. cum_pos_perc_total: Cumulative percentage positive events relative total observations. cum_neg_perc_total: Cumulative percentage negative events relative total observations. odds_pos: Odds positive events bin. odds_ratio: Odds ratio positive events compared total population. lift: Lift bin, calculated ratio positive rate bin overall positive rate. ks: Kolmogorov-Smirnov statistic, measuring difference cumulative positive negative percentages. gini_contribution: Contribution Gini coefficient bin. precision: Precision bin. recall: Recall current bin. f1_score: F1 score bin. log_likelihood: Log-likelihood bin. kl_divergence: Kullback-Leibler divergence bin. js_divergence: Jensen-Shannon divergence bin.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningGainsTable.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generates a Comprehensive Gains Table from Optimal Binning Results — OptimalBinningGainsTable","text":"function calculates various metrics bin: Weight Evidence (WoE): $$WoE_i = \\ln\\left(\\frac{P(X_i|Y=1)}{P(X_i|Y=0)}\\right)$$ Information Value (IV): $$IV_i = (P(X_i|Y=1) - P(X_i|Y=0)) \\times WoE_i$$ Kolmogorov-Smirnov (KS) statistic: $$KS_i = |F_1() - F_0()|$$ \\(F_1()\\) \\(F_0()\\) cumulative distribution functions positive negative classes. Odds Ratio: $$OR_i = \\frac{P(Y=1|X_i) / P(Y=0|X_i)}{P(Y=1) / P(Y=0)}$$ Lift: $$Lift_i = \\frac{P(Y=1|X_i)}{P(Y=1)}$$ Gini Contribution: $$Gini_i = P(X_i|Y=1) \\times F_0() - P(X_i|Y=0) \\times F_1()$$ Precision: $$Precision_i = \\frac{TP_i}{TP_i + FP_i}$$ Recall: $$Recall_i = \\frac{\\sum_{j=1}^TP_j}{\\sum_{j=1}^n TP_j}$$ F1 Score: $$F1_i = 2 \\times \\frac{Precision_i \\times Recall_i}{Precision_i + Recall_i}$$ Log-likelihood: $$LL_i = n_{1i} \\ln(p_i) + n_{0i} \\ln(1-p_i)$$ \\(n_{1i}\\) \\(n_{0i}\\) counts positive negative cases bin , \\(p_i\\) proportion positive cases bin . Kullback-Leibler (KL) Divergence: $$KL_i = p_i \\ln\\left(\\frac{p_i}{p}\\right) + (1-p_i) \\ln\\left(\\frac{1-p_i}{1-p}\\right)$$ \\(p_i\\) proportion positive cases bin \\(p\\) overall proportion positive cases. Jensen-Shannon (JS) Divergence: $$JS_i = \\frac{1}{2}KL(p_i || m) + \\frac{1}{2}KL(q_i || m)$$ \\(m = \\frac{1}{2}(p_i + p)\\), \\(p_i\\) proportion positive cases bin , \\(p\\) overall proportion positive cases.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningGainsTable.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generates a Comprehensive Gains Table from Optimal Binning Results — OptimalBinningGainsTable","text":"Siddiqi, N. (2006). Credit Risk Scorecards: Developing Implementing Intelligent Credit Scoring. John Wiley & Sons. Hand, D. J., & Till, R. J. (2001). Simple Generalisation Area ROC Curve Multiple Class Classification Problems. Machine Learning, 45(2), 171-186. Kullback, S., & Leibler, R. . (1951). Information Sufficiency. Annals Mathematical Statistics, 22(1), 79-86. Lin, J. (1991). Divergence measures based Shannon entropy. IEEE Transactions Information Theory, 37(1), 145-151.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningGainsTable.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generates a Comprehensive Gains Table from Optimal Binning Results — OptimalBinningGainsTable","text":"","code":"if (FALSE) { # \\dontrun{ binning_result <- OptimalBinning(target, feature) gains_table <- OptimalBinningGainsTable(binning_result) print(gains_table) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningGainsTableFeature.html","id":null,"dir":"Reference","previous_headings":"","what":"Generates a Comprehensive Gains Table from Weight of Evidence (WoE) and Target Feature Data — OptimalBinningGainsTableFeature","title":"Generates a Comprehensive Gains Table from Weight of Evidence (WoE) and Target Feature Data — OptimalBinningGainsTableFeature","text":"function takes numeric vector Weight Evidence (WoE) values corresponding binary target variable generate detailed gains table. table includes various metrics assess performance characteristics WoE bin.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningGainsTableFeature.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generates a Comprehensive Gains Table from Weight of Evidence (WoE) and Target Feature Data — OptimalBinningGainsTableFeature","text":"","code":"OptimalBinningGainsTableFeature(binned_feature, target)"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningGainsTableFeature.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generates a Comprehensive Gains Table from Weight of Evidence (WoE) and Target Feature Data — OptimalBinningGainsTableFeature","text":"binned_feature Numeric vector representing Weight Evidence (WoE) values observation categorical variable. target Numeric vector representing binary target variable, 1 indicates positive event (e.g., default) 0 indicates negative event (e.g., non-default).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningGainsTableFeature.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generates a Comprehensive Gains Table from Weight of Evidence (WoE) and Target Feature Data — OptimalBinningGainsTableFeature","text":"data frame containing following columns unique WoE bin: bin: bin labels. count: Total count observations bin. pos: Count positive events bin. neg: Count negative events bin. woe: Weight Evidence (WoE) value bin. iv: Information Value (IV) contribution bin. total_iv: Total Information Value (IV) across bins. cum_pos: Cumulative count positive events current bin. cum_neg: Cumulative count negative events current bin. pos_rate: Rate positive events bin. neg_rate: Rate negative events bin. pos_perc: Percentage positive events relative total positive events. neg_perc: Percentage negative events relative total negative events. count_perc: Percentage total observations bin. cum_count_perc: Cumulative percentage observations current bin. cum_pos_perc: Cumulative percentage positive events current bin. cum_neg_perc: Cumulative percentage negative events current bin. cum_pos_perc_total: Cumulative percentage positive events relative total observations. cum_neg_perc_total: Cumulative percentage negative events relative total observations. odds_pos: Odds positive events bin. odds_ratio: Odds ratio positive events bin compared total population. lift: Lift bin, calculated ratio positive rate bin overall positive rate. ks: Kolmogorov-Smirnov statistic, measuring difference cumulative positive negative percentages. gini_contribution: Contribution Gini coefficient bin. precision: Precision bin. recall: Recall current bin. f1_score: F1 score bin. log_likelihood: Log-likelihood bin. kl_divergence: Kullback-Leibler divergence bin. js_divergence: Jensen-Shannon divergence bin.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningGainsTableFeature.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generates a Comprehensive Gains Table from Weight of Evidence (WoE) and Target Feature Data — OptimalBinningGainsTableFeature","text":"function performs following steps: Checks feature_woe target length. Verifies target contains binary values (0 1). Groups target values unique WoE values. Computes various metrics group, including counts, rates, percentages, statistical measures. Handles cases positive negative classes instances returning zero counts appropriate NA values derived metrics. function calculates following key metrics: Weight Evidence (WoE): $$WoE_i = \\ln\\left(\\frac{P(X_i|Y=1)}{P(X_i|Y=0)}\\right)$$ Information Value (IV): $$IV_i = (P(X_i|Y=1) - P(X_i|Y=0)) \\times WoE_i$$ Kolmogorov-Smirnov (KS) statistic: $$KS_i = |F_1() - F_0()|$$ \\(F_1()\\) \\(F_0()\\) cumulative distribution functions positive negative classes. Odds Ratio: $$OR_i = \\frac{P(Y=1|X_i) / P(Y=0|X_i)}{P(Y=1) / P(Y=0)}$$ Lift: $$Lift_i = \\frac{P(Y=1|X_i)}{P(Y=1)}$$ Gini Contribution: $$Gini_i = P(X_i|Y=1) \\times F_0() - P(X_i|Y=0) \\times F_1()$$ Precision: $$Precision_i = \\frac{TP_i}{TP_i + FP_i}$$ Recall: $$Recall_i = \\frac{\\sum_{j=1}^TP_j}{\\sum_{j=1}^n TP_j}$$ F1 Score: $$F1_i = 2 \\times \\frac{Precision_i \\times Recall_i}{Precision_i + Recall_i}$$ Log-likelihood: $$LL_i = n_{1i} \\ln(p_i) + n_{0i} \\ln(1-p_i)$$ \\(n_{1i}\\) \\(n_{0i}\\) counts positive negative cases bin , \\(p_i\\) proportion positive cases bin . Kullback-Leibler (KL) Divergence: $$KL_i = p_i \\ln\\left(\\frac{p_i}{p}\\right) + (1-p_i) \\ln\\left(\\frac{1-p_i}{1-p}\\right)$$ \\(p_i\\) proportion positive cases bin \\(p\\) overall proportion positive cases. Jensen-Shannon (JS) Divergence: $$JS_i = \\frac{1}{2}KL(p_i || m) + \\frac{1}{2}KL(q_i || m)$$ \\(m = \\frac{1}{2}(p_i + p)\\), \\(p_i\\) proportion positive cases bin , \\(p\\) overall proportion positive cases.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningGainsTableFeature.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generates a Comprehensive Gains Table from Weight of Evidence (WoE) and Target Feature Data — OptimalBinningGainsTableFeature","text":"Siddiqi, N. (2006). Credit Risk Scorecards: Developing Implementing Intelligent Credit Scoring. John Wiley & Sons. Hand, D. J., & Till, R. J. (2001). Simple Generalisation Area ROC Curve Multiple Class Classification Problems. Machine Learning, 45(2), 171-186. Kullback, S., & Leibler, R. . (1951). Information Sufficiency. Annals Mathematical Statistics, 22(1), 79-86. Lin, J. (1991). Divergence measures based Shannon entropy. IEEE Transactions Information Theory, 37(1), 145-151.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningGainsTableFeature.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generates a Comprehensive Gains Table from Weight of Evidence (WoE) and Target Feature Data — OptimalBinningGainsTableFeature","text":"","code":"if (FALSE) { # \\dontrun{ feature_woe <- c(-0.5, 0.2, 0.2, -0.5, 0.3) target <- c(1, 0, 1, 0, 1) gains_table <- OptimalBinningGainsTableFeature(feature_woe, target) print(gains_table) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningGetAlgoName.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Available Optimal Binning Algorithms — OptimalBinningGetAlgoName","title":"Get Available Optimal Binning Algorithms — OptimalBinningGetAlgoName","text":"function retrieves available optimal binning algorithms OptimalBinningWoE package, separating categorical numerical types.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningGetAlgoName.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Available Optimal Binning Algorithms — OptimalBinningGetAlgoName","text":"","code":"OptimalBinningGetAlgoName()"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningGetAlgoName.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Available Optimal Binning Algorithms — OptimalBinningGetAlgoName","text":"list containing two elements: char named list categorical binning algorithms num named list numerical binning algorithms","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningGetAlgoName.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get Available Optimal Binning Algorithms — OptimalBinningGetAlgoName","text":"function searches exported functions OptimalBinningWoE package start \"optimal_binning_categorical_\" \"optimal_binning_numerical_\". creates two separate lists categorical numerical algorithms, using last part function name (last underscore) list item name.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningGetAlgoName.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Available Optimal Binning Algorithms — OptimalBinningGetAlgoName","text":"","code":"if (FALSE) { # \\dontrun{ algorithms <- OptimalBinningGetAlgoName() print(algorithms$char) # List of categorical algorithms print(algorithms$num) # List of numerical algorithms } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningIsWoEMonotonic.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if WoE values are monotonic — OptimalBinningIsWoEMonotonic","title":"Check if WoE values are monotonic — OptimalBinningIsWoEMonotonic","text":"Check WoE values monotonic","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningIsWoEMonotonic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if WoE values are monotonic — OptimalBinningIsWoEMonotonic","text":"","code":"OptimalBinningIsWoEMonotonic(woe_values)"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningIsWoEMonotonic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if WoE values are monotonic — OptimalBinningIsWoEMonotonic","text":"woe_values Vector WoE values","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningIsWoEMonotonic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if WoE values are monotonic — OptimalBinningIsWoEMonotonic","text":"Logical indicating WoE values monotonic","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningMapTargetVariable.html","id":null,"dir":"Reference","previous_headings":"","what":"Map Target Variable — OptimalBinningMapTargetVariable","title":"Map Target Variable — OptimalBinningMapTargetVariable","text":"Map Target Variable","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningMapTargetVariable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Map Target Variable — OptimalBinningMapTargetVariable","text":"","code":"OptimalBinningMapTargetVariable(dt, target, positive)"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningMapTargetVariable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Map Target Variable — OptimalBinningMapTargetVariable","text":"dt Data table target Target variable name positive Positive class indicator","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningMapTargetVariable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Map Target Variable — OptimalBinningMapTargetVariable","text":"Updated data table mapped target variable","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningPreprocessData.html","id":null,"dir":"Reference","previous_headings":"","what":"Preprocess Data for Optimal Binning — OptimalBinningPreprocessData","title":"Preprocess Data for Optimal Binning — OptimalBinningPreprocessData","text":"Preprocess Data Optimal Binning","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningPreprocessData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preprocess Data for Optimal Binning — OptimalBinningPreprocessData","text":"","code":"OptimalBinningPreprocessData(   dt,   target,   features,   control,   preprocess = \"both\" )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningPreprocessData.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preprocess Data for Optimal Binning — OptimalBinningPreprocessData","text":"dt data.table containing dataset. target Target name features Vector feature names process. control list control parameters. preprocess Preprocess feature. '' feature report. Can also '' 'feature'","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningPreprocessData.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preprocess Data for Optimal Binning — OptimalBinningPreprocessData","text":"list preprocessed data feature.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningSelectAlgorithm.html","id":null,"dir":"Reference","previous_headings":"","what":"Select Optimal Binning Algorithm — OptimalBinningSelectAlgorithm","title":"Select Optimal Binning Algorithm — OptimalBinningSelectAlgorithm","text":"function selects appropriate binning algorithm based method variable type.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningSelectAlgorithm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select Optimal Binning Algorithm — OptimalBinningSelectAlgorithm","text":"","code":"OptimalBinningSelectAlgorithm(feature, method, dt, min_bin, max_bin, control)"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningSelectAlgorithm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select Optimal Binning Algorithm — OptimalBinningSelectAlgorithm","text":"feature name feature bin. method binning method use. dt data.table containing dataset. min_bin Minimum number bins. max_bin Maximum number bins. control list additional control parameters.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningSelectAlgorithm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select Optimal Binning Algorithm — OptimalBinningSelectAlgorithm","text":"list containing selected algorithm, parameters, method name.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningSelectBestModel.html","id":null,"dir":"Reference","previous_headings":"","what":"Select the Best Model for Optimal Binning — OptimalBinningSelectBestModel","title":"Select the Best Model for Optimal Binning — OptimalBinningSelectBestModel","text":"function selects best model optimal binning across multiple features using various binning algorithms numerical categorical variables.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningSelectBestModel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select the Best Model for Optimal Binning — OptimalBinningSelectBestModel","text":"","code":"OptimalBinningSelectBestModel(   dt,   target,   features,   method = NULL,   min_bins,   max_bins,   control,   progress = TRUE,   trace = FALSE )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningSelectBestModel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select the Best Model for Optimal Binning — OptimalBinningSelectBestModel","text":"dt data.table containing target variable features binned. target name target variable data.table. features character vector feature names binned. method method use. available, test . min_bins minimum number bins use binning process. max_bins maximum number bins use binning process. control list control parameters binning algorithms (used directly function). progress Logical; TRUE, display progress bar processing (default TRUE). trace Logical; TRUE, provide detailed output debugging (default FALSE).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningSelectBestModel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select the Best Model for Optimal Binning — OptimalBinningSelectBestModel","text":"list containing results feature: woebin Weight Evidence (WoE) binning result best model. woefeature WoE-transformed feature best model. bestmethod name algorithm produced best model. report data.table summarizing performance tried models.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningSelectBestModel.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Select the Best Model for Optimal Binning — OptimalBinningSelectBestModel","text":"function iterates feature, applying various binning algorithms suitable either numerical categorical data. selects best model based monotonicity, number zero-count bins, total number bins, Information Value (IV). features 2 fewer distinct values, function forces treated factors applies categorical binning methods. binning algorithm fails, function attempts relax binning parameters try . still fails, method skipped feature.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningSelectBestModel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Select the Best Model for Optimal Binning — OptimalBinningSelectBestModel","text":"","code":"if (FALSE) { # \\dontrun{ library(data.table) dt <- data.table(   target = sample(0:1, 1000, replace = TRUE),   feature1 = rnorm(1000),   feature2 = sample(letters[1:5], 1000, replace = TRUE) ) results <- OptimalBinningSelectBestModel(   dt = dt,   target = \"target\",   features = c(\"feature1\", \"feature2\"),   min_bins = 3,   max_bins = 10 ) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningSelectOptimalFeatures.html","id":null,"dir":"Reference","previous_headings":"","what":"Select Optimal Features Based on Weight of Evidence — OptimalBinningSelectOptimalFeatures","title":"Select Optimal Features Based on Weight of Evidence — OptimalBinningSelectOptimalFeatures","text":"function selects optimal features result Optimal Binning Weight Evidence (WoE) analysis. filters features based Information Value (IV), allowing fine-tuned feature selection predictive modeling.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningSelectOptimalFeatures.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select Optimal Features Based on Weight of Evidence — OptimalBinningSelectOptimalFeatures","text":"","code":"OptimalBinningSelectOptimalFeatures(   obresult,   target,   iv_threshold = 0.02,   min_features = 5,   max_features = NULL )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningSelectOptimalFeatures.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select Optimal Features Based on Weight of Evidence — OptimalBinningSelectOptimalFeatures","text":"obresult list containing result Optimal Binning WoE analysis. Must include elements 'woedt' (data.table WoE transformed data) 'bestsreport' (data.table feature performance metrics). target Character. name target variable dataset. iv_threshold Numeric. minimum Information Value threshold feature selection. Features IV threshold excluded. Default 0.02. min_features Integer. minimum number features select, regardless IV. fewer features meet IV threshold, ensures minimum set still selected. Default 5. max_features Integer NULL. maximum number features select. NULL (default), maximum limit applied.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningSelectOptimalFeatures.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select Optimal Features Based on Weight of Evidence — OptimalBinningSelectOptimalFeatures","text":"list containing: data data.table selected WoE features target variable. selected_features character vector selected WoE feature names. feature_iv data.table features total IV. report data.table summarizing feature selection process.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningSelectOptimalFeatures.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Select Optimal Features Based on Weight of Evidence — OptimalBinningSelectOptimalFeatures","text":"function performs following steps: Validates input parameters. Extracts sorts features Information Value. Selects features based provided IV threshold. Adjusts selection meet minimum maximum feature count requirements. Prepares final dataset selected WoE features target variable. Generates summary report selection process. Mathematical Background: Weight Evidence (WoE) Information Value (IV) key concepts predictive modeling, especially credit scoring. derived information theory provide way measure predictive power independent variable relation dependent variable. Let \\(Y\\) binary target variable \\(X\\) predictor variable. given bin \\(\\) \\(X\\): $$P(X_i|Y=1) = \\frac{\\text{Number events bin }}{\\text{Total number events}}$$ $$P(X_i|Y=0) = \\frac{\\text{Number non-events bin }}{\\text{Total number non-events}}$$ Weight Evidence bin \\(\\) defined : $$WoE_i = \\ln\\left(\\frac{P(X_i|Y=1)}{P(X_i|Y=0)}\\right)$$ Information Value entire variable \\(X\\) : $$IV = \\sum_{} (P(X_i|Y=1) - P(X_i|Y=0)) \\cdot WoE_i$$ Interpretation Information Value: Note: IV > 0.5 might indicate overfitting data leakage investigated.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningSelectOptimalFeatures.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Select Optimal Features Based on Weight of Evidence — OptimalBinningSelectOptimalFeatures","text":"","code":"if (FALSE) { # \\dontrun{ # Assuming 'obwoe_result' is the output from an Optimal Binning and WoE analysis result <- OptimalBinningSelectOptimalFeatures(   obresult = obwoe_result,   target = \"target_variable\",   iv_threshold = 0.05,   min_features = 10,   max_features = 30 )  # Access the final dataset with selected WoE features final_dataset <- result$data  # View the selected WoE feature names print(result$selected_features)  # View the feature selection summary report print(result$report) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningValidateInputs.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate Inputs for Optimal Binning — OptimalBinningValidateInputs","title":"Validate Inputs for Optimal Binning — OptimalBinningValidateInputs","text":"Validate Inputs Optimal Binning","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningValidateInputs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate Inputs for Optimal Binning — OptimalBinningValidateInputs","text":"","code":"OptimalBinningValidateInputs(   dt,   target,   features,   method,   preprocess,   min_bins,   max_bins,   control,   positive )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningValidateInputs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate Inputs for Optimal Binning — OptimalBinningValidateInputs","text":"dt data.table containing dataset. target name target variable. features Vector feature names process. method binning method use. preprocess Logical. Whether preprocess data binning. min_bins Minimum number bins. max_bins Maximum number bins. control list additional control parameters. positive Character string specifying category considered positive.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/OptimalBinningValidateInputs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate Inputs for Optimal Binning — OptimalBinningValidateInputs","text":"None. Throws error input invalid.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/anova.oblr.html","id":null,"dir":"Reference","previous_headings":"","what":"Anova Method for oblr Objects — anova.oblr","title":"Anova Method for oblr Objects — anova.oblr","text":"function performs analysis variance (precisely, analysis deviance) one fitted logistic regression model objects class 'oblr'.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/anova.oblr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Anova Method for oblr Objects — anova.oblr","text":"","code":"# S3 method for class 'oblr' anova(object, ..., test = c(\"Chisq\", \"F\", \"none\"))"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/anova.oblr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Anova Method for oblr Objects — anova.oblr","text":"object object class \"oblr\", typically result call oblr(). ... Additional objects class \"oblr\", single object class \"list\" containing objects class \"oblr\". test character string specifying test statistic used. Can one \"Chisq\" (default) likelihood ratio test, \"F\" F-test, \"none\" skip significance testing.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/anova.oblr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Anova Method for oblr Objects — anova.oblr","text":"object class \"anova\" inheriting class \"data.frame\".","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/binning_categorical_cutpoints.html","id":null,"dir":"Reference","previous_headings":"","what":"Binning Categorical Variables using Custom Cutpoints — binning_categorical_cutpoints","title":"Binning Categorical Variables using Custom Cutpoints — binning_categorical_cutpoints","text":"function performs optimal binning categorical variables based predefined cutpoints, calculates Weight Evidence (WoE) Information Value (IV) bin, transforms feature accordingly.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/binning_categorical_cutpoints.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Binning Categorical Variables using Custom Cutpoints — binning_categorical_cutpoints","text":"","code":"binning_categorical_cutpoints(feature, target, cutpoints)"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/binning_categorical_cutpoints.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Binning Categorical Variables using Custom Cutpoints — binning_categorical_cutpoints","text":"feature character vector representing categorical feature binned. target integer vector representing binary target variable (0 1). cutpoints character vector containing bin definitions, categories separated '+' (e.g., \"+B+C\").","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/binning_categorical_cutpoints.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Binning Categorical Variables using Custom Cutpoints — binning_categorical_cutpoints","text":"list two elements: woefeature numeric vector representing transformed feature WoE values observation. woebin data frame containing detailed statistics bin, including counts, WoE, IV.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/binning_categorical_cutpoints.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Binning Categorical Variables using Custom Cutpoints — binning_categorical_cutpoints","text":"Binning preprocessing step groups categories categorical feature smaller number bins. function performs binning based user-defined cutpoints, cutpoint specifies group categories combined single bin. resulting bins evaluated using WoE IV metrics, often used predictive modeling, especially credit risk modeling. Weight Evidence (WoE) calculated : $$\\text{WoE} = \\log\\left(\\frac{\\text{Positive Rate}}{\\text{Negative Rate}}\\right)$$ Positive Rate proportion positive observations (target = 1) within bin, Negative Rate proportion negative observations (target = 0) within bin. Information Value (IV) measures predictive power categorical feature calculated : $$IV = \\sum (\\text{Positive Rate} - \\text{Negative Rate}) \\times \\text{WoE}$$ IV metric provides insight well binned feature predicts target variable: IV < 0.02: predictive 0.02 ≤ IV < 0.1: Weak predictive power 0.1 ≤ IV < 0.3: Medium predictive power IV ≥ 0.3: Strong predictive power WoE used transform categorical variable continuous numeric variable, can used directly logistic regression predictive models.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/binning_categorical_cutpoints.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Binning Categorical Variables using Custom Cutpoints — binning_categorical_cutpoints","text":"Siddiqi, N. (2006). Credit Risk Scorecards: Developing Implementing Intelligent Credit Scoring. John Wiley & Sons.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/binning_categorical_cutpoints.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Binning Categorical Variables using Custom Cutpoints — binning_categorical_cutpoints","text":"","code":"if (FALSE) { # \\dontrun{ # Example usage feature <- c(\"A\", \"B\", \"C\", \"A\", \"B\", \"C\", \"A\", \"C\", \"C\", \"B\") target <- c(1, 0, 1, 1, 0, 0, 0, 1, 1, 0) cutpoints <- c(\"A+B\", \"C\") result <- binning_categorical_cutpoints(feature, target, cutpoints) print(result$woefeature)  # WoE-transformed feature print(result$woebin)      # WoE and IV statistics for each bin } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/binning_numerical_cutpoints.html","id":null,"dir":"Reference","previous_headings":"","what":"Binning Numerical Variables using Custom Cutpoints — binning_numerical_cutpoints","title":"Binning Numerical Variables using Custom Cutpoints — binning_numerical_cutpoints","text":"function performs optimal binning numerical variable based predefined cutpoints, calculates Weight Evidence (WoE) Information Value (IV) bin, transforms feature accordingly.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/binning_numerical_cutpoints.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Binning Numerical Variables using Custom Cutpoints — binning_numerical_cutpoints","text":"","code":"binning_numerical_cutpoints(feature, target, cutpoints)"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/binning_numerical_cutpoints.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Binning Numerical Variables using Custom Cutpoints — binning_numerical_cutpoints","text":"feature numeric vector representing numerical feature binned. target integer vector representing binary target variable (0 1). cutpoints numeric vector containing cutpoints define bin boundaries.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/binning_numerical_cutpoints.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Binning Numerical Variables using Custom Cutpoints — binning_numerical_cutpoints","text":"list two elements: woefeature numeric vector representing transformed feature WoE values observation. woebin data frame containing detailed statistics bin, including counts, WoE, IV.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/binning_numerical_cutpoints.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Binning Numerical Variables using Custom Cutpoints — binning_numerical_cutpoints","text":"Binning preprocessing step groups continuous values numerical feature smaller number bins. function performs binning based user-defined cutpoints, allows define numerical feature split intervals. resulting bins evaluated using WoE IV metrics, often used predictive modeling, especially credit risk modeling. Weight Evidence (WoE) calculated : $$\\text{WoE} = \\log\\left(\\frac{\\text{Positive Rate}}{\\text{Negative Rate}}\\right)$$ Positive Rate proportion positive observations (target = 1) within bin, Negative Rate proportion negative observations (target = 0) within bin. Information Value (IV) measures predictive power numerical feature calculated : $$IV = \\sum (\\text{Positive Rate} - \\text{Negative Rate}) \\times \\text{WoE}$$ IV metric provides insight well binned feature predicts target variable: IV < 0.02: predictive 0.02 <= IV < 0.1: Weak predictive power 0.1 <= IV < 0.3: Medium predictive power IV >= 0.3: Strong predictive power WoE transformation helps convert numerical variable continuous numeric feature, can directly used logistic regression predictive models, improving model interpretability performance.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/binning_numerical_cutpoints.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Binning Numerical Variables using Custom Cutpoints — binning_numerical_cutpoints","text":"Siddiqi, N. (2006). Credit Risk Scorecards: Developing Implementing Intelligent Credit Scoring. John Wiley & Sons.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/binning_numerical_cutpoints.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Binning Numerical Variables using Custom Cutpoints — binning_numerical_cutpoints","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/binning_numerical_cutpoints.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Binning Numerical Variables using Custom Cutpoints — binning_numerical_cutpoints","text":"","code":"if (FALSE) { # \\dontrun{ # Example usage feature <- c(23, 45, 34, 25, 56, 48, 35, 29, 53, 41) target <- c(1, 0, 1, 1, 0, 0, 0, 1, 1, 0) cutpoints <- c(30, 40, 50) result <- binning_numerical_cutpoints(feature, target, cutpoints) print(result$woefeature)  # WoE-transformed feature print(result$woebin)      # WoE and IV statistics for each bin } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/coef.oblr.html","id":null,"dir":"Reference","previous_headings":"","what":"Coefficients Method for oblr Objects — coef.oblr","title":"Coefficients Method for oblr Objects — coef.oblr","text":"Extracts estimated coefficients oblr model.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/coef.oblr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coefficients Method for oblr Objects — coef.oblr","text":"","code":"# S3 method for class 'oblr' coef(object, ...)"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/coef.oblr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coefficients Method for oblr Objects — coef.oblr","text":"object object class oblr. ... Additional arguments passed methods.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/coef.oblr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coefficients Method for oblr Objects — coef.oblr","text":"numeric vector estimated coefficients.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/computeMetrics.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Performance Metrics for Logistic Regression Models — computeMetrics","title":"Compute Performance Metrics for Logistic Regression Models — computeMetrics","text":"Calculates various performance metrics oblr model.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/computeMetrics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Performance Metrics for Logistic Regression Models — computeMetrics","text":"","code":"computeMetrics(object, newdata = NULL, cutoff = 0.5)"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/computeMetrics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Performance Metrics for Logistic Regression Models — computeMetrics","text":"object object class \"oblr\". newdata data frame data.table containing new data evaluation. NULL, uses data fit. cutoff probability cutoff class prediction. Default 0.5.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/computeMetrics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Performance Metrics for Logistic Regression Models — computeMetrics","text":"data.table calculated metrics.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/computeMetrics.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute Performance Metrics for Logistic Regression Models — computeMetrics","text":"function calculates following metrics: Log-likelihood (LogLik): $$LogLik = \\sum_{=1}^n [y_i \\log(p_i) + (1-y_i) \\log(1-p_i)]$$ \\(y_i\\) observed values \\(p_i\\) predicted probabilities. Akaike Information Criterion (AIC): $$AIC = 2k - 2LogLik$$ \\(k\\) number parameters model. Bayesian Information Criterion (BIC): $$BIC = k\\log(n) - 2LogLik$$ \\(n\\) number observations. Area ROC Curve (AUC): AUC area Receiver Operating Characteristic curve, plots true positive rate false positive rate. Gini Coefficient: $$Gini = 2 * AUC - 1$$ Kolmogorov-Smirnov Statistic (KS): $$KS = \\max|F_1(x) - F_0(x)|$$ \\(F_1(x)\\) \\(F_0(x)\\) cumulative distribution functions positive negative classes, respectively. Accuracy: $$Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$$ TP = True Positives, TN = True Negatives, FP = False Positives, FN = False Negatives. Recall (Sensitivity): $$Recall = \\frac{TP}{TP + FN}$$ Precision: $$Precision = \\frac{TP}{TP + FP}$$ F1-Score: $$F1 = 2 * \\frac{Precision * Recall}{Precision + Recall}$$ metrics provide comprehensive view model's performance, including predictive capability (AUC, KS), fit data (LogLik, AIC, BIC), performance classification tasks (Accuracy, Recall, Precision, F1-Score).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/configure_parallel_setup.html","id":null,"dir":"Reference","previous_headings":"","what":"Configure Parallel Processing for Package Installation — configure_parallel_setup","title":"Configure Parallel Processing for Package Installation — configure_parallel_setup","text":"function detects operating system sets environment parallel processing package installation. determines number cores use based system's capabilities sets appropriate compiler flags OpenMP support.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/configure_parallel_setup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Configure Parallel Processing for Package Installation — configure_parallel_setup","text":"","code":"configure_parallel_setup()"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/configure_parallel_setup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Configure Parallel Processing for Package Installation — configure_parallel_setup","text":"list following components: os Detected operating system (Windows, macOS, Linux) cores Number cores use parallel processing openmp_flags Compiler flags OpenMP support","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/configure_parallel_setup.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Configure Parallel Processing for Package Installation — configure_parallel_setup","text":"function performs following tasks: Detects operating system. Determines number available cores, using conservative approach. Sets appropriate compiler flags OpenMP based OS. macOS, checks OpenMP available provides alternative flags. function designed called silently package installation, typically within .onLoad() function package.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/configure_parallel_setup.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Configure Parallel Processing for Package Installation — configure_parallel_setup","text":"function conservative core allocation avoid system overload. uses 50% available cores systems 2 cores.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/configure_parallel_setup.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Configure Parallel Processing for Package Installation — configure_parallel_setup","text":"","code":"if (FALSE) { # \\dontrun{ parallel_setup <- configure_parallel_setup() print(parallel_setup) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/fit_logistic_regression.html","id":null,"dir":"Reference","previous_headings":"","what":"Logistic Regression with Optional Hessian Calculation — fit_logistic_regression","title":"Logistic Regression with Optional Hessian Calculation — fit_logistic_regression","text":"function performs logistic regression using gradient-based optimization algorithm (L-BFGS) provides option compute Hessian matrix variance estimation. supports dense sparse matrices input.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/fit_logistic_regression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logistic Regression with Optional Hessian Calculation — fit_logistic_regression","text":"","code":"fit_logistic_regression(X_r, y_r, maxit = 300L, eps_f = 1e-08, eps_g = 1e-05)"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/fit_logistic_regression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logistic Regression with Optional Hessian Calculation — fit_logistic_regression","text":"X_r matrix predictor variables. can dense matrix (MatrixXd) sparse matrix (dgCMatrix). y_r numeric vector binary target values (0 1). maxit Maximum number iterations L-BFGS optimization algorithm (default: 300). eps_f Convergence tolerance function value (default: 1e-8). eps_g Convergence tolerance gradient (default: 1e-5).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/fit_logistic_regression.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Logistic Regression with Optional Hessian Calculation — fit_logistic_regression","text":"list containing following elements: coefficients numeric vector estimated coefficients predictor variable. se numeric vector standard errors coefficients, computed inverse Hessian (applicable). z_scores Z-scores coefficient, calculated ratio coefficient standard error. p_values P-values corresponding Z-scores coefficient. loglikelihood negative log-likelihood final model. gradient gradient log-likelihood function final estimate. hessian Hessian matrix log-likelihood function, used compute standard errors. convergence boolean indicating whether optimization algorithm converged successfully. iterations number iterations performed optimization algorithm. message message indicating whether model converged .","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/fit_logistic_regression.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Logistic Regression with Optional Hessian Calculation — fit_logistic_regression","text":"logistic regression model fitted using L-BFGS optimization algorithm. sparse matrices, algorithm automatically detects handles matrix efficiently. log-likelihood function logistic regression maximized: $$\\log(L(\\beta)) = \\sum_{=1}^{n} \\left( y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i) \\right)$$ \\(p_i\\) predicted probability observation \\(\\). Hessian matrix computed estimate variance coefficients, necessary calculating standard errors, Z-scores, p-values.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/fit_logistic_regression.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Logistic Regression with Optional Hessian Calculation — fit_logistic_regression","text":"Nocedal, J., & Wright, S. J. (2006). Numerical Optimization. Springer Science & Business Media. Bishop, C. M. (2006). Pattern Recognition Machine Learning. Springer.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/fit_logistic_regression.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Logistic Regression with Optional Hessian Calculation — fit_logistic_regression","text":"José E. Lopes","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/fit_logistic_regression.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Logistic Regression with Optional Hessian Calculation — fit_logistic_regression","text":"","code":"if (FALSE) { # \\dontrun{ # Create sample data set.seed(123) X <- matrix(rnorm(1000), ncol = 10) y <- rbinom(100, 1, 0.5)  # Run logistic regression result <- fit_logistic_regression(X, y)  # View results print(result$coefficients) print(result$p_values) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/fitted.oblr.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitted Values Method for oblr Objects — fitted.oblr","title":"Fitted Values Method for oblr Objects — fitted.oblr","text":"Returns fitted values (predicted probabilities) oblr model.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/fitted.oblr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitted Values Method for oblr Objects — fitted.oblr","text":"","code":"# S3 method for class 'oblr' fitted(object, ...)"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/fitted.oblr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitted Values Method for oblr Objects — fitted.oblr","text":"object object class oblr. ... Additional arguments passed methods.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/fitted.oblr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitted Values Method for oblr Objects — fitted.oblr","text":"numeric vector fitted values.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/logLik.oblr.html","id":null,"dir":"Reference","previous_headings":"","what":"Log-Likelihood Method for oblr Objects — logLik.oblr","title":"Log-Likelihood Method for oblr Objects — logLik.oblr","text":"Returns log-likelihood oblr model.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/logLik.oblr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log-Likelihood Method for oblr Objects — logLik.oblr","text":"","code":"# S3 method for class 'oblr' logLik(object, ...)"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/logLik.oblr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log-Likelihood Method for oblr Objects — logLik.oblr","text":"object object class oblr. ... Additional arguments passed methods.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/logLik.oblr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log-Likelihood Method for oblr Objects — logLik.oblr","text":"object class logLik containing log-likelihood.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/oblr.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimized Logistic Regression — oblr","title":"Optimized Logistic Regression — oblr","text":"Fits logistic regression models using optimized C++ implementation via Rcpp.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/oblr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimized Logistic Regression — oblr","text":"","code":"oblr(formula, data, max_iter = 1000, tol = 1e-06)"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/oblr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimized Logistic Regression — oblr","text":"formula object class formula describing model fitted. data data frame data.table containing model data. max_iter Maximum number iterations optimization algorithm. Default 1000. tol Convergence tolerance optimization algorithm. Default 1e-6.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/oblr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimized Logistic Regression — oblr","text":"object class oblr containing results logistic regression fit, including: coefficients Vector estimated coefficients. se Standard errors coefficients. z_scores Z-statistics coefficients. p_values P-values coefficients. loglikelihood Log-likelihood model. convergence Convergence indicator. iterations Number iterations performed. message Convergence message. data List containing design matrix X, response y, function call.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/oblr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimized Logistic Regression — oblr","text":"oblr function fits logistic regression model using optimized C++ implementation via Rcpp. implementation designed efficient, especially large sparse datasets. logistic regression model defined : $$P(Y=1|X) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 X_1 + ... + \\beta_p X_p)}}$$ \\(\\beta\\) coefficients estimated. optimization method used L-BFGS (Limited-memory Broyden-Fletcher-Goldfarb-Shanno), variant BFGS method uses limited amount memory. method particularly effective optimization problems many variables. estimation process involves following steps: Data preparation: design matrix X created using sparse.model.matrix Matrix package, efficient sparse data. Optimization: C++ function fit_logistic_regression called perform optimization using L-BFGS. Statistics calculation: Standard errors, z-statistics, p-values calculated using Hessian matrix returned optimization function. Convergence determined relative change objective function (log-likelihood) successive iterations, compared specified tolerance.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/oblr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimized Logistic Regression — oblr","text":"","code":"if (FALSE) { # \\dontrun{ library(data.table)  # Create example data set.seed(123) n <- 10000 X1 <- rnorm(n) X2 <- rnorm(n) Y <- rbinom(n, 1, plogis(1 + 0.5 * X1 - 0.5 * X2)) dt <- data.table(Y, X1, X2)  # Fit logistic regression model model <- oblr(Y ~ X1 + X2, data = dt, max_iter = 1000, tol = 1e-6)  # View results print(model) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/obwoe.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning and Weight of Evidence Calculation — obwoe","title":"Optimal Binning and Weight of Evidence Calculation — obwoe","text":"function performs optimal binning calculates Weight Evidence (WoE) numerical categorical features. implements variety advanced binning algorithms discretize continuous variables optimize categorical variables predictive modeling, particularly credit scoring risk assessment applications. function supports automatic method selection, data preprocessing, handles numerical categorical features. aims maximize predictive power features maintaining interpretability monotonic binning information value optimization.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/obwoe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning and Weight of Evidence Calculation — obwoe","text":"","code":"obwoe(   dt,   target,   features = NULL,   min_bins = 3,   max_bins = 4,   method = \"fetb\",   positive = \"bad|1\",   preprocess = TRUE,   progress = TRUE,   trace = FALSE,   outputall = TRUE,   control = list() )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/obwoe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning and Weight of Evidence Calculation — obwoe","text":"dt data.table containing dataset. target name target variable (must binary). features Vector feature names process. NULL, features except target processed. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 4). method binning method use. Can \"auto\" one methods listed details section. positive Character string specifying category considered positive. Must either \"bad|1\" \"good|1\". preprocess Logical. Whether preprocess data binning (default: TRUE). progress Logical. Whether display progress bar. Default TRUE. trace Logical. Whether generate error logs testing existing methods. outputall Logical. TRUE, returns optimal binning gains table. FALSE, returns list data, gains table, reports (default: TRUE). control list additional control parameters: cat_cutoff: Minimum frequency category (default: 0.05) bin_cutoff: Minimum frequency bin (default: 0.05) min_bads: Minimum proportion bad cases bin (default: 0.05) pvalue_threshold: P-value threshold statistical tests (default: 0.05) max_n_prebins: Maximum number pre-bins (default: 20) monotonicity_direction: Direction monotonicity algorithms (\"increase\" \"decrease\") lambda: Regularization parameter algorithms (default: 0.1) min_bin_size: Minimum bin size proportion total observations (default: 0.05) min_iv_gain: Minimum IV gain bin splitting algorithms (default: 0.01) max_depth: Maximum depth tree-based algorithms (default: 10) num_miss_value: Value replace missing numeric values (default: -999.0) char_miss_value: Value replace missing categorical values (default: \"N/\") outlier_method: Method outlier detection (\"iqr\", \"zscore\", \"grubbs\") outlier_process: Whether process outliers (default: FALSE) iqr_k: IQR multiplier outlier detection (default: 1.5) zscore_threshold: Z-score threshold outlier detection (default: 3) grubbs_alpha: Significance level Grubbs' test (default: 0.05) n_threads: Number threads parallel processing (default: 1) is_monotonic: Whether enforce monotonicity binning (default: TRUE) population_size: Population size genetic algorithm (default: 50) max_generations: Maximum number generations genetic algorithm (default: 100) mutation_rate: Mutation rate genetic algorithm (default: 0.1) initial_temperature: Initial temperature simulated annealing (default: 1) cooling_rate: Cooling rate simulated annealing (default: 0.995) max_iterations: Maximum number iterations iterative algorithms (default: 1000) include_upper_bound: Include upper bound numeric bins (default TRUE) bin_separator: Bin separator optimal bins categorical variables (default = \"%;%\")","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/obwoe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning and Weight of Evidence Calculation — obwoe","text":"Depending value outputall: outputall = FALSE: data.table containing optimal binning gains table (woebin). outputall = TRUE: list containing: data original dataset added WoE columns woebin Information bins created, including: feature: Name feature bin: Bin label range count: Number observations bin count_distr: Proportion observations bin good: Number good cases (target = 0) bin bad: Number bad cases (target = 1) bin good_rate: Proportion good cases bin bad_rate: Proportion bad cases bin woe: Weight Evidence bin iv: Information Value contribution bin report_best_model Report best tested models, including: feature: Name feature method: Best method selected feature iv_total: Total Information Value achieved n_bins: Number bins created runtime: Execution time binning feature report_preprocess Preprocessing report feature, including: feature: Name feature type: Data type feature missing_count: Number missing values outlier_count: Number outliers detected unique_count: Number unique values mean_before: Mean value preprocessing mean_after: Mean value preprocessing sd_before: Standard deviation preprocessing sd_after: Standard deviation preprocessing","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/obwoe.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning and Weight of Evidence Calculation — obwoe","text":"Supported Algorithms: function implements following binning algorithms: Categorical Variables: FETB (Fisher's Exact Test Binning): Uses Fisher's exact test binning CM (ChiMerge): Merges categories based chi-square statistic UDT (Unsupervised Decision Trees): Uses decision tree algorithms categorical binning IVB (Information Value Binning): Bins based information value GMB (Greedy Monotonic Binning): Uses greedy approach create monotonic bins categories SWB (Sliding Window Binning): Adapts sliding window approach categorical variables DPLC (Dynamic Programming Local Constraints): Applies dynamic programming local constraints MOB (Monotonic Optimal Binning): Ensures monotonicity Weight Evidence across categories MBA (Modified Binning Algorithm): modified approach categorical variable binning MILP (Mixed Integer Linear Programming): Applies mixed integer linear programming categorical binning SAB (Simulated Annealing Binning): Uses simulated annealing optimal binning Numerical Variables: UDT (Unsupervised Decision Trees): Applies decision tree algorithms unsupervised manner binning MDLP (Minimum Description Length Principle): Uses MDLP criterion binning MOB (Monotonic Optimal Binning): Ensures monotonicity Weight Evidence across bins MBLP (Monotonic Binning via Linear Programming): Uses linear programming monotonic binning DPLC (Dynamic Programming Local Constraints): Uses dynamic programming local constraints LPDB (Local Polynomial Density Binning): Employs local polynomial density estimation UBSD (Unsupervised Binning Standard Deviation): Uses standard deviation unsupervised binning FETB (Fisher's Exact Test Binning): Applies Fisher's exact test numerical variables EWB (Equal Width Binning): Creates bins equal width across range variable KMB (K-means Binning): Applies k-means clustering binning OSLP (Optimal Supervised Learning Path): Uses supervised learning path optimal binning MRBLP (Monotonic Regression-Based Linear Programming): Combines monotonic regression linear programming IR (Isotonic Regression): Uses isotonic regression binning BB (Branch Bound): Uses branch bound algorithm optimal binning LDB (Local Density Binning): Uses local density estimation binning Key Concepts: Weight Evidence (WoE): $$WoE_i = \\ln\\left(\\frac{P(X_i|Y=1)}{P(X_i|Y=0)}\\right)$$ \\(P(X_i|Y=1)\\) proportion positive cases bin , \\(P(X_i|Y=0)\\) proportion negative cases bin . Information Value (IV): $$IV_i = (P(X_i|Y=1) - P(X_i|Y=0)) \\times WoE_i$$ total IV sum IVs across bins: $$IV_{total} = \\sum_{=1}^{n} IV_i$$ Method Selection: method = \"auto\", function tests multiple algorithms selects one produces highest total Information Value respecting specified constraints.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/obwoe.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning and Weight of Evidence Calculation — obwoe","text":"","code":"if (FALSE) { # \\dontrun{ # Example 1: Using the German Credit Data library(OptimalBinningWoE) library(data.table) library(scorecard) data(germancredit, package = \"scorecard\") dt <- as.data.table(germancredit)  # Process all features with MBLP method result <- obwoe(dt,   target = \"creditability\", method = \"mblp\",   min_bins = 3, max_bins = 5, positive = \"bad|1\" )  # View WoE binning information print(result)  # Process only numeric features with MBLP method and get detailed output numeric_features <- names(dt)[sapply(dt, is.numeric)] numeric_features <- setdiff(numeric_features, \"creditability\")  result_detailed <- obwoe(dt,   target = \"creditability\", features = numeric_features,   method = \"mblp\", preprocess = TRUE, outputall = FALSE,   min_bins = 3, max_bins = 5, positive = \"bad|1\" )  # View WoE-transformed data head(result_detailed$data)  # View preprocessing report print(result_detailed$report_preprocess)  # View best model report print(result_detailed$report_best_model)  # Process only categoric features with UDT method categoric_features <- names(dt)[sapply(dt, function(i) !is.numeric(i))] categoric_features <- setdiff(categoric_features, \"creditability\") result_cat <- obwoe(dt,   target = \"creditability\", features = categoric_features,   method = \"udt\", preprocess = TRUE,   min_bins = 3, max_bins = 4, positive = \"bad|1\" )  # View binning information for categorical features print(result_cat) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_cm.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Categorical Variables (Refined) — optimal_binning_categorical_cm","title":"Optimal Binning for Categorical Variables (Refined) — optimal_binning_categorical_cm","text":"Implementa binning ótimo para variáveis categóricas utilizando o algoritmo Chi-Merge, calculando WoE (Weight Evidence) e IV (Information Value) para os bins resultantes. Este código foi aprimorado para melhor legibilidade, eficiência e robustez, mantendo compatibilidade de tipos e nomes de entrada/saída.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_cm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Categorical Variables (Refined) — optimal_binning_categorical_cm","text":"","code":"optimal_binning_categorical_cm(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   bin_separator = \"%;%\",   convergence_threshold = 1e-06,   max_iterations = 1000L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_cm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Categorical Variables (Refined) — optimal_binning_categorical_cm","text":"target Vetor inteiro com valores binários (0 ou 1) da variável resposta. feature Vetor de caracteres com valores categóricos da variável explicativa. min_bins Número mínimo de bins (default: 3). max_bins Número máximo de bins (default: 5). bin_cutoff Frequência mínima para um bin separado (default: 0.05). max_n_prebins Número máximo de pré-bins antes merging (default: 20). bin_separator Separador para concatenar nomes de categorias em cada bin (default: \"%;%\"). convergence_threshold Limite para convergência da diferença de Qui-quadrado (default: 1e-6). max_iterations Número máximo de iterações para mesclagem de bins (default: 1000).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_cm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Categorical Variables (Refined) — optimal_binning_categorical_cm","text":"Uma lista contendo: bin: Vetor com os nomes dos bins (categorias concatenadas). woe: Vetor com os valores de Weight Evidence de cada bin. iv: Vetor com os valores de Information Value de cada bin. count: Vetor com contagens totais de cada bin. count_pos: Vetor com contagens de casos positivos (target=1) em cada bin. count_neg: Vetor com contagens de casos negativos (target=0) em cada bin. converged: Booleano indicando se o algoritmo convergiu. iterations: Número de iterações executadas.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_cm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Categorical Variables (Refined) — optimal_binning_categorical_cm","text":"O algoritmo utiliza estatísticas de Qui-quadrado para mesclar bins adjacentes até atingir max_bins ou não haver mais merges vantajosos. Após mesclar categorias raras, pré-binagem, e assegurar min_bins, o código aplica monotonicidade WoE, ajustando os bins conforme necessário. Fórmulas: $$\\chi^2 = \\sum_{=1}^{2}\\sum_{j=1}^{2} \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}$$ $$WoE = \\ln\\left(\\frac{P(X|Y=1)}{P(X|Y=0)}\\right)$$ $$IV = (P(X|Y=1)-P(X|Y=0))*WoE$$","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_cm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Categorical Variables (Refined) — optimal_binning_categorical_cm","text":"","code":"if (FALSE) { # \\dontrun{ target <- c(1, 0, 1, 1, 0, 1, 0, 0, 1, 1) feature <- c(\"A\", \"B\", \"A\", \"C\", \"B\", \"D\", \"C\", \"A\", \"D\", \"B\") result <- optimal_binning_categorical_cm(target, feature, min_bins = 2, max_bins = 4) print(result) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_dplc.html","id":null,"dir":"Reference","previous_headings":"","what":"Binning Ótimo para Variáveis Categóricas usando Programação Dinâmica com Restrições Lineares (Versão Aprimorada) — optimal_binning_categorical_dplc","title":"Binning Ótimo para Variáveis Categóricas usando Programação Dinâmica com Restrições Lineares (Versão Aprimorada) — optimal_binning_categorical_dplc","text":"Este código implementa o binning ótimo para variáveis categóricas utilizando programação dinâmica, impondo restrições lineares e buscando maximizar o IV (Information Value). O algoritmo: Pré-processa dados, unindo categorias raras. Ordena categorias por taxas de evento. Aplica programação dinâmica para encontrar solução ótima em termos de IV. Impõe monotonicidade quando possível. Retorna bins finais com WoE e IV calculados. melhorias incluem: Organização e clareza código. Comentários detalhados. Uso de funções inline e estruturas de dados eficientes. Redução de cópias desnecessárias. Maior robustez na validação e tratamento de exceções.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_dplc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Binning Ótimo para Variáveis Categóricas usando Programação Dinâmica com Restrições Lineares (Versão Aprimorada) — optimal_binning_categorical_dplc","text":"","code":"optimal_binning_categorical_dplc(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   convergence_threshold = 1e-06,   max_iterations = 1000L,   bin_separator = \"%;%\" )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_dplc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Binning Ótimo para Variáveis Categóricas usando Programação Dinâmica com Restrições Lineares (Versão Aprimorada) — optimal_binning_categorical_dplc","text":"target Vetor inteiro binário (0 ou 1) target. feature Vetor de strings categóricas. min_bins Número mínimo de bins (default: 3). max_bins Número máximo de bins (default: 5). bin_cutoff Proporção mínima para um bin separado (default: 0.05). max_n_prebins Número máximo de pré-bins antes da mesclagem (default: 20). convergence_threshold Limite para convergência algoritmo (default: 1e-6). max_iterations Número máximo de iterações (default: 1000). bin_separator Separador para concatenar nomes de categorias em cada bin (default: \"%;%\").","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_dplc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Binning Ótimo para Variáveis Categóricas usando Programação Dinâmica com Restrições Lineares (Versão Aprimorada) — optimal_binning_categorical_dplc","text":"Uma lista contendo bin, woe, iv, count, count_pos, count_neg, converged e iterations.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_dplc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Binning Ótimo para Variáveis Categóricas usando Programação Dinâmica com Restrições Lineares (Versão Aprimorada) — optimal_binning_categorical_dplc","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(123) n <- 1000 target <- sample(0:1, n, replace = TRUE) feature <- sample(c(\"A\", \"B\", \"C\", \"D\", \"E\"), n, replace = TRUE) result <- optimal_binning_categorical_dplc(target, feature, min_bins = 2, max_bins = 4) print(result) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_fetb.html","id":null,"dir":"Reference","previous_headings":"","what":"Binning Ótimo para Variáveis Categóricas utilizando Fisher's Exact Test (Versão Fortificada) — optimal_binning_categorical_fetb","title":"Binning Ótimo para Variáveis Categóricas utilizando Fisher's Exact Test (Versão Fortificada) — optimal_binning_categorical_fetb","text":"Este código implementa um binning ótimo para variáveis categóricas utilizando o teste exato de Fisher, calculando WoE (Weight Evidence) e IV (Information Value). Além disso, foram adicionadas melhorias sugeridas por um especialista para garantir robustez, evitar problemas numéricos e tornar o código mais à prova de falhas. Melhorias sugeridas: Verificação adicional de condições limite, garantindo que o algoritmo não trave em cenários extremos. Cálculo mais robusto dos log-factoriais, evitando overflow e garantindo estabilidade numérica. Checagem de valores nulos e tratamento de distâncias zero cálculo de WoE e IV. Manipulação cuidadosa de merges para evitar bins vazios ou degenerados. Comentários detalhados, passo passo, para facilitar manutenção. Pré-alocação e uso criterioso de estruturas para evitar realocações excessivas. Tratamento explícito para casos de min_bins ou max_bins próximos ao número de categorias. Funções auxiliares inline para operações repetitivas, reduzindo risco de erros. Conservadorismo nos testes estatísticos: uso de EPSILON para evitar log de zero.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_fetb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Binning Ótimo para Variáveis Categóricas utilizando Fisher's Exact Test (Versão Fortificada) — optimal_binning_categorical_fetb","text":"","code":"optimal_binning_categorical_fetb(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   convergence_threshold = 1e-06,   max_iterations = 1000L,   bin_separator = \"%;%\" )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_fetb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Binning Ótimo para Variáveis Categóricas utilizando Fisher's Exact Test (Versão Fortificada) — optimal_binning_categorical_fetb","text":"target Vetor inteiro binário (0 ou 1) target. feature Vetor de strings categóricas da variável explicativa. min_bins Número mínimo de bins (default: 3). max_bins Número máximo de bins (default: 5). bin_cutoff Frequência mínima para manter um bin separado (default: 0.05). max_n_prebins Máximo de pré-bins antes da mesclagem (default: 20). convergence_threshold Limite de convergência (default: 1e-6). max_iterations Máximo de iterações (default: 1000). bin_separator Separador para nomes de categorias (default: \"%;%\").","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_fetb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Binning Ótimo para Variáveis Categóricas utilizando Fisher's Exact Test (Versão Fortificada) — optimal_binning_categorical_fetb","text":"Uma lista contendo: bin: Nomes dos bins. woe: Vetor numérico de WoE por bin. iv: Vetor numérico de IV por bin. count: Contagem total por bin. count_pos: Contagem de positivos por bin. count_neg: Contagem de negativos por bin. converged: Booleano indicando se houve convergência. iterations: Número de iterações executadas.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_fetb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Binning Ótimo para Variáveis Categóricas utilizando Fisher's Exact Test (Versão Fortificada) — optimal_binning_categorical_fetb","text":"O algoritmo utiliza o teste exato de Fisher para mesclar bins adjacentes, buscando maximizar separação estatística. Ao final, assegura monotonicidade e respeita restrições de número mínimo e máximo de bins. Foram implementados cuidados extras para evitar overflows, problemas de ponto flutuante e falta de convergência.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_fetb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Binning Ótimo para Variáveis Categóricas utilizando Fisher's Exact Test (Versão Fortificada) — optimal_binning_categorical_fetb","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(123) target <- sample(0:1, 1000, replace = TRUE) feature <- sample(LETTERS[1:5], 1000, replace = TRUE) result <- optimal_binning_categorical_fetb(target, feature, min_bins = 2,  max_bins = 4, bin_separator = \"|\") print(result) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_gmb.html","id":null,"dir":"Reference","previous_headings":"","what":"Binning Ótimo para Variáveis Categóricas usando Abordagem Gulosa (Versão Aprimorada) — optimal_binning_categorical_gmb","title":"Binning Ótimo para Variáveis Categóricas usando Abordagem Gulosa (Versão Aprimorada) — optimal_binning_categorical_gmb","text":"Este código implementa o binning ótimo para variáveis categóricas usando uma abordagem de mesclagem gulosa (Greedy Merge Binning), calculando WoE e IV. Foi aperfeiçoado para maior robustez, estabilidade numérica e para lidar com casos extremos de forma mais consistente. Melhorias sugeridas pelo \"especialista jedi\": Tratamento mais rigoroso de inputs, incluindo checagem de valores ausentes. Uso de epsilon e verificações para evitar log(0) e divisão por zero, garantindo maior estabilidade numérica. Comentários adicionais e refatoração para tornar o código mais legível e de fácil manutenção. Maior cuidado ao mesclar bins para evitar bins vazios ou malformados. Mecanismos para detectar cenários de falha na convergência, avisando ao usuário. Pré-alocação de vetores para evitar realocações frequentes, sempre que possível. Log de progresso/erros (utilizando avisos Rcpp::warning, caso seja necessário).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_gmb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Binning Ótimo para Variáveis Categóricas usando Abordagem Gulosa (Versão Aprimorada) — optimal_binning_categorical_gmb","text":"","code":"optimal_binning_categorical_gmb(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   bin_separator = \"%;%\",   convergence_threshold = 1e-06,   max_iterations = 1000L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_gmb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Binning Ótimo para Variáveis Categóricas usando Abordagem Gulosa (Versão Aprimorada) — optimal_binning_categorical_gmb","text":"target Vetor inteiro binário (0 ou 1) da variável resposta. feature Vetor de caracteres com valores categóricos da variável explicativa. min_bins Número mínimo de bins (default: 3). max_bins Número máximo de bins (default: 5). bin_cutoff Frequência mínima para um bin separado (default: 0.05). max_n_prebins Número máximo de pré-bins antes da fusão (default: 20). bin_separator Separador de categorias nome bin (default: \"%;%\"). convergence_threshold Limite de convergência para variação de IV (default: 1e-6). max_iterations Número máximo de iterações (default: 1000).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_gmb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Binning Ótimo para Variáveis Categóricas usando Abordagem Gulosa (Versão Aprimorada) — optimal_binning_categorical_gmb","text":"Uma lista contendo: bin: Vetor de strings com os nomes dos bins. woe: Vetor numérico com o WoE de cada bin. iv: Vetor numérico com o IV de cada bin. count: Contagem total em cada bin. count_pos: Contagem de casos positivos em cada bin. count_neg: Contagem de casos negativos em cada bin. converged: Booleano indicando se o algoritmo convergiu. iterations: Número de iterações executadas.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_gmb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Binning Ótimo para Variáveis Categóricas usando Abordagem Gulosa (Versão Aprimorada) — optimal_binning_categorical_gmb","text":"O algoritmo: Cria um bin para cada categoria única, classificando-os pelo ratio de positivos. Mescla categorias raras (frequência < bin_cutoff) em um bin próprio para manter estabilidade. Executa mesclas gulosas de bins adjacentes que maximizam o IV total. Para quando atinge min_bins, max_bins ou convergência IV. Impõe monotonicidade WoE, se necessário, fundindo bins violadores da monotonicidade.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_gmb.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Binning Ótimo para Variáveis Categóricas usando Abordagem Gulosa (Versão Aprimorada) — optimal_binning_categorical_gmb","text":"Beltrami, M., Mach, M., & Dall'Aglio, M. (2021). \"Monotonic Optimal Binning Algorithm Credit Risk Modeling.\" Risks, 9(3), 58. Siddiqi, N. (2006). Credit risk scorecards: developing implementing intelligent credit scoring. John Wiley & Sons.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_gmb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Binning Ótimo para Variáveis Categóricas usando Abordagem Gulosa (Versão Aprimorada) — optimal_binning_categorical_gmb","text":"","code":"if (FALSE) { # \\dontrun{ # Exemplo target <- c(1, 0, 1, 1, 0, 1, 0, 0, 1, 1) feature <- c(\"A\", \"B\", \"A\", \"C\", \"B\", \"D\", \"C\", \"A\", \"D\", \"B\") result <- optimal_binning_categorical_gmb(target, feature, min_bins = 2, max_bins = 4) print(result) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_ivb.html","id":null,"dir":"Reference","previous_headings":"","what":"Binning Ótimo para Variáveis Categóricas usando IVB — optimal_binning_categorical_ivb","title":"Binning Ótimo para Variáveis Categóricas usando IVB — optimal_binning_categorical_ivb","text":"Este código implementa um binning ótimo para variáveis categóricas utilizando um approach baseado em Information Value (IV) com programação dinâmica. Foram adicionadas melhorias para garantir robustez, estabilidade numérica e melhor manutenibilidade: Verificações de input mais rigorosas. Uso de epsilon para evitar log(0). Controle sobre min_bins e max_bins com base número de categorias. Tratamento de categorias raras e imposição de monotonicidade WoE/Taxas de evento. Comentários mais detalhados, melhor estruturação de código e checagem de convergência.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_ivb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Binning Ótimo para Variáveis Categóricas usando IVB — optimal_binning_categorical_ivb","text":"","code":"optimal_binning_categorical_ivb(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   bin_separator = \"%;%\",   convergence_threshold = 1e-06,   max_iterations = 1000L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_ivb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Binning Ótimo para Variáveis Categóricas usando IVB — optimal_binning_categorical_ivb","text":"target Vetor inteiro binário (0 ou 1) da variável resposta. feature Vetor de caracteres ou fator com os valores categóricos da variável explicativa. min_bins Número mínimo de bins (default: 3). max_bins Número máximo de bins (default: 5). bin_cutoff Frequência mínima para um bin separado (default: 0.05). max_n_prebins Máximo de pré-bins antes da fusão (default: 20). bin_separator Separador para nomes de categorias mescladas (default: \"%;%\"). convergence_threshold Limite de convergência IV (default: 1e-6). max_iterations Máximo de iterações na busca da solução ótima (default: 1000).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_ivb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Binning Ótimo para Variáveis Categóricas usando IVB — optimal_binning_categorical_ivb","text":"Uma lista contendo: bin: Vetor com os nomes dos bins formados. woe: Vetor numérico com WoE de cada bin. iv: Vetor numérico com IV de cada bin. count, count_pos, count_neg: Contagens total, positiva e negativa por bin. converged: Booleano indicando se o algoritmo convergiu. iterations: Número de iterações executadas.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_ivb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Binning Ótimo para Variáveis Categóricas usando IVB — optimal_binning_categorical_ivb","text":"","code":"if (FALSE) { # \\dontrun{ target <- c(1,0,1,1,0,1,0,0,1,1) feature <- c(\"A\",\"B\",\"A\",\"C\",\"B\",\"D\",\"C\",\"A\",\"D\",\"B\") result <- optimal_binning_categorical_ivb(target, feature, min_bins = 2, max_bins = 4) print(result) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_jedi.html","id":null,"dir":"Reference","previous_headings":"","what":"Binning Ótimo Categórico JEDI (Discretização Conjunta Guiada por Entropia) — optimal_binning_categorical_jedi","title":"Binning Ótimo Categórico JEDI (Discretização Conjunta Guiada por Entropia) — optimal_binning_categorical_jedi","text":"Um algoritmo robusto de binning categórico que otimiza o valor de informação (IV) mantendo relações monotônicas de weight evidence (WoE). Implementa uma estratégia adaptativa de fusão com proteções de estabilidade numérica e controle sofisticado número de bins.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_jedi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Binning Ótimo Categórico JEDI (Discretização Conjunta Guiada por Entropia) — optimal_binning_categorical_jedi","text":"","code":"optimal_binning_categorical_jedi(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   bin_separator = \"%;%\",   convergence_threshold = 1e-06,   max_iterations = 1000L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_jedi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Binning Ótimo Categórico JEDI (Discretização Conjunta Guiada por Entropia) — optimal_binning_categorical_jedi","text":"target Vetor inteiro binário (0 ou 1) representando variável resposta feature Vetor de caracteres dos valores categóricos preditores min_bins Número mínimo de bins de saída (padrão: 3). Ajustado se categorias únicas < min_bins max_bins Número máximo de bins de saída (padrão: 5). Deve ser >= min_bins bin_cutoff Limite mínimo de frequência relativa para bins individuais (padrão: 0.05) max_n_prebins Número máximo de pré-bins antes da otimização (padrão: 20) bin_separator Delimitador para nomes de categorias combinadas (padrão: \"%;%\") convergence_threshold Limite de diferença de IV para convergência (padrão: 1e-6) max_iterations Máximo de iterações de otimização (padrão: 1000)","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_jedi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Binning Ótimo Categórico JEDI (Discretização Conjunta Guiada por Entropia) — optimal_binning_categorical_jedi","text":"Uma lista contendo: bin: Vetor de caracteres com nomes dos bins (categorias concatenadas) woe: Vetor numérico com valores de Weight Evidence iv: Vetor numérico com valores de Information Value por bin count: Vetor inteiro com contagens de observações por bin count_pos: Vetor inteiro com contagens da classe positiva por bin count_neg: Vetor inteiro com contagens da classe negativa por bin converged: Lógico indicando se o algoritmo convergiu iterations: Contagem inteira de iterações de otimização realizadas","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_jedi.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Binning Ótimo Categórico JEDI (Discretização Conjunta Guiada por Entropia) — optimal_binning_categorical_jedi","text":"O algoritmo emprega uma abordagem de otimização em múltiplas fases: Framework Matemático: Para um bin , o WoE é calculado como: $$WoE_i = ln(\\frac{p_i + \\epsilon}{n_i + \\epsilon})$$ onde: \\(p_i\\) é proporção de casos positivos bin relativo ao total de positivos \\(n_i\\) é proporção de casos negativos bin relativo ao total de negativos \\(\\epsilon\\) é uma pequena constante (1e-10) para prevenir logaritmos indefinidos O IV para cada bin é calculado como: $$IV_i = (p_i - n_i) \\times WoE_i$$ E o IV total é: $$IV_{total} = \\sum_{=1}^{k} IV_i$$ Fases: Binning Inicial: Cria bins individuais para categorias únicas com validação de frequência Tratamento de Baixa Frequência: Combina categorias raras (< bin_cutoff) para garantir estabilidade estatística Otimização: Combina bins iterativamente usando minimização de perda de IV mantendo monotonicidade de WoE Ajuste Final: Garante restrições de contagem de bins (min_bins <= bins <= max_bins) quando possível Características Principais: Cálculos de WoE protegidos por epsilon para estabilidade numérica Estratégia adaptativa de fusão que minimiza perda de informação Tratamento robusto de casos extremos e violações de restrições Sem criação artificial de categorias, garantindo resultados interpretáveis Controle de Quantidade de Bins: Se bins > max_bins: Continua fusões usando minimização de perda de IV Se bins < min_bins: Retorna melhor solução disponível em vez de criar divisões artificiais","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_jedi.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Binning Ótimo Categórico JEDI (Discretização Conjunta Guiada por Entropia) — optimal_binning_categorical_jedi","text":"Framework de Binning Ótimo (Beltrami et al., 2021) Teoria Valor da Informação em Gestão de Risco (Thomas et al., 2002) Algoritmos de Binning Monotônico em Credit Scoring (Mironchyk & Tchistiakov, 2017)","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_jedi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Binning Ótimo Categórico JEDI (Discretização Conjunta Guiada por Entropia) — optimal_binning_categorical_jedi","text":"","code":"if (FALSE) { # \\dontrun{ # Uso básico resultado <- optimal_binning_categorical_jedi(   target = c(1,0,1,1,0),   feature = c(\"A\",\"B\",\"A\",\"C\",\"B\"),   min_bins = 2,   max_bins = 3 )  # Tratamento de categorias raras resultado <- optimal_binning_categorical_jedi(   target = vetor_target,   feature = vetor_feature,   bin_cutoff = 0.03,  # Tratamento mais agressivo de categorias raras   max_n_prebins = 15  # Limite de bins iniciais ) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mba.html","id":null,"dir":"Reference","previous_headings":"","what":"Binning Ótimo para Variáveis Categóricas usando MBA (Versão Corrigida) — optimal_binning_categorical_mba","title":"Binning Ótimo para Variáveis Categóricas usando MBA (Versão Corrigida) — optimal_binning_categorical_mba","text":"Este código realiza o binning ótimo para variáveis categóricas utilizando um algoritmo \"Monotonic Binning Algorithm (MBA)\", garantindo que não reduza o número de bins abaixo de min_bins ao impor monotonicidade ou ao otimizar quantidade de bins.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mba.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Binning Ótimo para Variáveis Categóricas usando MBA (Versão Corrigida) — optimal_binning_categorical_mba","text":"","code":"optimal_binning_categorical_mba(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   bin_separator = \"%;%\",   convergence_threshold = 1e-06,   max_iterations = 1000L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mba.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Binning Ótimo para Variáveis Categóricas usando MBA (Versão Corrigida) — optimal_binning_categorical_mba","text":"target Vetor inteiro binário (0 ou 1) target. feature Vetor de caracteres com valores categóricos da variável explicativa. min_bins Número mínimo de bins (default: 3). max_bins Número máximo de bins (default: 5). bin_cutoff Frequência mínima para considerar um bin separado (default: 0.05). max_n_prebins Máximo de pré-bins antes da fusão (default: 20). bin_separator Separador para nomes de categorias em bins mesclados (default: \"%;%\"), convergence_threshold Limite para detectar convergência IV (default: 1e-6). max_iterations Máximo de iterações (default: 1000).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mba.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Binning Ótimo para Variáveis Categóricas usando MBA (Versão Corrigida) — optimal_binning_categorical_mba","text":"Uma lista contendo: bin: Nomes dos bins. woe: WoE de cada bin. iv: IV de cada bin. count: Contagem total por bin. count_pos: Contagem de casos positivos por bin. count_neg: Contagem de casos negativos por bin. converged: Booleano indicando se o algoritmo convergiu. iterations: Número de iterações executadas.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mba.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Binning Ótimo para Variáveis Categóricas usando MBA (Versão Corrigida) — optimal_binning_categorical_mba","text":"Siddiqi, N. (2006). \"Credit Risk Scorecards: Developing Implementing Intelligent Credit Scoring.\"","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_milp.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Categorical Variables using MILP — optimal_binning_categorical_milp","title":"Optimal Binning for Categorical Variables using MILP — optimal_binning_categorical_milp","text":"function performs optimal binning categorical variables using Mixed Integer Linear Programming (MILP) inspired approach.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_milp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Categorical Variables using MILP — optimal_binning_categorical_milp","text":"","code":"optimal_binning_categorical_milp(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   bin_separator = \"%;%\",   convergence_threshold = 1e-06,   max_iterations = 1000L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_milp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Categorical Variables using MILP — optimal_binning_categorical_milp","text":"target integer vector binary target values (0 1). feature character vector feature values. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum proportion total observations bin (default: 0.05). max_n_prebins Maximum number pre-bins (default: 20). bin_separator Separator categories within bin (default: \"%;%\"). convergence_threshold Threshold IV convergence (default: 1e-6). max_iterations Maximum iterations (default: 1000).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_milp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Categorical Variables using MILP — optimal_binning_categorical_milp","text":"list binning results.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_milp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Categorical Variables using MILP — optimal_binning_categorical_milp","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(123) n <- 1000 target <- sample(0:1, n, replace = TRUE) feature <- sample(LETTERS[1:10], n, replace = TRUE) result <- optimal_binning_categorical_milp(target, feature, min_bins = 2, max_bins = 4) print(result) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mob.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Categorical Variables using Monotonic Optimal Binning (MOB) — optimal_binning_categorical_mob","title":"Optimal Binning for Categorical Variables using Monotonic Optimal Binning (MOB) — optimal_binning_categorical_mob","text":"function performs optimal binning categorical variables using Monotonic Optimal Binning (MOB) approach.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mob.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Categorical Variables using Monotonic Optimal Binning (MOB) — optimal_binning_categorical_mob","text":"","code":"optimal_binning_categorical_mob(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   bin_separator = \"%;%\",   convergence_threshold = 1e-06,   max_iterations = 1000L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mob.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Categorical Variables using Monotonic Optimal Binning (MOB) — optimal_binning_categorical_mob","text":"target integer vector binary target values (0 1). feature character vector categorical feature values. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum proportion observations bin (default: 0.05). max_n_prebins Maximum number pre-bins (default: 20). bin_separator Separator used merging category names (default: \"%;%\"). convergence_threshold Convergence threshold algorithm (default: 1e-6). max_iterations Maximum number iterations algorithm (default: 1000).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mob.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Categorical Variables using Monotonic Optimal Binning (MOB) — optimal_binning_categorical_mob","text":"list containing following elements: bin: character vector bin names (merged categories) woe: numeric vector Weight Evidence (WoE) values bin iv: numeric vector Information Value (IV) bin count: integer vector total counts bin count_pos: integer vector positive target counts bin count_neg: integer vector negative target counts bin converged: logical value indicating whether algorithm converged iterations: integer value indicating number iterations run","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mob.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Categorical Variables using Monotonic Optimal Binning (MOB) — optimal_binning_categorical_mob","text":"Este algoritmo aplica o Monotonic Optimal Binning (MOB) para variáveis categóricas. O processo visa maximizar o IV (Information Value) mantendo monotonicidade WoE (Weight Evidence). Passos algoritmo: Cálculo das estatísticas por categoria. Pré-binagem e ordenação por WoE. Aplicação da monotonicidade e ajuste de bins. Limitação número de bins max_bins. Cálculo dos valores finais de WoE e IV.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mob.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Categorical Variables using Monotonic Optimal Binning (MOB) — optimal_binning_categorical_mob","text":"Belotti, T., Crook, J. (2009). Credit Scoring Macroeconomic Variables Using Survival Analysis. Journal Operational Research Society, 60(12), 1699-1707. Mironchyk, P., Tchistiakov, V. (2017). Monotone optimal binning algorithm credit risk modeling. arXiv preprint arXiv:1711.05095.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_mob.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Categorical Variables using Monotonic Optimal Binning (MOB) — optimal_binning_categorical_mob","text":"","code":"if (FALSE) { # \\dontrun{ # Create sample data set.seed(123) target <- sample(0:1, 1000, replace = TRUE) feature <- sample(LETTERS[1:5], 1000, replace = TRUE)  # Run optimal binning result <- optimal_binning_categorical_mob(target, feature)  # View results print(result) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_sab.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Categorical Variables using Simulated Annealing — optimal_binning_categorical_sab","title":"Optimal Binning for Categorical Variables using Simulated Annealing — optimal_binning_categorical_sab","text":"function performs optimal binning categorical variables using Simulated Annealing approach. maximizes Information Value (IV) maintaining monotonicity bins.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_sab.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Categorical Variables using Simulated Annealing — optimal_binning_categorical_sab","text":"","code":"optimal_binning_categorical_sab(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   bin_separator = \"%;%\",   initial_temperature = 1,   cooling_rate = 0.995,   max_iterations = 1000L,   convergence_threshold = 1e-06 )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_sab.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Categorical Variables using Simulated Annealing — optimal_binning_categorical_sab","text":"target integer vector binary target values (0 1). feature character vector categorical feature values. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum proportion observations bin (default: 0.05). max_n_prebins Maximum number pre-bins (default: 20). bin_separator Separator string merging categories (default: \"%;%\"). initial_temperature Initial temperature Simulated Annealing (default: 1.0). cooling_rate Cooling rate Simulated Annealing (default: 0.995). max_iterations Maximum number iterations Simulated Annealing (default: 1000). convergence_threshold Threshold convergence (default: 1e-6).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_sab.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Categorical Variables using Simulated Annealing — optimal_binning_categorical_sab","text":"list containing following elements: bins: character vector bin names woe: numeric vector Weight Evidence (WoE) values bin iv: numeric vector Information Value (IV) bin count: integer vector total counts bin count_pos: integer vector positive counts bin count_neg: integer vector negative counts bin converged: logical value indicating whether algorithm converged iterations: integer value indicating number iterations run","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_sab.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Categorical Variables using Simulated Annealing — optimal_binning_categorical_sab","text":"algorithm uses Simulated Annealing find optimal binning solution maximizes Information Value maintaining monotonicity. respects specified constraints number bins bin sizes. Weight Evidence (WoE) calculated : $$WoE_i = \\ln(\\frac{\\text{Distribution positives}_i}{\\text{Distribution negatives}_i})$$ : $$\\text{Distribution positives}_i = \\frac{\\text{Number positives bin } }{\\text{Total Number positives}}$$ $$\\text{Distribution negatives}_i = \\frac{\\text{Number negatives bin } }{\\text{Total Number negatives}}$$ Information Value (IV) calculated : $$IV = \\sum_{=1}^{N} (\\text{Distribution positives}_i - \\text{Distribution negatives}_i) \\times WoE_i$$","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_sab.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Categorical Variables using Simulated Annealing — optimal_binning_categorical_sab","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(123) target <- sample(0:1, 1000, replace = TRUE) feature <- sample(LETTERS[1:5], 1000, replace = TRUE) result <- optimal_binning_categorical_sab(target, feature) print(result) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_sblp.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Categorical Variables using Similarity-Based Logistic Partitioning (SBLP) — optimal_binning_categorical_sblp","title":"Optimal Binning for Categorical Variables using Similarity-Based Logistic Partitioning (SBLP) — optimal_binning_categorical_sblp","text":"Esta função realiza um binning ótimo para variáveis categóricas utilizando uma abordagem de Similarity-Based Logistic Partitioning (SBLP). O objetivo é produzir bins que maximizem o Information Value (IV) e forneçam Weight Evidence (WOE) consistentes, considerando taxas alvo (target rates) e garantindo qualidade através de merges baseados em similaridade. Foi feita uma revisão para melhorar legibilidade, eficiência, robustez e manutenção da compatibilidade de nomes e tipos dos parâmetros de entrada/saída.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_sblp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Categorical Variables using Similarity-Based Logistic Partitioning (SBLP) — optimal_binning_categorical_sblp","text":"","code":"optimal_binning_categorical_sblp(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   convergence_threshold = 1e-06,   max_iterations = 1000L,   bin_separator = \";\" )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_sblp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Categorical Variables using Similarity-Based Logistic Partitioning (SBLP) — optimal_binning_categorical_sblp","text":"target Vetor inteiro binário (0 ou 1) representando variável resposta. feature Vetor de caracteres com categorias da variável explicativa. min_bins Número mínimo de bins (padrão: 3). max_bins Número máximo de bins (padrão: 5). bin_cutoff Proporção mínima de frequência para que uma categoria seja considerada um bin separado (padrão: 0.05). max_n_prebins Número máximo de pré-bins antes processo de partição (padrão: 20). convergence_threshold Limite para convergência algoritmo (padrão: 1e-6). max_iterations Número máximo de iterações algoritmo (padrão: 1000). bin_separator Separador utilizado para concatenar nomes de categorias nos bins (padrão: \";\").","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_sblp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Categorical Variables using Similarity-Based Logistic Partitioning (SBLP) — optimal_binning_categorical_sblp","text":"Uma lista contendo: bin: Vetor de strings com os nomes dos bins (categorias concatenadas). woe: Vetor numérico com os valores de Weight Evidence (WoE) para cada bin. iv: Vetor numérico com os valores de Information Value (IV) para cada bin. count: Vetor inteiro com contagem total de observações em cada bin. count_pos: Vetor inteiro com contagem de casos positivos (target=1) em cada bin. count_neg: Vetor inteiro com contagem de casos negativos (target=0) em cada bin. converged: Valor lógico indicando se o algoritmo convergiu. iterations: Número inteiro com quantidade de iterações executadas.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_sblp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Categorical Variables using Similarity-Based Logistic Partitioning (SBLP) — optimal_binning_categorical_sblp","text":"Passos algoritmo SBLP: Validação de entrada e cálculo das contagens iniciais por categoria. Tratamento de categorias raras, unindo-com outras similares em termos de taxa alvo. Garantia de número máximo de pré-bins, unindo bins pouco informativos. Ordenação das categorias pela taxa alvo. Aplicação de programação dinâmica para determinação da partição ótima, considerando min_bins e max_bins. Ajuste da monotonicidade WoE, se necessário, desde que o número de bins seja maior que min_bins. Cálculo final WoE e IV de cada bin, retornando o resultado. Fórmulas-chave: $$WoE = \\ln\\left(\\frac{P(X|Y=1)}{P(X|Y=0)}\\right)$$ $$IV = \\sum_{bins} (P(X|Y=1) - P(X|Y=0)) \\times WoE$$","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_sblp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Categorical Variables using Similarity-Based Logistic Partitioning (SBLP) — optimal_binning_categorical_sblp","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(123) target <- sample(0:1, 1000, replace = TRUE) feature <- sample(LETTERS[1:5], 1000, replace = TRUE) result <- optimal_binning_categorical_sblp(target, feature) print(result) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_swb.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Categorical Variables using Sliding Window Binning (SWB) (Refined) — optimal_binning_categorical_swb","title":"Optimal Binning for Categorical Variables using Sliding Window Binning (SWB) (Refined) — optimal_binning_categorical_swb","text":"Esta função realiza um binning ótimo de variáveis categóricas utilizando uma abordagem de Sliding Window Binning (SWB). O objetivo é gerar bins com bom poder preditivo (IV) e monotonicidade WoE, garantindo estabilidade, robustez, e mantendo compatibilidade de nomes e tipos de entrada e saída. Caso variável categórica tenha apenas 1 ou 2 níveis, não será realizada otimização, apenas o cálculo das estatísticas e retorno resultado.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_swb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Categorical Variables using Sliding Window Binning (SWB) (Refined) — optimal_binning_categorical_swb","text":"","code":"optimal_binning_categorical_swb(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   bin_separator = \"%;%\",   convergence_threshold = 1e-06,   max_iterations = 1000L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_swb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Categorical Variables using Sliding Window Binning (SWB) (Refined) — optimal_binning_categorical_swb","text":"target Vetor inteiro binário (0 ou 1) da variável resposta. feature Vetor de caracteres com categorias da variável explicativa. min_bins Número mínimo de bins (padrão: 3). max_bins Número máximo de bins (padrão: 5). bin_cutoff Freqüência mínima para considerar uma categoria como bin separado (padrão: 0.05). max_n_prebins Número máximo de pré-bins antes da fusão (padrão: 20). bin_separator Separador usado ao concatenar nomes de categorias em cada bin (padrão: \"%;%\"). convergence_threshold Limite para convergência IV (padrão: 1e-6). max_iterations Número máximo de iterações para otimização (padrão: 1000).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_swb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Categorical Variables using Sliding Window Binning (SWB) (Refined) — optimal_binning_categorical_swb","text":"Uma lista contendo: bin: Vetor de strings com os nomes dos bins. woe: Vetor numérico com valores de WOE para cada bin. iv: Vetor numérico com valores de IV para cada bin. count: Vetor inteiro com contagem total em cada bin. count_pos: Vetor inteiro com contagem de positivos (target=1) em cada bin. count_neg: Vetor inteiro com contagem de negativos (target=0) em cada bin. converged: Valor lógico indicando se o algoritmo convergiu. iterations: Número inteiro indicando quantas iterações foram executadas.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_swb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Categorical Variables using Sliding Window Binning (SWB) (Refined) — optimal_binning_categorical_swb","text":"Passos algoritmo SWB (ajustado): Inicializa bins para cada categoria, unindo categorias raras (abaixo bin_cutoff). Se variável tiver apenas 1 ou 2 níveis, não otimiza, apenas calcula o WoE/IV e retorna. Caso contrário, ordena bins pelo valor WoE, e funde bins adjacentes conforme necessário, respeitando min_bins e max_bins. Otimiza o número de bins visando monotonicidade WoE e maximização IV, evitando travar em caso de poucas classes. Fórmulas principais: $$WOE = \\ln\\left(\\frac{P(X|Y=1)}{P(X|Y=0)}\\right)$$ $$IV = \\sum (P(X|Y=1) - P(X|Y=0)) \\times WOE$$","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_swb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Categorical Variables using Sliding Window Binning (SWB) (Refined) — optimal_binning_categorical_swb","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(123) target <- sample(0:1, 1000, replace = TRUE) feature <- sample(LETTERS[1:5], 1000, replace = TRUE) result <- optimal_binning_categorical_swb(target, feature) print(result) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_udt.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Categorical Variables using a User-Defined Technique (UDT) (Refined) — optimal_binning_categorical_udt","title":"Optimal Binning for Categorical Variables using a User-Defined Technique (UDT) (Refined) — optimal_binning_categorical_udt","text":"Esta função realiza o binning de variáveis categóricas seguindo uma técnica personalizada (UDT). O objetivo é produzir bins com bom valor informativo (IV) e monotonicidade WoE, evitando criação de categorias artificiais. Caso variável categórica tenha apenas 1 ou 2 níveis únicos, nenhuma otimização é feita, apenas estatísticas são calculadas.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_udt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Categorical Variables using a User-Defined Technique (UDT) (Refined) — optimal_binning_categorical_udt","text":"","code":"optimal_binning_categorical_udt(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   bin_separator = \"%;%\",   convergence_threshold = 1e-06,   max_iterations = 1000L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_udt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Categorical Variables using a User-Defined Technique (UDT) (Refined) — optimal_binning_categorical_udt","text":"target Vetor inteiro binário (0 ou 1) representando variável resposta. feature Vetor de caracteres representando categorias da variável explicativa. min_bins Número mínimo de bins desejado (padrão: 3). max_bins Número máximo de bins desejado (padrão: 5). bin_cutoff Proporção mínima de observações para considerar uma categoria isolada como um bin separado (padrão: 0.05). max_n_prebins Número máximo de pré-bins antes da etapa principal de binning (padrão: 20). bin_separator String usada para separar nomes de categorias unidas em um mesmo bin (padrão: \"%;%\"). convergence_threshold Limite para critério de parada baseado em convergência IV (padrão: 1e-6). max_iterations Número máximo de iterações processo (padrão: 1000).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_udt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Categorical Variables using a User-Defined Technique (UDT) (Refined) — optimal_binning_categorical_udt","text":"Uma lista contendo: bins: Vetor de strings com nomes dos bins. woe: Vetor numérico com os valores de Weight Evidence para cada bin. iv: Vetor numérico com os valores de Information Value para cada bin. count: Vetor inteiro com contagem total de observações em cada bin. count_pos: Vetor inteiro com contagem de casos positivos (target=1) em cada bin. count_neg: Vetor inteiro com contagem de casos negativos (target=0) em cada bin. converged: Valor lógico indicando se o algoritmo convergiu. iterations: Número inteiro indicando quantas iterações foram executadas.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_udt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Categorical Variables using a User-Defined Technique (UDT) (Refined) — optimal_binning_categorical_udt","text":"Passos algoritmo (ajustado): Validação da entrada e criação de bins iniciais, cada um correspondendo uma categoria. Se houver apenas 1 ou 2 níveis, não otimizar, apenas calcular estatísticas e retornar. Agrupamento de categorias de baixa frequência em um bin \"Others\", se necessário. Cálculo WoE e IV de cada bin. Fusões e divisões só acontecem se puderem manter coerência com categorias originais. Não são criados nomes artificiais como \"no_split\". Caso não seja possível dividir coerentemente (por exemplo, um bin com apenas uma categoria), não dividir. Monotonicidade WoE é assegurada ao final, ordenando-se os bins pelo WoE. O processo itera até convergência (diferença IV < convergence_threshold) ou max_iterations.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_categorical_udt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Categorical Variables using a User-Defined Technique (UDT) (Refined) — optimal_binning_categorical_udt","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(123) target <- sample(0:1, 1000, replace = TRUE) feature <- sample(LETTERS[1:5], 1000, replace = TRUE) result <- optimal_binning_categorical_udt(target, feature) print(result) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_bb.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using Branch and Bound — optimal_binning_numerical_bb","title":"Optimal Binning for Numerical Variables using Branch and Bound — optimal_binning_numerical_bb","text":"function optimizes numerical variable binning using Branch Bound approach, ensuring stable high-quality bins predictive modeling.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_bb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using Branch and Bound — optimal_binning_numerical_bb","text":"","code":"optimal_binning_numerical_bb(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   is_monotonic = TRUE,   convergence_threshold = 1e-06,   max_iterations = 1000L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_bb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using Branch and Bound — optimal_binning_numerical_bb","text":"target integer vector binary target values (0 1). feature numeric vector feature values. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum frequency cutoff bin (default: 0.05). max_n_prebins Maximum number pre-bins (default: 20). is_monotonic Whether enforce monotonic WoE (default: TRUE). convergence_threshold Convergence threshold IV (default: 1e-6). max_iterations Maximum iterations (default: 1000).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_bb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using Branch and Bound — optimal_binning_numerical_bb","text":"list binning details statistics.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_bb.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using Branch and Bound — optimal_binning_numerical_bb","text":"Farooq, B., & Miller, E. J. (2015). Optimal Binning Continuous Variables. Kotsiantis, S., & Kanellopoulos, D. (2006). Discretization Techniques: Recent Survey.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_bb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using Branch and Bound — optimal_binning_numerical_bb","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(123) n <- 10000 feature <- rnorm(n) target <- rbinom(n, 1, plogis(0.5 * feature)) result <- optimal_binning_numerical_bb(target, feature, min_bins = 3, max_bins = 5) print(result) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_cm.html","id":null,"dir":"Reference","previous_headings":"","what":"Binning Ótimo para Variáveis Numéricas usando ChiMerge (Versão Aprimorada) — optimal_binning_numerical_cm","title":"Binning Ótimo para Variáveis Numéricas usando ChiMerge (Versão Aprimorada) — optimal_binning_numerical_cm","text":"Implementa um algoritmo de binning ótimo para variáveis numéricas utilizando o método ChiMerge, calculando WoE (Weight Evidence) e IV (Information Value). Este código foi otimizado em legibilidade, eficiência e robustez, mantendo compatibilidade de tipos e nomes.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_cm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Binning Ótimo para Variáveis Numéricas usando ChiMerge (Versão Aprimorada) — optimal_binning_numerical_cm","text":"","code":"optimal_binning_numerical_cm(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   convergence_threshold = 1e-06,   max_iterations = 1000L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_cm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Binning Ótimo para Variáveis Numéricas usando ChiMerge (Versão Aprimorada) — optimal_binning_numerical_cm","text":"target Vetor inteiro binário (0/1) target. feature Vetor numérico de valores da feature ser binada. min_bins Número mínimo de bins (default: 3). max_bins Número máximo de bins (default: 5). bin_cutoff Frequência mínima (proporção) de observações em cada bin (default: 0.05). max_n_prebins Número máximo de pré-bins para discretização inicial (default: 20). convergence_threshold Limite de convergência algoritmo (default: 1e-6). max_iterations Número máximo de iterações (default: 1000).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_cm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Binning Ótimo para Variáveis Numéricas usando ChiMerge (Versão Aprimorada) — optimal_binning_numerical_cm","text":"Uma lista com: bins: Vetor de nomes dos bins. woe: Vetor de WoE por bin. iv: Vetor de IV por bin. count: Contagem total por bin. count_pos: Contagem de casos positivos (target=1) por bin. count_neg: Contagem de casos negativos (target=0) por bin. cutpoints: Pontos de corte utilizados para criar os bins. converged: Booleano indicando se o algoritmo convergiu. iterations: Número de iterações executadas.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_cm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Binning Ótimo para Variáveis Numéricas usando ChiMerge (Versão Aprimorada) — optimal_binning_numerical_cm","text":"O algoritmo segue estes passos: Discretização inicial em max_n_prebins via quantis. Mesclagem iterativa de bins adjacentes com base na estatística Qui-quadrado. Mesclagem de bins com contagens zero em alguma classe. Mesclagem de bins raros (baseado em bin_cutoff). Cálculo de WoE e IV para cada bin final. Aplicação de monotonicidade (se possível). Referências: Kerber, R. (1992). ChiMerge: Discretization Numeric Attributes. AAAI Press. Zeng, G. (2014). necessary condition good binning algorithm credit scoring. Applied Mathematical Sciences, 8(65), 3229-3242.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_cm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Binning Ótimo para Variáveis Numéricas usando ChiMerge (Versão Aprimorada) — optimal_binning_numerical_cm","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(123) n <- 10000 feature <- rnorm(n) target <- rbinom(n, 1, plogis(0.5 * feature)) result <- optimal_binning_numerical_cm(target, feature, min_bins = 3, max_bins = 5) print(result) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_dplc.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using Dynamic Programming with Local Constraints (DPLC) — optimal_binning_numerical_dplc","title":"Optimal Binning for Numerical Variables using Dynamic Programming with Local Constraints (DPLC) — optimal_binning_numerical_dplc","text":"Performs optimal binning numerical variables using Dynamic Programming Local Constraints (DPLC) approach. creates optimal bins numerical feature based relationship binary target variable, maximizing predictive power respecting user-defined constraints enforcing monotonicity.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_dplc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using Dynamic Programming with Local Constraints (DPLC) — optimal_binning_numerical_dplc","text":"","code":"optimal_binning_numerical_dplc(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   convergence_threshold = 1e-06,   max_iterations = 1000L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_dplc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using Dynamic Programming with Local Constraints (DPLC) — optimal_binning_numerical_dplc","text":"target integer vector binary target values (0 1). feature numeric vector feature values. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum proportion total observations bin avoid merged (default: 0.05). max_n_prebins Maximum number pre-bins optimization process (default: 20). convergence_threshold Convergence threshold algorithm (default: 1e-6). max_iterations Maximum number iterations allowed (default: 1000).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_dplc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using Dynamic Programming with Local Constraints (DPLC) — optimal_binning_numerical_dplc","text":"list containing following elements: bin Character vector bin ranges. woe Numeric vector WoE values bin. iv Numeric vector Information Value (IV) bin. count Numeric vector total observations bin. count_pos Numeric vector positive target observations bin. count_neg Numeric vector negative target observations bin. cutpoints Numeric vector cut points generate bins. converged Logical indicating algorithm converged. iterations Integer number iterations run algorithm.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_dplc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using Dynamic Programming with Local Constraints (DPLC) — optimal_binning_numerical_dplc","text":"Dynamic Programming Local Constraints (DPLC) algorithm numerical variables works follows: Perform initial pre-binning based quantiles feature distribution. Calculate initial counts Weight Evidence (WoE) bin. Enforce monotonicity WoE values across bins merging adjacent non-monotonic bins. Ensure number bins min_bins max_bins: Merge bins smallest WoE difference max_bins. Handle rare bins merging bin_cutoff threshold. Calculate final Information Value (IV) bin. algorithm aims create bins maximize predictive power numerical variable adhering specified constraints. enforces monotonicity WoE values, particularly useful credit scoring risk modeling applications. Weight Evidence (WoE) calculated : $$WoE = \\ln\\left(\\frac{\\text{Positive Rate}}{\\text{Negative Rate}}\\right)$$ Information Value (IV) calculated : $$IV = (\\text{Positive Rate} - \\text{Negative Rate}) \\times WoE$$","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_dplc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using Dynamic Programming with Local Constraints (DPLC) — optimal_binning_numerical_dplc","text":"","code":"# Create sample data set.seed(123) n <- 1000 target <- sample(0:1, n, replace = TRUE) feature <- rnorm(n)  # Run optimal binning result <- optimal_binning_numerical_dplc(target, feature, min_bins = 2, max_bins = 4)  # Print results print(result) #> $bin #> [1] \"(-Inf;-1.691862]\"     \"(-1.691862;0.031526]\" \"(0.031526;1.651915]\"  #> [4] \"(1.651915;+Inf]\"      #>  #> $woe #> [1]  0.18434380  0.02400115  0.01511220 -0.55136299 #>  #> $iv #> [1] 0.0016962072 0.0002592498 0.0001027778 0.0147786563 #>  #> $count #> [1]  50 450 450  50 #>  #> $count_pos #> [1]  27 225 224  18 #>  #> $count_neg #> [1]  23 225 226  32 #>  #> $cutpoints #> [1] -1.691862  0.031526  1.651915 #>  #> $converged #> [1] TRUE #>  #> $iterations #> [1] 17 #>"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ewb.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using Equal-Width Binning — optimal_binning_numerical_ewb","title":"Optimal Binning for Numerical Variables using Equal-Width Binning — optimal_binning_numerical_ewb","text":"Realiza binning ótimo de variáveis numéricas por meio de intervalos de largura igual (Equal-Width Binning) com etapas subsequentes de mesclagem e ajuste. Este procedimento busca criar uma estratégia de binning interpretável e com bom poder preditivo, levando em conta monotonicidade e cortes mínimos nos bins.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ewb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using Equal-Width Binning — optimal_binning_numerical_ewb","text":"","code":"optimal_binning_numerical_ewb(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   convergence_threshold = 1e-06,   max_iterations = 1000L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ewb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using Equal-Width Binning — optimal_binning_numerical_ewb","text":"target Vetor inteiro binário (0 ou 1) representando variável alvo. feature Vetor numérico com os valores da feature ser binned. min_bins Número mínimo de bins (padrão: 3). max_bins Número máximo de bins (padrão: 5). bin_cutoff Fração mínima de observações que cada bin deve conter (padrão: 0.05). max_n_prebins Número máximo de pré-bins antes da otimização (padrão: 20). convergence_threshold Limite de convergência (padrão: 1e-6). max_iterations Número máximo de iterações permitidas (padrão: 1000).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ewb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using Equal-Width Binning — optimal_binning_numerical_ewb","text":"Uma lista com: bins Vetor de caracteres com o intervalo de cada bin. woe Vetor numérico com os valores de WoE de cada bin. iv Vetor numérico com o valor de IV de cada bin. count Vetor numérico com o total de observações em cada bin. count_pos Vetor numérico com o total de observações positivas em cada bin. count_neg Vetor numérico com o total de observações negativas em cada bin. cutpoints Vetor numérico com os pontos de corte. converged Valor lógico indicando se o algoritmo convergiu. iterations Número de iterações executadas pelo algoritmo.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ewb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using Equal-Width Binning — optimal_binning_numerical_ewb","text":"O algoritmo consiste nos seguintes passos: Criação de pré-bins de largura igual. Atribuição dos dados esses pré-bins. Mesclagem de bins raros (com poucas observações). Cálculo WoE e IV inicial. Garantia de monotonicidade WoE por meio de mesclagem de bins não monotônicos. Ajuste para assegurar o número máximo de bins não exceda max_bins. Recalcular WoE e IV ao final. Este método visa fornecer bins que balanceiem interpretabilidade, monotonicidade e poder preditivo, útil em modelagem de risco e credit scoring.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ewb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using Equal-Width Binning — optimal_binning_numerical_ewb","text":"","code":"set.seed(123) target <- sample(0:1, 1000, replace = TRUE) feature <- rnorm(1000) result <- optimal_binning_numerical_ewb(target, feature) print(result) #> $bin #> [1] \"(-2.809775;-0.019709]\" \"(-0.019709;0.910313]\"  \"(0.910313;3.390371]\"   #>  #> $woe #> [1]  0.01987743  0.03562919 -0.12833957 #>  #> $iv #> [1] 0.0001916461 0.0004367342 0.0028105280 #>  #> $count #> [1] 485 344 171 #>  #> $count_pos #> [1] 242 173  79 #>  #> $count_neg #> [1] 243 171  92 #>  #> $cutpoints #> [1] -0.0197092  0.9103126 #>  #> $converged #> [1] TRUE #>  #> $iterations #> [1] 18 #>"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_fetb.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using Fisher's Exact Test (FETB) — optimal_binning_numerical_fetb","title":"Optimal Binning for Numerical Variables using Fisher's Exact Test (FETB) — optimal_binning_numerical_fetb","text":"function implements optimal binning algorithm numerical variables using Fisher's Exact Test. attempts create optimal set bins given numerical feature based relationship binary target variable, ensuring statistical significance (via Fisher's Exact Test) monotonicity WoE values.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_fetb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using Fisher's Exact Test (FETB) — optimal_binning_numerical_fetb","text":"","code":"optimal_binning_numerical_fetb(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   convergence_threshold = 1e-06,   max_iterations = 1000L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_fetb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using Fisher's Exact Test (FETB) — optimal_binning_numerical_fetb","text":"target numeric vector binary target values (0 1). feature numeric vector feature values binned. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff P-value threshold merging bins (default: 0.05). max_n_prebins Maximum number pre-bins merging process (default: 20). convergence_threshold Threshold algorithmic convergence (default: 1e-6). max_iterations Maximum number iterations allowed merging monotonicity enforcement (default: 1000).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_fetb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using Fisher's Exact Test (FETB) — optimal_binning_numerical_fetb","text":"list containing: bin character vector bin ranges. woe numeric vector WoE values bin. iv numeric vector IV bin. count numeric vector total observations bin. count_pos numeric vector positive target observations bin. count_neg numeric vector negative target observations bin. cutpoints numeric vector cut points used generate bins. converged logical indicating algorithm converged. iterations integer indicating number iterations run.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_fetb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using Fisher's Exact Test (FETB) — optimal_binning_numerical_fetb","text":"algorithm works follows: Pre-binning: Initially divides feature max_n_prebins bins based sorted values. Fisher Merging: Adjacent bins merged Fisher's Exact Test p-value exceeds bin_cutoff, indicating statistically significant difference . Monotonicity Enforcement: Ensures WoE values monotonic merging non-monotonic adjacent bins. Final WoE/IV Calculation: achieving stable set bins (reaching iteration limits), calculates final WoE IV bin. method aims providing statistically justifiable monotonic binning, particularly useful credit scoring risk modeling tasks.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_fetb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using Fisher's Exact Test (FETB) — optimal_binning_numerical_fetb","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(123) target <- sample(0:1, 1000, replace = TRUE) feature <- rnorm(1000) result <- optimal_binning_numerical_fetb(target, feature) print(result$bins) print(result$woe) print(result$iv) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ir.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using Isotonic Regression — optimal_binning_numerical_ir","title":"Optimal Binning for Numerical Variables using Isotonic Regression — optimal_binning_numerical_ir","text":"Realiza binning ótimo para variáveis numéricas usando regressão isotônica, assegurando monotonicidade nas taxas e bins estáveis.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ir.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using Isotonic Regression — optimal_binning_numerical_ir","text":"","code":"optimal_binning_numerical_ir(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   convergence_threshold = 1e-06,   max_iterations = 1000L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ir.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using Isotonic Regression — optimal_binning_numerical_ir","text":"target Vetor binário (0 ou 1). feature Vetor numérico. min_bins Inteiro, número mínimo de bins (default: 3). max_bins Inteiro, número máximo de bins (default: 5). bin_cutoff Fração mínima de observações por bin (default: 0.05). max_n_prebins Máximo de pré-bins (default: 20). convergence_threshold Limite para convergência (default: 1e-6). max_iterations Máximo de iterações (default: 1000).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ir.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using Isotonic Regression — optimal_binning_numerical_ir","text":"Uma lista com bins, woe, iv, contagens, cutpoints, convergência e iterações.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ir.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using Isotonic Regression — optimal_binning_numerical_ir","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(123) n <- 1000 target <- sample(0:1, n, replace = TRUE) feature <- rnorm(n) result <- optimal_binning_numerical_ir(target, feature, min_bins = 2, max_bins = 4) print(result) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_jedi.html","id":null,"dir":"Reference","previous_headings":"","what":"Binning Ótimo Numérico JEDI (Discretização por Intervalos Guiada por Entropia Conjunta) — optimal_binning_numerical_jedi","title":"Binning Ótimo Numérico JEDI (Discretização por Intervalos Guiada por Entropia Conjunta) — optimal_binning_numerical_jedi","text":"Um algoritmo avançado de binning numérico que otimiza o valor de informação (IV) mantendo relações monotônicas de weight evidence (WoE). O algoritmo emprega pré-binning baseado em quantis com estratégias adaptativas de fusão, garantindo tanto estabilidade estatística quanto preservação ótima de informação.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_jedi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Binning Ótimo Numérico JEDI (Discretização por Intervalos Guiada por Entropia Conjunta) — optimal_binning_numerical_jedi","text":"","code":"optimal_binning_numerical_jedi(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   convergence_threshold = 1e-06,   max_iterations = 1000L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_jedi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Binning Ótimo Numérico JEDI (Discretização por Intervalos Guiada por Entropia Conjunta) — optimal_binning_numerical_jedi","text":"target Vetor numérico (0,1) representando variável alvo binária feature Vetor numérico preditor contínuo min_bins Número mínimo de bins de saída (padrão: 3, deve ser ≥2) max_bins Número máximo de bins de saída (padrão: 5, deve ser ≥ min_bins) bin_cutoff Frequência relativa mínima por bin (padrão: 0.05) max_n_prebins Número máximo de pré-bins antes da otimização (padrão: 20) convergence_threshold Limite de diferença de IV para convergência (padrão: 1e-6) max_iterations Máximo de iterações de otimização (padrão: 1000)","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_jedi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Binning Ótimo Numérico JEDI (Discretização por Intervalos Guiada por Entropia Conjunta) — optimal_binning_numerical_jedi","text":"Uma lista contendo: bin: Vetor de caracteres dos intervalos dos bins woe: Vetor numérico dos valores de Weight Evidence iv: Vetor numérico dos valores de Information Value por bin count: Vetor inteiro de contagens de observações por bin count_pos: Vetor inteiro de contagens da classe positiva por bin count_neg: Vetor inteiro de contagens da classe negativa por bin cutpoints: Vetor numérico dos pontos de corte (excluindo ±Inf) converged: Lógico indicando se o algoritmo convergiu iterations: Contagem inteira de iterações de otimização realizadas","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_jedi.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Binning Ótimo Numérico JEDI (Discretização por Intervalos Guiada por Entropia Conjunta) — optimal_binning_numerical_jedi","text":"Framework Matemático: Para uma variável numérica \\(X\\) e alvo binário \\(Y \\\\{0,1\\}\\), o algoritmo cria \\(K\\) bins definidos por \\(K-1\\) pontos de corte onde cada bin \\(B_i = (c_{-1}, c_i]\\) maximiza o conteúdo de informação satisfazendo restrições: Monotonicidade WoE: \\(WoE_i \\le WoE_{+1}\\) (ou \\(\\ge\\) para tendência decrescente) Tamanho mínimo bin: \\(contagem(B_i)/N \\ge bin\\_cutoff\\) Limites de quantidade de bins: \\(min\\_bins \\le K \\le max\\_bins\\) O Weight Evidence para bin \\(\\) é definido como: $$WoE_i = ln(\\frac{Pos_i / \\sum Pos_i}{Neg_i / \\sum Neg_i})$$ E o Information Value por bin como: $$IV_i = (Pos_i/\\sum Pos_i - Neg_i/\\sum Neg_i) \\times WoE_i$$ O IV total é dado por: $$IV_{total} = \\sum_{=1}^K IV_i$$ Fases Algoritmo: Pré-binning baseado em quantis com validação de frequência mínima Tratamento de bins pequenos através de fusões minimizando perda de IV Imposição de monotonicidade via fusão adaptativa de bins Otimização da quantidade de bins através de divisões/fusões controladas Monitoramento de convergência usando estabilidade IV Características Principais: Cálculo de WoE protegido por epsilon para estabilidade numérica Estratégia adaptativa de fusão minimizando perda de informação Tratamento robusto de casos extremos e distribuições extremas Busca binária eficiente para atribuição de bins Detecção antecipada de convergência","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_jedi.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Binning Ótimo Numérico JEDI (Discretização por Intervalos Guiada por Entropia Conjunta) — optimal_binning_numerical_jedi","text":"Teoria da Informação e Aprendizado Estatístico (Cover & Thomas, 2006) Binning Ótimo para Modelos de Scoring (Mironchyk & Tchistiakov, 2017) Binning e Scoring Monotônico (Beltrami & Bassani, 2021)","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_jedi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Binning Ótimo Numérico JEDI (Discretização por Intervalos Guiada por Entropia Conjunta) — optimal_binning_numerical_jedi","text":"","code":"if (FALSE) { # \\dontrun{ # Uso básico com parâmetros padrão resultado <- optimal_binning_numerical_jedi(   target = c(1,0,1,0,1),   feature = c(1.2,3.4,2.1,4.5,2.8) )  # Configuração personalizada para binning mais granular resultado <- optimal_binning_numerical_jedi(   target = vetor_target,   feature = vetor_feature,   min_bins = 5,   max_bins = 10,   bin_cutoff = 0.03 ) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_kmb.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using K-means Binning (KMB) — optimal_binning_numerical_kmb","title":"Optimal Binning for Numerical Variables using K-means Binning (KMB) — optimal_binning_numerical_kmb","text":"function implements K-means Binning (KMB) algorithm optimal binning numerical variables.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_kmb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using K-means Binning (KMB) — optimal_binning_numerical_kmb","text":"","code":"optimal_binning_numerical_kmb(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   convergence_threshold = 1e-06,   max_iterations = 1000L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_kmb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using K-means Binning (KMB) — optimal_binning_numerical_kmb","text":"target integer vector binary target values (0 1). feature numeric vector feature values binned. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum frequency bin (default: 0.05). max_n_prebins Maximum number pre-bins (default: 20). convergence_threshold Convergence threshold algorithm (default: 1e-6). max_iterations Maximum number iterations allowed (default: 1000).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_kmb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using K-means Binning (KMB) — optimal_binning_numerical_kmb","text":"list containing following elements: bin Character vector bin ranges. woe Numeric vector WoE values bin. iv Numeric vector Information Value (IV) bin. count Integer vector total observations bin. count_pos Integer vector positive target observations bin. count_neg Integer vector negative target observations bin. cutpoints Numeric vector cut points generate bins. converged Logical indicating algorithm converged. iterations Integer number iterations run algorithm.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_kmb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using K-means Binning (KMB) — optimal_binning_numerical_kmb","text":"K-means Binning (KMB) algorithm advanced method optimal binning numerical variables. combines elements k-means clustering traditional binning techniques create bins maximize predictive power feature respecting user-defined constraints. algorithm works several steps: Initial Binning: Creates initial bins based unique values feature, respecting max_n_prebins constraint. Data Assignment: Assigns data points appropriate bins. Low Frequency Merging: Merges bins frequencies bin_cutoff threshold. Enforce Monotonicity: Merges bins ensure WoE values monotonic. Bin Count Adjustment: Adjusts number bins fall within specified range (min_bins max_bins). Statistics Calculation: Computes Weight Evidence (WoE) Information Value (IV) bin. KMB method uses modified version Weight Evidence (WoE) calculation incorporates Laplace smoothing handle cases zero counts $$WoE_i = \\ln\\left(\\frac{(n_{1i} + 0.5) / (N_1 + 1)}{(n_{0i} + 0.5) / (N_0 + 1)}\\right)$$ \\(n_{1i}\\) \\(n_{0i}\\) number events non-events bin , \\(N_1\\) \\(N_0\\) total number events non-events. Information Value (IV) bin calculated : $$IV_i = \\left(\\frac{n_{1i}}{N_1} - \\frac{n_{0i}}{N_0}\\right) \\times WoE_i$$ KMB method aims create bins maximize overall IV respecting user-defined constraints. uses greedy approach merge bins necessary, choosing merge bins smallest difference IV. adjusting number bins, algorithm either merges bins similar IVs (many bins) stops merging min_bins reached, even monotonicity achieved.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_kmb.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using K-means Binning (KMB) — optimal_binning_numerical_kmb","text":"Fayyad, U., & Irani, K. (1993). Multi-interval discretization continuous-valued attributes classification learning. Proceedings 13th International Joint Conference Artificial Intelligence (pp. 1022-1027). Thomas, L. C., Edelman, D. B., & Crook, J. N. (2002). Credit Scoring Applications. SIAM Monographs Mathematical Modeling Computation.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_kmb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using K-means Binning (KMB) — optimal_binning_numerical_kmb","text":"","code":"if (FALSE) { # \\dontrun{   # Create sample data   set.seed(123)   target <- sample(0:1, 1000, replace = TRUE)   feature <- rnorm(1000)    # Run optimal binning   result <- optimal_binning_numerical_kmb(target, feature)    # View results   print(result) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ldb.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using Local Density Binning (LDB) — optimal_binning_numerical_ldb","title":"Optimal Binning for Numerical Variables using Local Density Binning (LDB) — optimal_binning_numerical_ldb","text":"Implementa o algoritmo Local Density Binning (LDB) para binning ótimo de variáveis numéricas.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ldb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using Local Density Binning (LDB) — optimal_binning_numerical_ldb","text":"","code":"optimal_binning_numerical_ldb(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   convergence_threshold = 1e-06,   max_iterations = 1000L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ldb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using Local Density Binning (LDB) — optimal_binning_numerical_ldb","text":"target Vetor inteiro binário (0 ou 1). feature Vetor numérico ser binned. min_bins Número mínimo de bins (default: 3). max_bins Número máximo de bins (default: 5). bin_cutoff Frequência mínima para um bin (default: 0.05). max_n_prebins Número máximo de pré-bins (default: 20). convergence_threshold Limite de convergência (default: 1e-6). max_iterations Máximo de iterações (default: 1000).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ldb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using Local Density Binning (LDB) — optimal_binning_numerical_ldb","text":"Uma lista com bins, woe, iv, contagens, cutpoints, converged e iterations.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ldb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using Local Density Binning (LDB) — optimal_binning_numerical_ldb","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(123) target <- sample(0:1, 1000, replace = TRUE) feature <- rnorm(1000) result <- optimal_binning_numerical_ldb(target, feature) print(result$bins) print(result$woe) print(result$iv) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_lpdb.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using Local Polynomial Density Binning (LPDB) — optimal_binning_numerical_lpdb","title":"Optimal Binning for Numerical Variables using Local Polynomial Density Binning (LPDB) — optimal_binning_numerical_lpdb","text":"Implementa o algoritmo Local Polynomial Density Binning (LPDB) para binning ótimo de variáveis numéricas.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_lpdb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using Local Polynomial Density Binning (LPDB) — optimal_binning_numerical_lpdb","text":"","code":"optimal_binning_numerical_lpdb(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   convergence_threshold = 1e-06,   max_iterations = 1000L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_lpdb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using Local Polynomial Density Binning (LPDB) — optimal_binning_numerical_lpdb","text":"target Vetor inteiro binário (0 ou 1). feature Vetor numérico ser binned. min_bins Número mínimo de bins (default: 3). max_bins Número máximo de bins (default: 5). bin_cutoff Frequência mínima por bin (default: 0.05). max_n_prebins Máximo de pré-bins (default: 20). convergence_threshold Limite de convergência (default: 1e-6). max_iterations Máximo de iterações (default: 1000).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_lpdb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using Local Polynomial Density Binning (LPDB) — optimal_binning_numerical_lpdb","text":"Uma lista com bins, woe, iv, contagens, cutpoints, converged e iterations.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_lpdb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using Local Polynomial Density Binning (LPDB) — optimal_binning_numerical_lpdb","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(123) target <- sample(0:1, 1000, replace = TRUE) feature <- rnorm(1000) result <- optimal_binning_numerical_lpdb(target, feature) print(result$bins) print(result$woe) print(result$iv) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mblp.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Features Using Monotonic Binning via Linear Programming (MBLP) — optimal_binning_numerical_mblp","title":"Optimal Binning for Numerical Features Using Monotonic Binning via Linear Programming (MBLP) — optimal_binning_numerical_mblp","text":"Este método realiza um binning ótimo de variáveis numéricas, garantindo monotonicidade WoE entre os bins, respeitando restrições de min/max bins e fusão de bins raros. Retorna bins, WoE, IV, contagens e metadados.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mblp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Features Using Monotonic Binning via Linear Programming (MBLP) — optimal_binning_numerical_mblp","text":"","code":"optimal_binning_numerical_mblp(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   convergence_threshold = 1e-06,   max_iterations = 1000L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mblp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Features Using Monotonic Binning via Linear Programming (MBLP) — optimal_binning_numerical_mblp","text":"target Vetor inteiro binário (0 ou 1). feature Vetor numérico da feature. min_bins Número mínimo de bins (default: 3). max_bins Número máximo de bins (default: 5). bin_cutoff Limite para mesclar bins raros (freq < bin_cutoff). max_n_prebins Máximo de pré-bins antes da otimização (default: 20). convergence_threshold Limite para convergência IV (default: 1e-6). max_iterations Máximo de iterações (default: 1000).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mblp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Features Using Monotonic Binning via Linear Programming (MBLP) — optimal_binning_numerical_mblp","text":"Lista com bins, woe, iv, contagens, cutpoints, converged e iterations.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mblp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Features Using Monotonic Binning via Linear Programming (MBLP) — optimal_binning_numerical_mblp","text":"","code":"set.seed(123) feature <- rnorm(1000) target <- rbinom(1000, 1, 0.3) result <- optimal_binning_numerical_mblp(target, feature, min_bins = 3, max_bins = 6) print(result) #> $bin #> [1] \"(-Inf;-0.348472]\"      \"(-0.348472;-0.214505]\" \"(-0.214505;+Inf]\"      #>  #> $woe #> [1] -0.03718072 -0.66293131  0.06916390 #>  #> $iv #> [1] 0.0004816501 0.0191991896 0.0028990292 #>  #> $count #> [1] 351  50 599 #>  #> $count_pos #> [1] 105   9 193 #>  #> $count_neg #> [1] 246  41 406 #>  #> $cutpoints #> [1] -0.3484724 -0.2145045 #>  #> $converged #> [1] TRUE #>  #> $iterations #> [1] 5 #>"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mdlp.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Features using MDLP — optimal_binning_numerical_mdlp","title":"Optimal Binning for Numerical Features using MDLP — optimal_binning_numerical_mdlp","text":"Executa binning ótimo usando o Princípio Comprimento Mínimo da Descrição (MDLP). Cria bins de modo minimizar perda de informação, mesclando bins adjacentes que reduzem o custo MDL, e assegurando monotonicidade WoE. Ajusta o número de bins entre min_bins e max_bins, mesclando bins raros.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mdlp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Features using MDLP — optimal_binning_numerical_mdlp","text":"","code":"optimal_binning_numerical_mdlp(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   convergence_threshold = 1e-06,   max_iterations = 1000L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mdlp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Features using MDLP — optimal_binning_numerical_mdlp","text":"target Vetor inteiro binário (0 ou 1). feature Vetor numérico da feature. min_bins Número mínimo de bins (default: 3). max_bins Número máximo de bins (default: 5). bin_cutoff Proporção mínima de registros por bin (default: 0.05). max_n_prebins Número máximo de pré-bins (default: 20). convergence_threshold Limite de convergência (default: 1e-6). max_iterations Número máximo de iterações (default: 1000).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mdlp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Features using MDLP — optimal_binning_numerical_mdlp","text":"Uma lista com bins, woe, iv, contagens, cutpoints, convergência e iterações.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mob.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform Optimal Binning for Numerical Features using Monotonic Optimal Binning (MOB) — optimal_binning_numerical_mob","title":"Perform Optimal Binning for Numerical Features using Monotonic Optimal Binning (MOB) — optimal_binning_numerical_mob","text":"function implements Monotonic Optimal Binning algorithm numerical features. creates optimal bins maintaining monotonicity Weight Evidence (WoE) values.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mob.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform Optimal Binning for Numerical Features using Monotonic Optimal Binning (MOB) — optimal_binning_numerical_mob","text":"","code":"optimal_binning_numerical_mob(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   convergence_threshold = 1e-06,   max_iterations = 1000L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mob.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform Optimal Binning for Numerical Features using Monotonic Optimal Binning (MOB) — optimal_binning_numerical_mob","text":"target integer vector binary target values (0 1) feature numeric vector feature values binned min_bins Minimum number bins create (default: 3) max_bins Maximum number bins create (default: 5) bin_cutoff Minimum frequency observations bin (default: 0.05) max_n_prebins Maximum number prebins create initially (default: 20) convergence_threshold Threshold convergence iterative process (default: 1e-6) max_iterations Maximum number iterations binning process (default: 1000)","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mob.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform Optimal Binning for Numerical Features using Monotonic Optimal Binning (MOB) — optimal_binning_numerical_mob","text":"list containing following elements: bin character vector bin labels woe numeric vector Weight Evidence values bin iv numeric vector Information Value bin count integer vector total count observations bin count_pos integer vector count positive class observations bin count_neg integer vector count negative class observations bin cutpoints numeric vector cutpoints used create bins converged logical value indicating whether algorithm converged iterations integer value indicating number iterations run","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mob.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Perform Optimal Binning for Numerical Features using Monotonic Optimal Binning (MOB) — optimal_binning_numerical_mob","text":"algorithm starts creating initial bins iteratively merges achieve optimal binning maintaining monotonicity WoE values. respects minimum maximum number bins specified.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mob.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform Optimal Binning for Numerical Features using Monotonic Optimal Binning (MOB) — optimal_binning_numerical_mob","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(42) feature <- rnorm(1000) target <- rbinom(1000, 1, 0.5) result <- optimal_binning_numerical_mob(target, feature) print(result) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mrblp.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using Monotonic Risk Binning with Likelihood Ratio Pre-binning (MRBLP) — optimal_binning_numerical_mrblp","title":"Optimal Binning for Numerical Variables using Monotonic Risk Binning with Likelihood Ratio Pre-binning (MRBLP) — optimal_binning_numerical_mrblp","text":"function implements optimal binning algorithm numerical variables using Monotonic Risk Binning Likelihood Ratio Pre-binning (MRBLP). transforms continuous feature discrete bins preserving monotonic relationship target variable maximizing predictive power.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mrblp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using Monotonic Risk Binning with Likelihood Ratio Pre-binning (MRBLP) — optimal_binning_numerical_mrblp","text":"","code":"optimal_binning_numerical_mrblp(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   convergence_threshold = 1e-06,   max_iterations = 1000L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mrblp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using Monotonic Risk Binning with Likelihood Ratio Pre-binning (MRBLP) — optimal_binning_numerical_mrblp","text":"target integer vector binary target values (0 1). feature numeric vector continuous feature binned. min_bins Integer. minimum number bins create (default: 3). max_bins Integer. maximum number bins create (default: 5). bin_cutoff Numeric. minimum proportion observations bin (default: 0.05). max_n_prebins Integer. maximum number pre-bins create initial binning step (default: 20). convergence_threshold Numeric. threshold convergence monotonic binning step (default: 1e-6). max_iterations Integer. maximum number iterations monotonic binning step (default: 1000).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mrblp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using Monotonic Risk Binning with Likelihood Ratio Pre-binning (MRBLP) — optimal_binning_numerical_mrblp","text":"list containing following elements: bins character vector bin ranges. woe numeric vector Weight Evidence (WoE) values bin. iv numeric vector Information Value (IV) bin. count integer vector total count observations bin. count_pos integer vector count positive observations bin. count_neg integer vector count negative observations bin. cutpoints numeric vector cutpoints used create bins. converged logical value indicating whether algorithm converged. iterations integer value indicating number iterations run.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mrblp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using Monotonic Risk Binning with Likelihood Ratio Pre-binning (MRBLP) — optimal_binning_numerical_mrblp","text":"MRBLP algorithm combines pre-binning, small bin merging, monotonic binning create optimal binning solution numerical variables. process involves following steps: Pre-binning: algorithm starts creating initial bins using equal-frequency binning. number pre-bins determined max_n_prebins parameter. Small bin merging: Bins proportion observations less bin_cutoff merged adjacent bins ensure statistical significance. Monotonic binning: algorithm enforces monotonic relationship bin order Weight Evidence (WoE) values. step ensures binning preserves original relationship feature target variable. Bin count adjustment: number bins exceeds max_bins, algorithm merges bins smallest difference Information Value (IV). number bins less min_bins, largest bin split. algorithm includes additional controls prevent instability ensure convergence: convergence threshold used determine algorithm stop iterating. maximum number iterations set prevent infinite loops. convergence reached within specified time standards, function returns best result obtained last iteration.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mrblp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Binning for Numerical Variables using Monotonic Risk Binning with Likelihood Ratio Pre-binning (MRBLP) — optimal_binning_numerical_mrblp","text":"Belcastro, L., Marozzo, F., Talia, D., & Trunfio, P. (2020). \"Big Data Analytics Clouds.\" Handbook Big Data Technologies (pp. 101-142). Springer, Cham. Zeng, Y. (2014). \"Optimal Binning Scoring Modeling.\" Computational Economics, 44(1), 137-149.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mrblp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal Binning for Numerical Variables using Monotonic Risk Binning with Likelihood Ratio Pre-binning (MRBLP) — optimal_binning_numerical_mrblp","text":"Lopes, J.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_mrblp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using Monotonic Risk Binning with Likelihood Ratio Pre-binning (MRBLP) — optimal_binning_numerical_mrblp","text":"","code":"if (FALSE) { # \\dontrun{ # Generate sample data set.seed(42) n <- 10000 feature <- rnorm(n) target <- rbinom(n, 1, plogis(0.5 + 0.5 * feature))  # Run optimal binning result <- optimal_binning_numerical_mrblp(target, feature)  # View binning results print(result) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_oslp.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using OSLP — optimal_binning_numerical_oslp","title":"Optimal Binning for Numerical Variables using OSLP — optimal_binning_numerical_oslp","text":"Performs optimal binning numerical variables using Optimal Supervised Learning Partitioning (OSLP) approach.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_oslp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using OSLP — optimal_binning_numerical_oslp","text":"","code":"optimal_binning_numerical_oslp(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   convergence_threshold = 1e-06,   max_iterations = 1000L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_oslp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using OSLP — optimal_binning_numerical_oslp","text":"target numeric vector binary target values (0 1). feature numeric vector feature values. min_bins Minimum number bins (default: 3, must >= 2). max_bins Maximum number bins (default: 5, must > min_bins). bin_cutoff Minimum proportion total observations bin avoid merged (default: 0.05, must (0, 1)). max_n_prebins Maximum number pre-bins optimization (default: 20). convergence_threshold Threshold convergence (default: 1e-6). max_iterations Maximum number iterations (default: 1000).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_oslp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using OSLP — optimal_binning_numerical_oslp","text":"list containing: bins Character vector bin labels. woe Numeric vector Weight Evidence (WoE) values bin. iv Numeric vector Information Value (IV) bin. count Integer vector total count observations bin. count_pos Integer vector positive class count bin. count_neg Integer vector negative class count bin. cutpoints Numeric vector cutpoints used create bins. converged Logical value indicating whether algorithm converged. iterations Integer value indicating number iterations run.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_oslp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using OSLP — optimal_binning_numerical_oslp","text":"","code":"if (FALSE) { # \\dontrun{ # Sample data set.seed(123) n <- 1000 target <- sample(0:1, n, replace = TRUE) feature <- rnorm(n)  # Optimal binning result <- optimal_binning_numerical_oslp(target, feature,                                          min_bins = 2, max_bins = 4)  # Print results print(result) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ubsd.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using Unsupervised Binning with Standard Deviation — optimal_binning_numerical_ubsd","title":"Optimal Binning for Numerical Variables using Unsupervised Binning with Standard Deviation — optimal_binning_numerical_ubsd","text":"function implements optimal binning algorithm numerical variables using Unsupervised Binning approach based Standard Deviation (UBSD) Weight Evidence (WoE) Information Value (IV) criteria.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ubsd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using Unsupervised Binning with Standard Deviation — optimal_binning_numerical_ubsd","text":"","code":"optimal_binning_numerical_ubsd(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   convergence_threshold = 1e-06,   max_iterations = 1000L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ubsd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using Unsupervised Binning with Standard Deviation — optimal_binning_numerical_ubsd","text":"target numeric vector binary target values (contain exactly two unique values: 0 1). feature numeric vector feature values binned. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum frequency observations bin (default: 0.05). max_n_prebins Maximum number pre-bins initial standard deviation-based discretization (default: 20). convergence_threshold Threshold convergence total IV (default: 1e-6). max_iterations Maximum number iterations algorithm (default: 1000).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ubsd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using Unsupervised Binning with Standard Deviation — optimal_binning_numerical_ubsd","text":"list containing following elements: bins character vector bin names. woe numeric vector Weight Evidence values bin. iv numeric vector Information Value bin. count integer vector total count observations bin. count_pos integer vector count positive observations bin. count_neg integer vector count negative observations bin. cutpoints numeric vector cut points used generate bins. converged logical value indicating whether algorithm converged. iterations integer value indicating number iterations run.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ubsd.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using Unsupervised Binning with Standard Deviation — optimal_binning_numerical_ubsd","text":"optimal binning algorithm numerical variables uses Unsupervised Binning approach based Standard Deviation (UBSD) Weight Evidence (WoE) Information Value (IV) create bins maximize predictive power feature maintaining interpretability. algorithm follows steps: Initial binning based standard deviations around mean Assignment data points bins Merging rare bins based bin_cutoff parameter Calculation WoE IV bin Enforcement monotonicity WoE across bins merging bins ensure number bins within specified range algorithm iterates convergence reached maximum number iterations hit.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_ubsd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using Unsupervised Binning with Standard Deviation — optimal_binning_numerical_ubsd","text":"","code":"if (FALSE) { # \\dontrun{ # Generate sample data set.seed(123) n <- 10000 feature <- rnorm(n) target <- rbinom(n, 1, plogis(0.5 * feature))  # Apply optimal binning result <- optimal_binning_numerical_ubsd(target, feature, min_bins = 3, max_bins = 5)  # View binning results print(result) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_udt.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Binning for Numerical Variables using Unsupervised Decision Trees — optimal_binning_numerical_udt","title":"Optimal Binning for Numerical Variables using Unsupervised Decision Trees — optimal_binning_numerical_udt","text":"function implements optimal binning algorithm numerical variables using Unsupervised Decision Tree (UDT) approach Weight Evidence (WoE) Information Value (IV) criteria.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_udt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Binning for Numerical Variables using Unsupervised Decision Trees — optimal_binning_numerical_udt","text":"","code":"optimal_binning_numerical_udt(   target,   feature,   min_bins = 3L,   max_bins = 5L,   bin_cutoff = 0.05,   max_n_prebins = 20L,   convergence_threshold = 1e-06,   max_iterations = 1000L )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_udt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Binning for Numerical Variables using Unsupervised Decision Trees — optimal_binning_numerical_udt","text":"target integer vector binary target values (0 1). feature numeric vector feature values binned. min_bins Minimum number bins (default: 3). max_bins Maximum number bins (default: 5). bin_cutoff Minimum frequency observations bin (default: 0.05). max_n_prebins Maximum number pre-bins initial quantile-based discretization (default: 20). convergence_threshold Threshold convergence optimization process (default: 1e-6). max_iterations Maximum number iterations optimization process (default: 1000).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_udt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Binning for Numerical Variables using Unsupervised Decision Trees — optimal_binning_numerical_udt","text":"list containing binning details: bins character vector bin intervals. woe numeric vector Weight Evidence values bin. iv numeric vector Information Value bin. count integer vector total observations bin. count_pos integer vector positive observations bin. count_neg integer vector negative observations bin. cutpoints numeric vector cut points bins. converged logical value indicating whether algorithm converged. iterations integer value number iterations run.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_udt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal Binning for Numerical Variables using Unsupervised Decision Trees — optimal_binning_numerical_udt","text":"optimal binning algorithm numerical variables uses Unsupervised Decision Tree approach Weight Evidence (WoE) Information Value (IV) create bins maximize predictive power feature maintaining interpretability. algorithm follows steps: Initial discretization using quantile-based binning Merging rare bins based bin_cutoff parameter Bin optimization using IV WoE criteria Enforcement monotonicity WoE across bins Adjustment number bins within specified range","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/optimal_binning_numerical_udt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal Binning for Numerical Variables using Unsupervised Decision Trees — optimal_binning_numerical_udt","text":"","code":"if (FALSE) { # \\dontrun{ # Generate sample data set.seed(123) n <- 10000 feature <- rnorm(n) target <- rbinom(n, 1, plogis(0.5 * feature))  # Apply optimal binning result <- optimal_binning_numerical_udt(target, feature, min_bins = 3, max_bins = 5)  # View binning results print(result) } # }"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/predict.oblr.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict Method for oblr Objects — predict.oblr","title":"Predict Method for oblr Objects — predict.oblr","text":"Generates predictions fitted oblr model. Can return probabilities, link values, class predictions.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/predict.oblr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict Method for oblr Objects — predict.oblr","text":"","code":"# S3 method for class 'oblr' predict(   object,   newdata = NULL,   type = c(\"proba\", \"class\", \"link\"),   cutoff = 0.5,   ... )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/predict.oblr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict Method for oblr Objects — predict.oblr","text":"object object class oblr. newdata data frame data.table containing new data prediction. NULL, uses data fit. type type prediction return: \"link\" linear predictor, \"proba\" probabilities, \"class\" class predictions. cutoff probability cutoff class prediction. Default 0.5. used type = \"class\". ... Additional arguments passed methods.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/predict.oblr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict Method for oblr Objects — predict.oblr","text":"numeric vector predictions. type = \"class\", returns factor levels 0 1.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/print.oblr.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Method for oblr Objects — print.oblr","title":"Print Method for oblr Objects — print.oblr","text":"Prints brief summary oblr model, including estimated coefficients convergence information.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/print.oblr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Method for oblr Objects — print.oblr","text":"","code":"# S3 method for class 'oblr' print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/print.oblr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Method for oblr Objects — print.oblr","text":"x object class oblr. digits Number significant digits display. Defaults maximum 3 getOption(\"digits\") - 3. ... Additional arguments passed methods.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/print.summary.oblr.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Method for summary.oblr Objects — print.summary.oblr","title":"Print Method for summary.oblr Objects — print.summary.oblr","text":"Prints detailed summary oblr model, including coefficients, standard errors, z-values, p-values, model fit statistics.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/print.summary.oblr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Method for summary.oblr Objects — print.summary.oblr","text":"","code":"# S3 method for class 'summary.oblr' print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/print.summary.oblr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Method for summary.oblr Objects — print.summary.oblr","text":"x object class summary.oblr. digits Number significant digits display. Defaults maximum 3 getOption(\"digits\") - 3. ... Additional arguments passed methods.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/residuals.oblr.html","id":null,"dir":"Reference","previous_headings":"","what":"Residuals Method for oblr Objects — residuals.oblr","title":"Residuals Method for oblr Objects — residuals.oblr","text":"Calculates residuals oblr model, deviance, Pearson, others.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/residuals.oblr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Residuals Method for oblr Objects — residuals.oblr","text":"","code":"# S3 method for class 'oblr' residuals(   object,   type = c(\"deviance\", \"pearson\", \"raw\", \"standardized\", \"studentized_internal\",     \"studentized_external\", \"leverage_adjusted\"),   ... )"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/residuals.oblr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Residuals Method for oblr Objects — residuals.oblr","text":"object object class oblr. type type residuals calculate: \"deviance\", \"pearson\", \"raw\", \"standardized\", \"studentized_internal\", \"studentized_external\", \"leverage_adjusted\". ... Additional arguments passed methods.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/residuals.oblr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Residuals Method for oblr Objects — residuals.oblr","text":"numeric vector residuals.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/residuals.oblr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Residuals Method for oblr Objects — residuals.oblr","text":"following types residuals can calculated: Raw Residuals: difference observed predicted values: $$e_i = y_i - \\hat{y}_i$$ Deviance Residuals: Deviance residuals measure contribution observation model deviance. logistic regression, defined : $$e_i^{\\text{Deviance}} = \\text{sign}(y_i - \\hat{y}_i) \\sqrt{2 \\left[ y_i \\log\\left(\\frac{y_i}{\\hat{y}_i}\\right) + (1 - y_i) \\log\\left(\\frac{1 - y_i}{1 - \\hat{y}_i}\\right) \\right]}$$ \\(\\hat{y}_i\\) predicted probability, \\(y_i\\) observed value. Pearson Residuals: residuals scale raw residuals estimated standard deviation: $$e_i^{\\text{Pearson}} = \\frac{y_i - \\hat{y}_i}{\\sqrt{\\hat{y}_i (1 - \\hat{y}_i)}}$$ Pearson residuals used assess goodness fit generalized linear models. Standardized Residuals: residuals standardize raw residuals dividing estimated standard deviation, adjusting fitted values: $$e_i^{\\text{Standardized}} = \\frac{e_i}{\\sqrt{\\hat{y}_i (1 - \\hat{y}_i)}}$$ Internally Studentized Residuals: residuals account leverage (influence) observation fitted value: $$e_i^{\\text{Internally Studentized}} = \\frac{e_i}{\\sqrt{\\hat{y}_i (1 - \\hat{y}_i)(1 - h_i)}}$$ \\(h_i\\) leverage \\(\\)-th observation, calculated hat matrix. Externally Studentized Residuals: residuals similar internally studentized residuals exclude \\(\\)-th observation estimating variance: $$e_i^{\\text{Externally Studentized}} = \\frac{e_i}{\\hat{\\sigma}_{()} \\sqrt{1 - h_i}}$$ \\(\\hat{\\sigma}_{()}\\) estimated standard error excluding \\(\\)-th observation. Leverage-Adjusted Residuals: residuals adjust raw residuals leverage value \\(h_i\\): $$e_i^{\\text{Leverage-Adjusted}} = \\frac{e_i}{\\sqrt{1 - h_i}}$$","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/summary.oblr.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary Method for oblr Objects — summary.oblr","title":"Summary Method for oblr Objects — summary.oblr","text":"Provides detailed summary oblr model, including coefficients, standard errors, z-values, p-values, model fit statistics.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/summary.oblr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary Method for oblr Objects — summary.oblr","text":"","code":"# S3 method for class 'oblr' summary(object, ...)"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/summary.oblr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary Method for oblr Objects — summary.oblr","text":"object object class oblr. ... Additional arguments passed methods.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/summary.oblr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary Method for oblr Objects — summary.oblr","text":"object class summary.oblr containing model summary.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/update.oblr.html","id":null,"dir":"Reference","previous_headings":"","what":"Update Method for oblr Objects — update.oblr","title":"Update Method for oblr Objects — update.oblr","text":"Updates oblr model new parameters without refitting entire model.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/update.oblr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update Method for oblr Objects — update.oblr","text":"","code":"# S3 method for class 'oblr' update(object, formula., data., ...)"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/update.oblr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update Method for oblr Objects — update.oblr","text":"object object class oblr. formula. new formula model. specified, original formula retained. data. New data fitting model. specified, original data retained. ... Additional arguments passed methods.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/update.oblr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update Method for oblr Objects — update.oblr","text":"new object class oblr fitted updated parameters.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/vcov.oblr.html","id":null,"dir":"Reference","previous_headings":"","what":"Variance-Covariance Matrix Method for oblr Objects — vcov.oblr","title":"Variance-Covariance Matrix Method for oblr Objects — vcov.oblr","text":"Returns variance-covariance matrix estimated coefficients oblr model.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/vcov.oblr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Variance-Covariance Matrix Method for oblr Objects — vcov.oblr","text":"","code":"# S3 method for class 'oblr' vcov(object, ...)"},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/vcov.oblr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Variance-Covariance Matrix Method for oblr Objects — vcov.oblr","text":"object object class oblr. ... Additional arguments passed methods.","code":""},{"path":"https://evandeilton.github.io/OptimalBinningWoE/reference/vcov.oblr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Variance-Covariance Matrix Method for oblr Objects — vcov.oblr","text":"variance-covariance matrix estimated coefficients.","code":""}]

<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Optimal Binning for Numerical Variables using Divergence Measures and Information Value — optimal_binning_numerical_dmiv • OptimalBinningWoE</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Optimal Binning for Numerical Variables using Divergence Measures and Information Value — optimal_binning_numerical_dmiv"><meta name="description" content="Performs optimal binning for numerical variables using various divergence measures as proposed
by Zeng (2013). This method transforms continuous features into discrete bins by maximizing
the statistical divergence between distributions of positive and negative cases, while
maintaining interpretability constraints."><meta property="og:description" content="Performs optimal binning for numerical variables using various divergence measures as proposed
by Zeng (2013). This method transforms continuous features into discrete bins by maximizing
the statistical divergence between distributions of positive and negative cases, while
maintaining interpretability constraints."></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">OptimalBinningWoE</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.3.2</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Optimal Binning for Numerical Variables using Divergence Measures and Information Value</h1>

      <div class="d-none name"><code>optimal_binning_numerical_dmiv.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>Performs optimal binning for numerical variables using various divergence measures as proposed
by Zeng (2013). This method transforms continuous features into discrete bins by maximizing
the statistical divergence between distributions of positive and negative cases, while
maintaining interpretability constraints.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">optimal_binning_numerical_dmiv</span><span class="op">(</span></span>
<span>  <span class="va">target</span>,</span>
<span>  <span class="va">feature</span>,</span>
<span>  min_bins <span class="op">=</span> <span class="fl">3L</span>,</span>
<span>  max_bins <span class="op">=</span> <span class="fl">5L</span>,</span>
<span>  bin_cutoff <span class="op">=</span> <span class="fl">0.05</span>,</span>
<span>  max_n_prebins <span class="op">=</span> <span class="fl">20L</span>,</span>
<span>  is_monotonic <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  convergence_threshold <span class="op">=</span> <span class="fl">1e-06</span>,</span>
<span>  max_iterations <span class="op">=</span> <span class="fl">1000L</span>,</span>
<span>  bin_method <span class="op">=</span> <span class="st">"woe1"</span>,</span>
<span>  divergence_method <span class="op">=</span> <span class="st">"l2"</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-target">target<a class="anchor" aria-label="anchor" href="#arg-target"></a></dt>
<dd><p>An integer binary vector (0 or 1) representing the target variable.</p></dd>


<dt id="arg-feature">feature<a class="anchor" aria-label="anchor" href="#arg-feature"></a></dt>
<dd><p>A numeric vector of feature values to be binned.</p></dd>


<dt id="arg-min-bins">min_bins<a class="anchor" aria-label="anchor" href="#arg-min-bins"></a></dt>
<dd><p>Minimum number of bins to generate (default: 3).</p></dd>


<dt id="arg-max-bins">max_bins<a class="anchor" aria-label="anchor" href="#arg-max-bins"></a></dt>
<dd><p>Maximum number of bins to generate (default: 5).</p></dd>


<dt id="arg-bin-cutoff">bin_cutoff<a class="anchor" aria-label="anchor" href="#arg-bin-cutoff"></a></dt>
<dd><p>Minimum frequency fraction for each bin (default: 0.05).</p></dd>


<dt id="arg-max-n-prebins">max_n_prebins<a class="anchor" aria-label="anchor" href="#arg-max-n-prebins"></a></dt>
<dd><p>Maximum number of pre-bins generated before optimization (default: 20).</p></dd>


<dt id="arg-is-monotonic">is_monotonic<a class="anchor" aria-label="anchor" href="#arg-is-monotonic"></a></dt>
<dd><p>Logical value indicating whether to enforce monotonicity in WoE (default: TRUE).</p></dd>


<dt id="arg-convergence-threshold">convergence_threshold<a class="anchor" aria-label="anchor" href="#arg-convergence-threshold"></a></dt>
<dd><p>Convergence threshold for divergence measure change (default: 1e-6).</p></dd>


<dt id="arg-max-iterations">max_iterations<a class="anchor" aria-label="anchor" href="#arg-max-iterations"></a></dt>
<dd><p>Maximum number of iterations allowed for optimization (default: 1000).</p></dd>


<dt id="arg-bin-method">bin_method<a class="anchor" aria-label="anchor" href="#arg-bin-method"></a></dt>
<dd><p>Method for WoE calculation, either 'woe' (traditional) or 'woe1' (Zeng's) (default: 'woe1').</p></dd>


<dt id="arg-divergence-method">divergence_method<a class="anchor" aria-label="anchor" href="#arg-divergence-method"></a></dt>
<dd><p>Divergence measure to optimize. Options:</p><ul><li><p>'he': Hellinger Discrimination</p></li>
<li><p>'kl': Kullback-Leibler Divergence</p></li>
<li><p>'tr': Triangular Discrimination</p></li>
<li><p>'klj': J-Divergence (symmetric KL)</p></li>
<li><p>'sc': Chi-Square Symmetric Divergence</p></li>
<li><p>'js': Jensen-Shannon Divergence</p></li>
<li><p>'l1': L1 metric (Manhattan distance)</p></li>
<li><p>'l2': L2 metric (Euclidean distance) - Default</p></li>
<li><p>'ln': L-infinity metric (Maximum distance)</p></li>
</ul></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p>A list containing:</p>
<dl><dt>id</dt>
<dd><p>Numeric identifiers for each bin (1-based).</p></dd>

<dt>bin</dt>
<dd><p>Character vector with the intervals of each bin (e.g., <code>(-Inf; 0]</code>, <code>(0; +Inf)</code>).</p></dd>

<dt>woe</dt>
<dd><p>Numeric vector with the Weight of Evidence values for each bin.</p></dd>

<dt>divergence</dt>
<dd><p>Numeric vector with the divergence measure contribution for each bin.</p></dd>

<dt>count</dt>
<dd><p>Integer vector with the total number of observations in each bin.</p></dd>

<dt>count_pos</dt>
<dd><p>Integer vector with the number of positive observations in each bin.</p></dd>

<dt>count_neg</dt>
<dd><p>Integer vector with the number of negative observations in each bin.</p></dd>

<dt>cutpoints</dt>
<dd><p>Numeric vector of cut points between bins (excluding infinity).</p></dd>

<dt>converged</dt>
<dd><p>Logical value indicating whether the algorithm converged.</p></dd>

<dt>iterations</dt>
<dd><p>Number of iterations executed by the optimization algorithm.</p></dd>

<dt>total_divergence</dt>
<dd><p>The total divergence measure of the binning solution.</p></dd>

<dt>bin_method</dt>
<dd><p>The WoE calculation method used ('woe' or 'woe1').</p></dd>

<dt>divergence_method</dt>
<dd><p>The divergence measure used for optimization.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>
    <p>This implementation is based on the theoretical framework from Zeng (2013) "Metric Divergence
Measures and Information Value in Credit Scoring", which explores various divergence measures
for optimal binning in credit scoring applications.</p>
<p>The algorithm extends traditional optimal binning by:</p><ol><li><p>Supporting multiple divergence measures including true metric distances (L1, L2, L-infinity)</p></li>
<li><p>Offering choice between traditional WoE and Zeng's corrected WOE1 formula</p></li>
<li><p>Optimizing bin boundaries to maximize the chosen divergence measure</p></li>
<li><p>Ensuring monotonicity when requested, with direction determined by divergence maximization</p></li>
</ol><p>The mathematical formulations of the divergence measures include:</p>
<p>$$Hellinger: h(P||Q) = \frac{1}{2}\sum_{i=1}^{n}(\sqrt{p_i} - \sqrt{q_i})^2$$
$$Kullback-Leibler: D(P||Q) = \sum_{i=1}^{n}p_i\ln(\frac{p_i}{q_i})$$
$$J-Divergence: J(P||Q) = \sum_{i=1}^{n}(p_i - q_i)\ln(\frac{p_i}{q_i})$$
$$Triangular: \Delta(P||Q) = \sum_{i=1}^{n}\frac{(p_i - q_i)^2}{p_i + q_i}$$
$$Chi-Square: \psi(P||Q) = \sum_{i=1}^{n}\frac{(p_i - q_i)^2(p_i + q_i)}{p_iq_i}$$
$$Jensen-Shannon: I(P||Q) = \frac{1}{2}[\sum_{i=1}^{n}p_i\ln(\frac{2p_i}{p_i+q_i}) + \sum_{i=1}^{n}q_i\ln(\frac{2q_i}{p_i+q_i})]$$
$$L1: L_1(P||Q) = \sum_{i=1}^{n}|p_i - q_i|$$
$$L2: L_2(P||Q) = \sqrt{\sum_{i=1}^{n}(p_i - q_i)^2}$$
$$L-infinity: L_\infty(P||Q) = \max_{1 \leq i \leq n}|p_i - q_i|$$</p>
<p>WoE calculation methods:
$$Traditional WoE: \ln(\frac{p_i/P}{n_i/N})$$
$$Zeng's WOE1: \ln(\frac{g_i}{b_i})$$</p>
<p>Where:</p><ul><li><p>\(p_i, q_i\): Proportion of positive/negative cases in bin i</p></li>
<li><p>\(g_i, b_i\): Count of positive/negative cases in bin i</p></li>
<li><p>\(P, N\): Total positive/negative cases</p></li>
</ul></div>
    <div class="section level2">
    <h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a></h2>
    <p>Zeng, G. (2013). Metric Divergence Measures and Information Value in Credit Scoring.
Journal of Mathematics, 2013, Article ID 848271, 10 pages.</p>
<p>Siddiqi, N. (2006). Credit Risk Scorecards: Developing and Implementing Intelligent Credit Scoring.
John Wiley &amp; Sons.</p>
<p>Thomas, L. C., Edelman, D. B., &amp; Crook, J. N. (2002). Credit Scoring and Its Applications.
Society for Industrial and Applied Mathematics.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="kw">if</span> <span class="op">(</span><span class="cn">FALSE</span><span class="op">)</span> <span class="op">{</span> <span class="co"># \dontrun{</span></span></span>
<span class="r-in"><span><span class="co"># Generate synthetic data</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">10000</span></span></span>
<span class="r-in"><span><span class="va">feature</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="co"># Create target with logistic relationship</span></span></span>
<span class="r-in"><span><span class="va">target</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html" class="external-link">rbinom</a></span><span class="op">(</span><span class="va">n</span>, <span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/stats/Logistic.html" class="external-link">plogis</a></span><span class="op">(</span><span class="fl">0.5</span> <span class="op">*</span> <span class="va">feature</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Apply optimal binning with default L2 metric and WOE1</span></span></span>
<span class="r-in"><span><span class="va">result</span> <span class="op">&lt;-</span> <span class="fu">optimal_binning_numerical_dmiv</span><span class="op">(</span><span class="va">target</span>, <span class="va">feature</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">result</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Try with J-Divergence and traditional WoE</span></span></span>
<span class="r-in"><span><span class="va">result_j</span> <span class="op">&lt;-</span> <span class="fu">optimal_binning_numerical_dmiv</span><span class="op">(</span></span></span>
<span class="r-in"><span>  target <span class="op">=</span> <span class="va">target</span>,</span></span>
<span class="r-in"><span>  feature <span class="op">=</span> <span class="va">feature</span>,</span></span>
<span class="r-in"><span>  divergence_method <span class="op">=</span> <span class="st">"klj"</span>,</span></span>
<span class="r-in"><span>  bin_method <span class="op">=</span> <span class="st">"woe"</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Compare results from different metrics</span></span></span>
<span class="r-in"><span><span class="va">l1_result</span> <span class="op">&lt;-</span> <span class="fu">optimal_binning_numerical_dmiv</span><span class="op">(</span><span class="va">target</span>, <span class="va">feature</span>, divergence_method <span class="op">=</span> <span class="st">"l1"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">l2_result</span> <span class="op">&lt;-</span> <span class="fu">optimal_binning_numerical_dmiv</span><span class="op">(</span><span class="va">target</span>, <span class="va">feature</span>, divergence_method <span class="op">=</span> <span class="st">"l2"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">ln_result</span> <span class="op">&lt;-</span> <span class="fu">optimal_binning_numerical_dmiv</span><span class="op">(</span><span class="va">target</span>, <span class="va">feature</span>, divergence_method <span class="op">=</span> <span class="st">"ln"</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Compare total divergence values</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"L1 total divergence:"</span>, <span class="va">l1_result</span><span class="op">$</span><span class="va">total_divergence</span>, <span class="st">"\n"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"L2 total divergence:"</span>, <span class="va">l2_result</span><span class="op">$</span><span class="va">total_divergence</span>, <span class="st">"\n"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"L-infinity total divergence:"</span>, <span class="va">ln_result</span><span class="op">$</span><span class="va">total_divergence</span>, <span class="st">"\n"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">}</span> <span class="co"># }</span></span></span>
<span class="r-in"><span></span></span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Lopes J. E.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.2.</p>
</div>

    </footer></div>





  </body></html>


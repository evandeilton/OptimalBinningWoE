<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Optimal Binning for Numerical Variables using Unsupervised Binning with Standard Deviation — ob_numerical_ubsd • OptimalBinningWoE</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Optimal Binning for Numerical Variables using Unsupervised Binning with Standard Deviation — ob_numerical_ubsd"><meta name="description" content='Implements a hybrid binning algorithm that initializes bins using
unsupervised statistical properties (mean and standard deviation of
the feature) and refines them through supervised optimization using
Weight of Evidence (WoE) and Information Value (IV).
Important Clarification: Despite "Unsupervised" in the name, this
method is predominantly supervised. The unsupervised component is
limited to the initial bin creation step (~1% of the algorithm). All subsequent
refinement (merge, monotonicity enforcement, bin count adjustment) uses the
target variable extensively.
The statistical initialization via \(\mu \pm k\sigma\) provides a data-driven
starting point that may be advantageous for approximately normal distributions,
but offers no guarantees for skewed or multimodal data.'><meta property="og:description" content='Implements a hybrid binning algorithm that initializes bins using
unsupervised statistical properties (mean and standard deviation of
the feature) and refines them through supervised optimization using
Weight of Evidence (WoE) and Information Value (IV).
Important Clarification: Despite "Unsupervised" in the name, this
method is predominantly supervised. The unsupervised component is
limited to the initial bin creation step (~1% of the algorithm). All subsequent
refinement (merge, monotonicity enforcement, bin count adjustment) uses the
target variable extensively.
The statistical initialization via \(\mu \pm k\sigma\) provides a data-driven
starting point that may be advantageous for approximately normal distributions,
but offers no guarantees for skewed or multimodal data.'><meta property="og:image" content="https://evandeilton.github.io/OptimalBinningWoE/logo.png"></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">OptimalBinningWoE</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.0.1</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles"><li><a class="dropdown-item" href="../articles/introduction.html">OptimalBinningWoE: Practical Guide for Credit Risk Modeling</a></li>
  </ul></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/evandeilton/OptimalBinningWoE/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Optimal Binning for Numerical Variables using Unsupervised Binning with Standard Deviation</h1>
      <small class="dont-index">Source: <a href="https://github.com/evandeilton/OptimalBinningWoE/blob/main/R/obn_ubsd.R" class="external-link"><code>R/obn_ubsd.R</code></a></small>
      <div class="d-none name"><code>ob_numerical_ubsd.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>Implements a <strong>hybrid binning algorithm</strong> that initializes bins using
<strong>unsupervised statistical properties</strong> (mean and standard deviation of
the feature) and refines them through <strong>supervised optimization</strong> using
Weight of Evidence (WoE) and Information Value (IV).</p>
<p><strong>Important Clarification</strong>: Despite "Unsupervised" in the name, this
method is <strong>predominantly supervised</strong>. The unsupervised component is
limited to the initial bin creation step (~1% of the algorithm). All subsequent
refinement (merge, monotonicity enforcement, bin count adjustment) uses the
target variable extensively.</p>
<p>The statistical initialization via \(\mu \pm k\sigma\) provides a data-driven
starting point that may be advantageous for approximately normal distributions,
but offers no guarantees for skewed or multimodal data.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">ob_numerical_ubsd</span><span class="op">(</span></span>
<span>  <span class="va">feature</span>,</span>
<span>  <span class="va">target</span>,</span>
<span>  min_bins <span class="op">=</span> <span class="fl">3</span>,</span>
<span>  max_bins <span class="op">=</span> <span class="fl">5</span>,</span>
<span>  bin_cutoff <span class="op">=</span> <span class="fl">0.05</span>,</span>
<span>  max_n_prebins <span class="op">=</span> <span class="fl">20</span>,</span>
<span>  convergence_threshold <span class="op">=</span> <span class="fl">1e-06</span>,</span>
<span>  max_iterations <span class="op">=</span> <span class="fl">1000</span>,</span>
<span>  laplace_smoothing <span class="op">=</span> <span class="fl">0.5</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-feature">feature<a class="anchor" aria-label="anchor" href="#arg-feature"></a></dt>
<dd><p>Numeric vector of feature values. Missing values (NA) and infinite
values are <strong>not permitted</strong> and will trigger an error.</p></dd>


<dt id="arg-target">target<a class="anchor" aria-label="anchor" href="#arg-target"></a></dt>
<dd><p>Integer or numeric vector of binary target values (must contain
only 0 and 1). Must have the same length as <code>feature</code>.</p></dd>


<dt id="arg-min-bins">min_bins<a class="anchor" aria-label="anchor" href="#arg-min-bins"></a></dt>
<dd><p>Minimum number of bins (default: 3). Must be at least 2.</p></dd>


<dt id="arg-max-bins">max_bins<a class="anchor" aria-label="anchor" href="#arg-max-bins"></a></dt>
<dd><p>Maximum number of bins (default: 5). Must be \(\ge\) <code>min_bins</code>.</p></dd>


<dt id="arg-bin-cutoff">bin_cutoff<a class="anchor" aria-label="anchor" href="#arg-bin-cutoff"></a></dt>
<dd><p>Minimum fraction of total observations per bin (default: 0.05).
Must be in (0, 1).</p></dd>


<dt id="arg-max-n-prebins">max_n_prebins<a class="anchor" aria-label="anchor" href="#arg-max-n-prebins"></a></dt>
<dd><p>Maximum number of pre-bins before optimization (default: 20).
Must be at least equal to <code>min_bins</code>.</p></dd>


<dt id="arg-convergence-threshold">convergence_threshold<a class="anchor" aria-label="anchor" href="#arg-convergence-threshold"></a></dt>
<dd><p>Convergence threshold for IV change (default: 1e-6).</p></dd>


<dt id="arg-max-iterations">max_iterations<a class="anchor" aria-label="anchor" href="#arg-max-iterations"></a></dt>
<dd><p>Maximum iterations for optimization (default: 1000).</p></dd>


<dt id="arg-laplace-smoothing">laplace_smoothing<a class="anchor" aria-label="anchor" href="#arg-laplace-smoothing"></a></dt>
<dd><p>Laplace smoothing parameter (default: 0.5). Must be
non-negative.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p>A list containing:</p><dl><dt>id</dt>
<dd><p>Integer bin identifiers (1-based).</p></dd>

  <dt>bin</dt>
<dd><p>Character bin intervals <code>"[lower;upper)"</code>.</p></dd>

  <dt>woe</dt>
<dd><p>Numeric WoE values (monotonic after enforcement).</p></dd>

  <dt>iv</dt>
<dd><p>Numeric IV contributions per bin.</p></dd>

  <dt>count</dt>
<dd><p>Integer total observations per bin.</p></dd>

  <dt>count_pos</dt>
<dd><p>Integer positive class counts.</p></dd>

  <dt>count_neg</dt>
<dd><p>Integer negative class counts.</p></dd>

  <dt>event_rate</dt>
<dd><p>Numeric event rates per bin.</p></dd>

  <dt>cutpoints</dt>
<dd><p>Numeric bin boundaries (excluding \(\pm\infty\)).</p></dd>

  <dt>total_iv</dt>
<dd><p>Total Information Value.</p></dd>

  <dt>converged</dt>
<dd><p>Logical convergence flag.</p></dd>

  <dt>iterations</dt>
<dd><p>Integer iteration count.</p></dd>


</dl></div>
    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>
    <p><strong>Algorithm Overview</strong></p>
<p>UBSD executes in six phases:</p>
<p><strong>Phase 1: Statistical Initialization (UNSUPERVISED)</strong></p>
<p>Initial bin edges are created by combining two approaches:</p>
<ol><li><p><strong>Standard deviation-based cutpoints</strong>:
    $$\{\mu - 2\sigma, \mu - \sigma, \mu, \mu + \sigma, \mu + 2\sigma\}$$
    where \(\mu\) is the sample mean and \(\sigma\) is the sample standard
    deviation (with Bessel correction: \(N-1\) divisor).</p></li>
<li><p><strong>Equal-width cutpoints</strong>:
    $$\left\{x_{\min} + i \times \frac{x_{\max} - x_{\min}}{\text{max\_n\_prebins}}\right\}_{i=1}^{\text{max\_n\_prebins}-1}$$</p></li>
</ol><p>The union of these two sets is taken, sorted, and limited to <code>max_n_prebins</code>
edges (plus \(-\infty\) and \(+\infty\) boundaries).</p>
<p><strong>Rationale</strong>: For approximately normal distributions, \(\mu \pm k\sigma\)
cutpoints align with natural quantiles:</p><ul><li><p>\(\mu - 2\sigma\) to \(\mu + 2\sigma\) captures ~95% of data (68-95-99.7 rule)</p></li>
<li><p>Equal-width ensures coverage of entire range</p></li>
</ul><p><strong>Limitation</strong>: For skewed distributions (e.g., log-normal), \(\mu - 2\sigma\)
may fall outside the data range, creating empty bins.</p>
<p><strong>Special Case</strong>: If \(\sigma &lt; \epsilon\) (feature is nearly constant),
fallback to pure equal-width binning.</p>
<p><strong>Phase 2: Observation Assignment</strong></p>
<p>Each observation is assigned to a bin via linear search:
$$\text{bin}(x_i) = \min\{j : x_i &gt; \text{lower}_j \land x_i \le \text{upper}_j\}$$</p>
<p>Counts are accumulated: <code>count</code>, <code>count_pos</code>, <code>count_neg</code>.</p>
<p><strong>Phase 3: Rare Bin Merging (SUPERVISED)</strong></p>
<p>Bins with \(\text{count} &lt; \text{bin\_cutoff} \times N\) are merged with
adjacent bins. Merge direction is chosen to minimize IV loss:</p>
<p>$$\text{direction} = \arg\min_{d \in \{\text{left}, \text{right}\}} \left( \text{IV}_i + \text{IV}_{i+d} \right)$$</p>
<p>This is a <strong>supervised</strong> step (uses IV computed from target).</p>
<p><strong>Phase 4: WoE/IV Calculation (SUPERVISED)</strong></p>
<p>Weight of Evidence with Laplace smoothing:
$$\text{WoE}_i = \ln\left(\frac{n_i^{+} + \alpha}{n^{+} + k\alpha} \bigg/ \frac{n_i^{-} + \alpha}{n^{-} + k\alpha}\right)$$</p>
<p>Information Value:
$$\text{IV}_i = \left(\frac{n_i^{+} + \alpha}{n^{+} + k\alpha} - \frac{n_i^{-} + \alpha}{n^{-} + k\alpha}\right) \times \text{WoE}_i$$</p>
<p><strong>Phase 5: Monotonicity Enforcement (SUPERVISED)</strong></p>
<p>Direction is auto-detected via majority vote:
$$\text{increasing} = \begin{cases} \text{TRUE} &amp; \text{if } \sum_i \mathbb{1}_{\{\text{WoE}_i &gt; \text{WoE}_{i-1}\}} \ge \sum_i \mathbb{1}_{\{\text{WoE}_i &lt; \text{WoE}_{i-1}\}} \\ \text{FALSE} &amp; \text{otherwise} \end{cases}$$</p>
<p>Violations are resolved via PAVA (Pool Adjacent Violators Algorithm).</p>
<p><strong>Phase 6: Bin Count Adjustment (SUPERVISED)</strong></p>
<p>If \(k &gt; \text{max\_bins}\), bins are merged to minimize IV loss:
$$\text{merge\_idx} = \arg\min_{i=0}^{k-2} \left( \text{IV}_i + \text{IV}_{i+1} \right)$$</p>
<p><strong>Convergence Criterion</strong>:
$$|\text{IV}_{\text{total}}^{(t)} - \text{IV}_{\text{total}}^{(t-1)}| &lt; \text{convergence\_threshold}$$</p>
<p><strong>Comparison with Related Methods</strong></p>
<table class="table table"><tr><td><strong>Method</strong></td><td><strong>Initialization</strong></td><td><strong>Truly Unsupervised?</strong></td><td><strong>Best For</strong></td></tr><tr><td>UBSD</td><td>\(\mu \pm k\sigma\) + equal-width</td><td>No (1 pct unsup)</td><td>Normal distributions</td></tr><tr><td>MOB/MRBLP</td><td>Equal-frequency</td><td>No (0 pct unsup)</td><td>General use</td></tr><tr><td>MDLP</td><td>Equal-frequency</td><td>No (0 pct unsup)</td><td>Information theory</td></tr><tr><td>Sketch</td><td>KLL Sketch quantiles</td><td>No (0 pct unsup)</td><td>Streaming data</td></tr></table><p><strong>When to Use UBSD</strong></p>
<ul><li><p><strong>Use UBSD</strong>: If you have prior knowledge that the feature is
    approximately normally distributed and want bins aligned with standard
    deviations (e.g., for interpretability: "2 standard deviations below mean").</p></li>
<li><p><strong>Avoid UBSD</strong>: For skewed distributions (use MDLP or MOB), for
    multimodal distributions (use LDB), or when you need provable optimality
    (use Sketch for quantile guarantees).</p></li>
<li><p><strong>Alternative</strong>: For true unsupervised binning (no target), use
    <code><a href="https://rdrr.io/r/base/cut.html" class="external-link">cut()</a></code> with <code>breaks = "Sturges"</code> or <code>"FD"</code> (Freedman-Diaconis).</p></li>
</ul><p><strong>Computational Complexity</strong></p>
<p>Identical to MOB/MRBLP: \(O(N + k^2 \times \text{max\_iterations})\)</p>
    </div>
    <div class="section level2">
    <h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a></h2>

<ul><li><p>Sturges, H. A. (1926). "The Choice of a Class Interval". <em>Journal
    of the American Statistical Association</em>, 21(153), 65-66.</p></li>
<li><p>Scott, D. W. (1979). "On optimal and data-based histograms". <em>Biometrika</em>,
    66(3), 605-610.</p></li>
<li><p>Freedman, D., &amp; Diaconis, P. (1981). "On the histogram as a density estimator:
    L2 theory". <em>Zeitschrift fuer Wahrscheinlichkeitstheorie</em>, 57(4), 453-476.</p></li>
<li><p>Thomas, L. C. (2009). <em>Consumer Credit Models: Pricing, Profit, and
    Portfolios</em>. Oxford University Press.</p></li>
<li><p>Zeng, G. (2014). "A Necessary Condition for a Good Binning Algorithm in
    Credit Scoring". <em>Applied Mathematical Sciences</em>, 8(65), 3229-3242.</p></li>
<li><p>Siddiqi, N. (2006). <em>Credit Risk Scorecards</em>. Wiley.</p></li>
</ul></div>
    <div class="section level2">
    <h2 id="see-also">See also<a class="anchor" aria-label="anchor" href="#see-also"></a></h2>
    <div class="dont-index"><p><code><a href="ob_numerical_mdlp.html">ob_numerical_mdlp</a></code> for information-theoretic binning,
<code><a href="ob_numerical_mob.html">ob_numerical_mob</a></code> for pure supervised binning,
<code><a href="https://rdrr.io/r/base/cut.html" class="external-link">cut</a></code> for true unsupervised binning.</p></div>
    </div>
    <div class="section level2">
    <h2 id="author">Author<a class="anchor" aria-label="anchor" href="#author"></a></h2>
    <p>Lopes, J. E.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="kw">if</span> <span class="op">(</span><span class="cn">FALSE</span><span class="op">)</span> <span class="op">{</span> <span class="co"># \dontrun{</span></span></span>
<span class="r-in"><span><span class="co"># Simulate normally distributed credit scores</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">5000</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Feature: Normally distributed FICO scores</span></span></span>
<span class="r-in"><span><span class="va">feature</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span>, mean <span class="op">=</span> <span class="fl">680</span>, sd <span class="op">=</span> <span class="fl">60</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Target: Logistic relationship with score</span></span></span>
<span class="r-in"><span><span class="va">prob_default</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">/</span> <span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="op">(</span><span class="va">feature</span> <span class="op">-</span> <span class="fl">680</span><span class="op">)</span> <span class="op">/</span> <span class="fl">30</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">target</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html" class="external-link">rbinom</a></span><span class="op">(</span><span class="va">n</span>, <span class="fl">1</span>, <span class="va">prob_default</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Apply UBSD</span></span></span>
<span class="r-in"><span><span class="va">result</span> <span class="op">&lt;-</span> <span class="fu">ob_numerical_ubsd</span><span class="op">(</span></span></span>
<span class="r-in"><span>  feature <span class="op">=</span> <span class="va">feature</span>,</span></span>
<span class="r-in"><span>  target <span class="op">=</span> <span class="va">target</span>,</span></span>
<span class="r-in"><span>  min_bins <span class="op">=</span> <span class="fl">3</span>,</span></span>
<span class="r-in"><span>  max_bins <span class="op">=</span> <span class="fl">5</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Compare with MDLP (should be similar for normal data)</span></span></span>
<span class="r-in"><span><span class="va">result_mdlp</span> <span class="op">&lt;-</span> <span class="fu"><a href="ob_numerical_mdlp.html">ob_numerical_mdlp</a></span><span class="op">(</span><span class="va">feature</span>, <span class="va">target</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span></span></span>
<span class="r-in"><span>  Method <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"UBSD"</span>, <span class="st">"MDLP"</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>  N_Bins <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">result</span><span class="op">$</span><span class="va">woe</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">result_mdlp</span><span class="op">$</span><span class="va">woe</span><span class="op">)</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>  Total_IV <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">result</span><span class="op">$</span><span class="va">total_iv</span>, <span class="va">result_mdlp</span><span class="op">$</span><span class="va">total_iv</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">}</span> <span class="co"># }</span></span></span>
<span class="r-in"><span></span></span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by José Evandeilton Lopes.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

    </footer></div>





  </body></html>


<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Optimal Binning for Categorical Variables using Monotonic Binning Algorithm (MBA) — optimal_binning_categorical_mba • OptimalBinningWoE</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Optimal Binning for Categorical Variables using Monotonic Binning Algorithm (MBA) — optimal_binning_categorical_mba"><meta name="description" content="Performs optimal binning for categorical variables using a Monotonic Binning Algorithm (MBA),
which combines Weight of Evidence (WOE) and Information Value (IV) methods with monotonicity
constraints. This implementation includes Bayesian smoothing for robust estimation with small
samples, adaptive monotonicity enforcement, and efficient handling of rare categories."><meta property="og:description" content="Performs optimal binning for categorical variables using a Monotonic Binning Algorithm (MBA),
which combines Weight of Evidence (WOE) and Information Value (IV) methods with monotonicity
constraints. This implementation includes Bayesian smoothing for robust estimation with small
samples, adaptive monotonicity enforcement, and efficient handling of rare categories."></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">OptimalBinningWoE</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.3.2</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Optimal Binning for Categorical Variables using Monotonic Binning Algorithm (MBA)</h1>

      <div class="d-none name"><code>optimal_binning_categorical_mba.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>Performs optimal binning for categorical variables using a Monotonic Binning Algorithm (MBA),
which combines Weight of Evidence (WOE) and Information Value (IV) methods with monotonicity
constraints. This implementation includes Bayesian smoothing for robust estimation with small
samples, adaptive monotonicity enforcement, and efficient handling of rare categories.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">optimal_binning_categorical_mba</span><span class="op">(</span></span>
<span>  <span class="va">target</span>,</span>
<span>  <span class="va">feature</span>,</span>
<span>  min_bins <span class="op">=</span> <span class="fl">3L</span>,</span>
<span>  max_bins <span class="op">=</span> <span class="fl">5L</span>,</span>
<span>  bin_cutoff <span class="op">=</span> <span class="fl">0.05</span>,</span>
<span>  max_n_prebins <span class="op">=</span> <span class="fl">20L</span>,</span>
<span>  bin_separator <span class="op">=</span> <span class="st">"%;%"</span>,</span>
<span>  convergence_threshold <span class="op">=</span> <span class="fl">1e-06</span>,</span>
<span>  max_iterations <span class="op">=</span> <span class="fl">1000L</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-target">target<a class="anchor" aria-label="anchor" href="#arg-target"></a></dt>
<dd><p>An integer vector of binary target values (0 or 1).</p></dd>


<dt id="arg-feature">feature<a class="anchor" aria-label="anchor" href="#arg-feature"></a></dt>
<dd><p>A character vector of categorical feature values.</p></dd>


<dt id="arg-min-bins">min_bins<a class="anchor" aria-label="anchor" href="#arg-min-bins"></a></dt>
<dd><p>Minimum number of bins (default: 3).</p></dd>


<dt id="arg-max-bins">max_bins<a class="anchor" aria-label="anchor" href="#arg-max-bins"></a></dt>
<dd><p>Maximum number of bins (default: 5).</p></dd>


<dt id="arg-bin-cutoff">bin_cutoff<a class="anchor" aria-label="anchor" href="#arg-bin-cutoff"></a></dt>
<dd><p>Minimum frequency for a category to be considered as a separate bin (default: 0.05).</p></dd>


<dt id="arg-max-n-prebins">max_n_prebins<a class="anchor" aria-label="anchor" href="#arg-max-n-prebins"></a></dt>
<dd><p>Maximum number of pre-bins before merging (default: 20).</p></dd>


<dt id="arg-bin-separator">bin_separator<a class="anchor" aria-label="anchor" href="#arg-bin-separator"></a></dt>
<dd><p>String used to separate category names when merging bins (default: "%;%").</p></dd>


<dt id="arg-convergence-threshold">convergence_threshold<a class="anchor" aria-label="anchor" href="#arg-convergence-threshold"></a></dt>
<dd><p>Threshold for convergence in optimization (default: 1e-6).</p></dd>


<dt id="arg-max-iterations">max_iterations<a class="anchor" aria-label="anchor" href="#arg-max-iterations"></a></dt>
<dd><p>Maximum number of iterations for optimization (default: 1000).</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p>A list containing:</p><ul><li><p>id: Numeric vector of bin identifiers.</p></li>
<li><p>bin: Character vector of bin labels.</p></li>
<li><p>woe: Numeric vector of Weight of Evidence values for each bin.</p></li>
<li><p>iv: Numeric vector of Information Value for each bin.</p></li>
<li><p>count: Integer vector of total counts for each bin.</p></li>
<li><p>count_pos: Integer vector of positive target counts for each bin.</p></li>
<li><p>count_neg: Integer vector of negative target counts for each bin.</p></li>
<li><p>total_iv: Total Information Value of the binning.</p></li>
<li><p>converged: Logical value indicating whether the algorithm converged.</p></li>
<li><p>iterations: Integer indicating the number of iterations run.</p></li>
</ul></div>
    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>
    <p>This algorithm implements an enhanced version of the monotonic binning approach with several
key features:</p>
<ol><li><p><strong>Bayesian Smoothing:</strong> Applies prior pseudo-counts proportional to the overall class
prevalence to improve stability for small bins and rare categories.</p></li>
<li><p><strong>Adaptive Monotonicity:</strong> Uses context-aware thresholds based on the average WoE
difference between bins to better handle datasets with varying scales.</p></li>
<li><p><strong>Similarity-Based Merging:</strong> Merges bins based on event rate similarity rather than
just adjacency, which better preserves information content.</p></li>
<li><p><strong>Best Solution Tracking:</strong> Maintains the best solution found during optimization,
even if the algorithm doesn't formally converge.</p></li>
</ol><p>The mathematical foundation of the algorithm is based on the following concepts:</p>
<p>The Weight of Evidence (WoE) with Bayesian smoothing is calculated as:</p>
<p>$$WoE_i = \ln\left(\frac{p_i^*}{q_i^*}\right)$$</p>
<p>where:</p><ul><li><p>\(p_i^* = \frac{n_i^+ + \alpha \cdot \pi}{N^+ + \alpha}\) is the smoothed proportion of
positive cases in bin i</p></li>
<li><p>\(q_i^* = \frac{n_i^- + \alpha \cdot (1-\pi)}{N^- + \alpha}\) is the smoothed proportion of
negative cases in bin i</p></li>
<li><p>\(\pi = \frac{N^+}{N^+ + N^-}\) is the overall positive rate</p></li>
<li><p>\(\alpha\) is the prior strength parameter (default: 0.5)</p></li>
<li><p>\(n_i^+\) is the count of positive cases in bin i</p></li>
<li><p>\(n_i^-\) is the count of negative cases in bin i</p></li>
<li><p>\(N^+\) is the total number of positive cases</p></li>
<li><p>\(N^-\) is the total number of negative cases</p></li>
</ul><p>The Information Value (IV) for each bin is calculated as:</p>
<p>$$IV_i = (p_i^* - q_i^*) \times WoE_i$$</p>
<p>And the total IV is:</p>
<p>$$IV_{total} = \sum_{i=1}^{k} |IV_i|$$</p>
<p>The algorithm performs the following steps:</p><ol><li><p>Input validation and preprocessing</p></li>
<li><p>Initial pre-binning based on frequency</p></li>
<li><p>Merging of rare categories based on bin_cutoff</p></li>
<li><p>Calculation of WoE and IV with Bayesian smoothing</p></li>
<li><p>Enforcement of monotonicity constraints</p></li>
<li><p>Optimization of bin count through iterative merging</p></li>
</ol></div>
    <div class="section level2">
    <h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a></h2>

<ul><li><p>Beltrami, M., Mach, M., &amp; Dall'Aglio, M. (2021). Monotonic Optimal Binning Algorithm for Credit Risk Modeling. Risks, 9(3), 58.</p></li>
<li><p>Siddiqi, N. (2006). Credit risk scorecards: developing and implementing intelligent credit scoring (Vol. 3). John Wiley &amp; Sons.</p></li>
<li><p>Mironchyk, P., &amp; Tchistiakov, V. (2017). Monotone Optimal Binning Algorithm for Credit Risk Modeling. Working Paper.</p></li>
<li><p>Gelman, A., Jakulin, A., Pittau, M. G., &amp; Su, Y. S. (2008). A weakly informative default prior distribution for logistic and other regression models. The annals of applied statistics, 2(4), 1360-1383.</p></li>
<li><p>Thomas, L.C., Edelman, D.B., &amp; Crook, J.N. (2002). Credit Scoring and its Applications. SIAM.</p></li>
<li><p>Navas-Palencia, G. (2020). Optimal binning: mathematical programming formulations for binary classification. arXiv preprint arXiv:2001.08025.</p></li>
<li><p>Lin, X., Wang, G., &amp; Zhang, T. (2022). Efficient monotonic binning for predictive modeling in high-dimensional spaces. Knowledge-Based Systems, 235, 107629.</p></li>
</ul></div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="kw">if</span> <span class="op">(</span><span class="cn">FALSE</span><span class="op">)</span> <span class="op">{</span> <span class="co"># \dontrun{</span></span></span>
<span class="r-in"><span><span class="co"># Create sample data</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">target</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fl">0</span><span class="op">:</span><span class="fl">1</span>, <span class="fl">1000</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">feature</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="va">LETTERS</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span><span class="op">]</span>, <span class="fl">1000</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Run optimal binning</span></span></span>
<span class="r-in"><span><span class="va">result</span> <span class="op">&lt;-</span> <span class="fu">optimal_binning_categorical_mba</span><span class="op">(</span><span class="va">feature</span>, <span class="va">target</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># View results</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">result</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Handle rare categories more aggressively</span></span></span>
<span class="r-in"><span><span class="va">result2</span> <span class="op">&lt;-</span> <span class="fu">optimal_binning_categorical_mba</span><span class="op">(</span></span></span>
<span class="r-in"><span>  <span class="va">feature</span>, <span class="va">target</span>, </span></span>
<span class="r-in"><span>  bin_cutoff <span class="op">=</span> <span class="fl">0.1</span>, </span></span>
<span class="r-in"><span>  min_bins <span class="op">=</span> <span class="fl">2</span>, </span></span>
<span class="r-in"><span>  max_bins <span class="op">=</span> <span class="fl">4</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">}</span> <span class="co"># }</span></span></span>
<span class="r-in"><span></span></span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Lopes J. E.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.2.</p>
</div>

    </footer></div>





  </body></html>


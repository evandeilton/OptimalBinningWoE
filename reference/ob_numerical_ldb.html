<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Optimal Binning for Numerical Variables using Local Density Binning — ob_numerical_ldb • OptimalBinningWoE</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Optimal Binning for Numerical Variables using Local Density Binning — ob_numerical_ldb"><meta name="description" content="Implements supervised discretization via Local Density Binning (LDB), a method
that leverages kernel density estimation to identify natural transition regions
in the feature space while optimizing the Weight of Evidence (WoE) monotonicity
and Information Value (IV) for binary classification tasks."><meta property="og:description" content="Implements supervised discretization via Local Density Binning (LDB), a method
that leverages kernel density estimation to identify natural transition regions
in the feature space while optimizing the Weight of Evidence (WoE) monotonicity
and Information Value (IV) for binary classification tasks."><meta property="og:image" content="https://evandeilton.github.io/OptimalBinningWoE/logo.png"></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">OptimalBinningWoE</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.0.1</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles"><li><a class="dropdown-item" href="../articles/introduction.html">OptimalBinningWoE: Practical Guide for Credit Risk Modeling</a></li>
  </ul></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/evandeilton/OptimalBinningWoE/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Optimal Binning for Numerical Variables using Local Density Binning</h1>
      <small class="dont-index">Source: <a href="https://github.com/evandeilton/OptimalBinningWoE/blob/main/R/obn_ldb.R" class="external-link"><code>R/obn_ldb.R</code></a></small>
      <div class="d-none name"><code>ob_numerical_ldb.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>Implements supervised discretization via Local Density Binning (LDB), a method
that leverages kernel density estimation to identify natural transition regions
in the feature space while optimizing the Weight of Evidence (WoE) monotonicity
and Information Value (IV) for binary classification tasks.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">ob_numerical_ldb</span><span class="op">(</span></span>
<span>  <span class="va">feature</span>,</span>
<span>  <span class="va">target</span>,</span>
<span>  min_bins <span class="op">=</span> <span class="fl">3</span>,</span>
<span>  max_bins <span class="op">=</span> <span class="fl">5</span>,</span>
<span>  bin_cutoff <span class="op">=</span> <span class="fl">0.05</span>,</span>
<span>  max_n_prebins <span class="op">=</span> <span class="fl">20</span>,</span>
<span>  enforce_monotonic <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  convergence_threshold <span class="op">=</span> <span class="fl">1e-06</span>,</span>
<span>  max_iterations <span class="op">=</span> <span class="fl">1000</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-feature">feature<a class="anchor" aria-label="anchor" href="#arg-feature"></a></dt>
<dd><p>Numeric vector of feature values to be binned. Missing values (NA)
and infinite values are automatically filtered out during preprocessing.</p></dd>


<dt id="arg-target">target<a class="anchor" aria-label="anchor" href="#arg-target"></a></dt>
<dd><p>Integer vector of binary target values (must contain only 0 and 1).
Must have the same length as <code>feature</code>.</p></dd>


<dt id="arg-min-bins">min_bins<a class="anchor" aria-label="anchor" href="#arg-min-bins"></a></dt>
<dd><p>Minimum number of bins to generate (default: 3). Must be at least 2.</p></dd>


<dt id="arg-max-bins">max_bins<a class="anchor" aria-label="anchor" href="#arg-max-bins"></a></dt>
<dd><p>Maximum number of bins to generate (default: 5). Must be greater
than or equal to <code>min_bins</code>.</p></dd>


<dt id="arg-bin-cutoff">bin_cutoff<a class="anchor" aria-label="anchor" href="#arg-bin-cutoff"></a></dt>
<dd><p>Minimum fraction of total observations in each bin (default: 0.05).
Bins with frequency below this threshold are merged with adjacent bins. Must be
in the range [0, 1].</p></dd>


<dt id="arg-max-n-prebins">max_n_prebins<a class="anchor" aria-label="anchor" href="#arg-max-n-prebins"></a></dt>
<dd><p>Maximum number of pre-bins before optimization (default: 20).
Controls granularity of initial density-based discretization.</p></dd>


<dt id="arg-enforce-monotonic">enforce_monotonic<a class="anchor" aria-label="anchor" href="#arg-enforce-monotonic"></a></dt>
<dd><p>Logical flag to enforce monotonicity in WoE values across
bins (default: TRUE). When enabled, bins violating monotonicity are iteratively
merged until global monotonicity is achieved.</p></dd>


<dt id="arg-convergence-threshold">convergence_threshold<a class="anchor" aria-label="anchor" href="#arg-convergence-threshold"></a></dt>
<dd><p>Convergence threshold for iterative optimization
(default: 1e-6). Currently used for future extensions.</p></dd>


<dt id="arg-max-iterations">max_iterations<a class="anchor" aria-label="anchor" href="#arg-max-iterations"></a></dt>
<dd><p>Maximum number of iterations for merging operations
(default: 1000). Prevents infinite loops in edge cases.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p>A list containing:</p><dl><dt>id</dt>
<dd><p>Integer vector of bin identifiers (1-based indexing).</p></dd>

  <dt>bin</dt>
<dd><p>Character vector of bin intervals in the format <code>"(lower;upper]"</code>.</p></dd>

  <dt>woe</dt>
<dd><p>Numeric vector of Weight of Evidence values for each bin.</p></dd>

  <dt>iv</dt>
<dd><p>Numeric vector of Information Value contributions for each bin.</p></dd>

  <dt>count</dt>
<dd><p>Integer vector of total observations in each bin.</p></dd>

  <dt>count_pos</dt>
<dd><p>Integer vector of positive class (target = 1) counts per bin.</p></dd>

  <dt>count_neg</dt>
<dd><p>Integer vector of negative class (target = 0) counts per bin.</p></dd>

  <dt>event_rate</dt>
<dd><p>Numeric vector of event rates (proportion of positives) per bin.</p></dd>

  <dt>cutpoints</dt>
<dd><p>Numeric vector of cutpoints defining bin boundaries (excluding
    -Inf and +Inf).</p></dd>

  <dt>converged</dt>
<dd><p>Logical flag indicating whether the algorithm converged within
    <code>max_iterations</code>.</p></dd>

  <dt>iterations</dt>
<dd><p>Integer count of iterations performed during optimization.</p></dd>

  <dt>total_iv</dt>
<dd><p>Numeric scalar representing the total Information Value
    (sum of all bin IVs).</p></dd>

  <dt>monotonicity</dt>
<dd><p>Character string indicating monotonicity status: <code>"increasing"</code>,
    <code>"decreasing"</code>, or <code>"none"</code>.</p></dd>


</dl></div>
    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>
    <p><strong>Algorithm Overview</strong></p>
<p>The Local Density Binning (LDB) algorithm operates in four sequential phases:</p>
<p><strong>Phase 1: Density-Based Pre-binning</strong></p>
<p>The algorithm employs kernel density estimation (KDE) with a Gaussian kernel
to identify the local density structure of the feature:</p>
<p>$$\hat{f}(x) = \frac{1}{nh\sqrt{2\pi}} \sum_{i=1}^{n} \exp\left[-\frac{(x - x_i)^2}{2h^2}\right]$$</p>
<p>where \(h\) is the bandwidth computed via Silverman's rule of thumb:</p>
<p>$$h = 0.9 \times \min(\hat{\sigma}, \text{IQR}/1.34) \times n^{-1/5}$$</p>
<p>Bin boundaries are placed at local minima of \(\hat{f}(x)\), which correspond
to natural transition regions where density is lowest (analogous to valleys in
the density landscape). This strategy ensures bins capture homogeneous subpopulations.</p>
<p><strong>Phase 2: Weight of Evidence Computation</strong></p>
<p>For each bin \(i\), the WoE quantifies the log-ratio of positive to negative
class distributions, adjusted with Laplace smoothing (\(\alpha = 0.5\)) to
prevent division by zero:</p>
<p>$$\text{WoE}_i = \ln\left(\frac{\text{DistGood}_i}{\text{DistBad}_i}\right)$$</p>
<p>where:</p>
<p>$$\text{DistGood}_i = \frac{n_{i}^{+} + \alpha}{n^{+} + K\alpha}, \quad \text{DistBad}_i = \frac{n_{i}^{-} + \alpha}{n^{-} + K\alpha}$$</p>
<p>and \(K\) is the total number of bins. The Information Value for bin \(i\) is:</p>
<p>$$\text{IV}_i = (\text{DistGood}_i - \text{DistBad}_i) \times \text{WoE}_i$$</p>
<p>Total IV aggregates discriminatory power: \(\text{IV}_{\text{total}} = \sum_{i=1}^{K} \text{IV}_i\).</p>
<p><strong>Phase 3: Monotonicity Enforcement</strong></p>
<p>When <code>enforce_monotonic = TRUE</code>, the algorithm ensures WoE values are
monotonic with respect to bin order. The direction (increasing/decreasing) is
determined via Pearson correlation between bin indices and WoE values. Bins
violating monotonicity are iteratively merged using the merge strategy described
in Phase 4, continuing until global monotonicity is achieved or <code>min_bins</code>
is reached.</p>
<p>This approach is rooted in isotonic regression principles (Robertson et al., 1988),
ensuring the scorecard maintains a consistent logical relationship between
feature values and credit risk.</p>
<p><strong>Phase 4: Adaptive Bin Merging</strong></p>
<p>Two merging criteria are applied sequentially:</p>
<ol><li><p><strong>Frequency-based merging</strong>: Bins with total count below
    <code>bin_cutoff</code> \(\times n\) are merged with the adjacent bin having
    the most similar event rate (minimizing heterogeneity). If event rates are
    equivalent, the merge that preserves higher IV is preferred.</p></li>
<li><p><strong>Cardinality reduction</strong>: If the number of bins exceeds <code>max_bins</code>,
    the pair of adjacent bins minimizing IV loss when merged is identified via:
    $$\Delta \text{IV}_{i,i+1} = \text{IV}_i + \text{IV}_{i+1} - \text{IV}_{\text{merged}}$$
    This greedy optimization continues until \(K \le\) <code>max_bins</code>.</p></li>
</ol><p><strong>Theoretical Foundations</strong></p>
<ul><li><p><strong>Kernel Density Estimation</strong>: The bandwidth selection follows
    Silverman (1986, Chapter 3), balancing bias-variance tradeoff for univariate
    density estimation.</p></li>
<li><p><strong>Weight of Evidence</strong>: Siddiqi (2006) formalizes WoE/IV as measures
    of predictive strength in credit scoring, with IV thresholds: \(&lt; 0.02\)
    (unpredictive), 0.02-0.1 (weak), 0.1-0.3 (medium), 0.3-0.5 (strong), \(&gt; 0.5\)
    (suspect overfitting).</p></li>
<li><p><strong>Supervised Discretization</strong>: García et al. (2013) categorize LDB
    within "static" supervised methods that do not require iterative feedback
    from the model, unlike dynamic methods (e.g., ChiMerge).</p></li>
</ul><p><strong>Computational Complexity</strong></p>
<ul><li><p>KDE computation: \(O(n^2)\) for naive implementation (each of \(n\)
    points evaluates \(n\) kernel terms).</p></li>
<li><p>Binary search for bin assignment: \(O(n \log K)\) where \(K\) is
    the number of bins.</p></li>
<li><p>Merge iterations: \(O(K^2 \times \text{max\_iterations})\) in worst case.</p></li>
</ul><p>For large datasets (\(n &gt; 10^5\)), the KDE phase dominates runtime.</p>
    </div>
    <div class="section level2">
    <h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a></h2>

<ul><li><p>Silverman, B. W. (1986). <em>Density Estimation for Statistics and
    Data Analysis</em>. Chapman and Hall/CRC.</p></li>
<li><p>Siddiqi, N. (2006). <em>Credit Risk Scorecards: Developing and
    Implementing Intelligent Credit Scoring</em>. Wiley.</p></li>
<li><p>Dougherty, J., Kohavi, R., &amp; Sahami, M. (1995). "Supervised and
    Unsupervised Discretization of Continuous Features". <em>Proceedings of
    the 12th International Conference on Machine Learning</em>, pp. 194-202.</p></li>
<li><p>Robertson, T., Wright, F. T., &amp; Dykstra, R. L. (1988). <em>Order
    Restricted Statistical Inference</em>. Wiley.</p></li>
<li><p>García, S., Luengo, J., Sáez, J. A., López, V., &amp; Herrera, F. (2013).
    "A Survey of Discretization Techniques: Taxonomy and Empirical Analysis in
    Supervised Learning". <em>IEEE Transactions on Knowledge and Data Engineering</em>,
    25(4), 734-750.</p></li>
</ul></div>
    <div class="section level2">
    <h2 id="see-also">See also<a class="anchor" aria-label="anchor" href="#see-also"></a></h2>
    <div class="dont-index"><p><code><a href="ob_numerical_mdlp.html">ob_numerical_mdlp</a></code> for Minimum Description Length Principle binning,
<code><a href="ob_numerical_mob.html">ob_numerical_mob</a></code> for monotonic binning with similar constraints.</p></div>
    </div>
    <div class="section level2">
    <h2 id="author">Author<a class="anchor" aria-label="anchor" href="#author"></a></h2>
    <p>Lopes, J. E. (implemented algorithm)</p>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="kw">if</span> <span class="op">(</span><span class="cn">FALSE</span><span class="op">)</span> <span class="op">{</span> <span class="co"># \dontrun{</span></span></span>
<span class="r-in"><span><span class="co"># Simulate credit scoring data</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">42</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">10000</span></span></span>
<span class="r-in"><span><span class="va">feature</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span></span></span>
<span class="r-in"><span>  <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">3000</span>, mean <span class="op">=</span> <span class="fl">600</span>, sd <span class="op">=</span> <span class="fl">50</span><span class="op">)</span>, <span class="co"># Low-risk segment</span></span></span>
<span class="r-in"><span>  <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">4000</span>, mean <span class="op">=</span> <span class="fl">700</span>, sd <span class="op">=</span> <span class="fl">40</span><span class="op">)</span>, <span class="co"># Medium-risk segment</span></span></span>
<span class="r-in"><span>  <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">3000</span>, mean <span class="op">=</span> <span class="fl">750</span>, sd <span class="op">=</span> <span class="fl">30</span><span class="op">)</span> <span class="co"># High-risk segment</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">target</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span></span></span>
<span class="r-in"><span>  <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html" class="external-link">rbinom</a></span><span class="op">(</span><span class="fl">3000</span>, <span class="fl">1</span>, <span class="fl">0.15</span><span class="op">)</span>, <span class="co"># 15% default rate</span></span></span>
<span class="r-in"><span>  <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html" class="external-link">rbinom</a></span><span class="op">(</span><span class="fl">4000</span>, <span class="fl">1</span>, <span class="fl">0.08</span><span class="op">)</span>, <span class="co"># 8% default rate</span></span></span>
<span class="r-in"><span>  <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html" class="external-link">rbinom</a></span><span class="op">(</span><span class="fl">3000</span>, <span class="fl">1</span>, <span class="fl">0.03</span><span class="op">)</span> <span class="co"># 3% default rate</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Apply LDB with monotonicity enforcement</span></span></span>
<span class="r-in"><span><span class="va">result</span> <span class="op">&lt;-</span> <span class="fu">ob_numerical_ldb</span><span class="op">(</span></span></span>
<span class="r-in"><span>  feature <span class="op">=</span> <span class="va">feature</span>,</span></span>
<span class="r-in"><span>  target <span class="op">=</span> <span class="va">target</span>,</span></span>
<span class="r-in"><span>  min_bins <span class="op">=</span> <span class="fl">3</span>,</span></span>
<span class="r-in"><span>  max_bins <span class="op">=</span> <span class="fl">5</span>,</span></span>
<span class="r-in"><span>  bin_cutoff <span class="op">=</span> <span class="fl">0.05</span>,</span></span>
<span class="r-in"><span>  max_n_prebins <span class="op">=</span> <span class="fl">20</span>,</span></span>
<span class="r-in"><span>  enforce_monotonic <span class="op">=</span> <span class="cn">TRUE</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Inspect binning quality</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">result</span><span class="op">$</span><span class="va">total_iv</span><span class="op">)</span> <span class="co"># Should be &gt; 0.1 for predictive features</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">result</span><span class="op">$</span><span class="va">monotonicity</span><span class="op">)</span> <span class="co"># Should indicate direction</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Visualize WoE pattern</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">result</span><span class="op">$</span><span class="va">woe</span>,</span></span>
<span class="r-in"><span>  type <span class="op">=</span> <span class="st">"b"</span>, xlab <span class="op">=</span> <span class="st">"Bin"</span>, ylab <span class="op">=</span> <span class="st">"WoE"</span>,</span></span>
<span class="r-in"><span>  main <span class="op">=</span> <span class="st">"Monotonic WoE Trend"</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Generate scorecard transformation</span></span></span>
<span class="r-in"><span><span class="va">bin_mapping</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span></span></span>
<span class="r-in"><span>  bin <span class="op">=</span> <span class="va">result</span><span class="op">$</span><span class="va">bin</span>,</span></span>
<span class="r-in"><span>  woe <span class="op">=</span> <span class="va">result</span><span class="op">$</span><span class="va">woe</span>,</span></span>
<span class="r-in"><span>  iv <span class="op">=</span> <span class="va">result</span><span class="op">$</span><span class="va">iv</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">bin_mapping</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">}</span> <span class="co"># }</span></span></span>
<span class="r-in"><span></span></span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by José Evandeilton Lopes.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

    </footer></div>





  </body></html>


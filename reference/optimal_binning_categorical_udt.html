<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Optimal Binning for Categorical Variables using a User-Defined Technique (UDT) — optimal_binning_categorical_udt • OptimalBinningWoE</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Optimal Binning for Categorical Variables using a User-Defined Technique (UDT) — optimal_binning_categorical_udt"><meta name="description" content="This function performs binning for categorical variables using a user-defined technique (UDT).
The algorithm creates bins with optimal predictive power (measured by Information Value)
while maintaining monotonicity of Weight of Evidence and avoiding the creation of artificial categories.
Enhanced with statistical robustness features like Laplace smoothing and Jensen-Shannon divergence."><meta property="og:description" content="This function performs binning for categorical variables using a user-defined technique (UDT).
The algorithm creates bins with optimal predictive power (measured by Information Value)
while maintaining monotonicity of Weight of Evidence and avoiding the creation of artificial categories.
Enhanced with statistical robustness features like Laplace smoothing and Jensen-Shannon divergence."></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">OptimalBinningWoE</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.3.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Optimal Binning for Categorical Variables using a User-Defined Technique (UDT)</h1>

      <div class="d-none name"><code>optimal_binning_categorical_udt.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>This function performs binning for categorical variables using a user-defined technique (UDT).
The algorithm creates bins with optimal predictive power (measured by Information Value)
while maintaining monotonicity of Weight of Evidence and avoiding the creation of artificial categories.
Enhanced with statistical robustness features like Laplace smoothing and Jensen-Shannon divergence.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">optimal_binning_categorical_udt</span><span class="op">(</span></span>
<span>  <span class="va">target</span>,</span>
<span>  <span class="va">feature</span>,</span>
<span>  min_bins <span class="op">=</span> <span class="fl">3L</span>,</span>
<span>  max_bins <span class="op">=</span> <span class="fl">5L</span>,</span>
<span>  bin_cutoff <span class="op">=</span> <span class="fl">0.05</span>,</span>
<span>  max_n_prebins <span class="op">=</span> <span class="fl">20L</span>,</span>
<span>  bin_separator <span class="op">=</span> <span class="st">"%;%"</span>,</span>
<span>  convergence_threshold <span class="op">=</span> <span class="fl">1e-06</span>,</span>
<span>  max_iterations <span class="op">=</span> <span class="fl">1000L</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-target">target<a class="anchor" aria-label="anchor" href="#arg-target"></a></dt>
<dd><p>Integer binary vector (0 or 1) representing the response variable.</p></dd>


<dt id="arg-feature">feature<a class="anchor" aria-label="anchor" href="#arg-feature"></a></dt>
<dd><p>Character vector representing the categories of the explanatory variable.</p></dd>


<dt id="arg-min-bins">min_bins<a class="anchor" aria-label="anchor" href="#arg-min-bins"></a></dt>
<dd><p>Minimum number of desired bins (default: 3).</p></dd>


<dt id="arg-max-bins">max_bins<a class="anchor" aria-label="anchor" href="#arg-max-bins"></a></dt>
<dd><p>Maximum number of desired bins (default: 5).</p></dd>


<dt id="arg-bin-cutoff">bin_cutoff<a class="anchor" aria-label="anchor" href="#arg-bin-cutoff"></a></dt>
<dd><p>Minimum proportion of observations to consider a category as a separate bin (default: 0.05).</p></dd>


<dt id="arg-max-n-prebins">max_n_prebins<a class="anchor" aria-label="anchor" href="#arg-max-n-prebins"></a></dt>
<dd><p>Maximum number of pre-bins before the main binning step (default: 20).</p></dd>


<dt id="arg-bin-separator">bin_separator<a class="anchor" aria-label="anchor" href="#arg-bin-separator"></a></dt>
<dd><p>String used to separate names of categories grouped in the same bin (default: "%;%").</p></dd>


<dt id="arg-convergence-threshold">convergence_threshold<a class="anchor" aria-label="anchor" href="#arg-convergence-threshold"></a></dt>
<dd><p>Threshold for stopping criteria based on IV convergence (default: 1e-6).</p></dd>


<dt id="arg-max-iterations">max_iterations<a class="anchor" aria-label="anchor" href="#arg-max-iterations"></a></dt>
<dd><p>Maximum number of iterations in the optimization process (default: 1000).</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p>A list containing:</p><ul><li><p>id: Numeric identifiers for each bin.</p></li>
<li><p>bin: String vector with bin names representing grouped categories.</p></li>
<li><p>woe: Numeric vector with Weight of Evidence values for each bin.</p></li>
<li><p>iv: Numeric vector with Information Value for each bin.</p></li>
<li><p>count: Integer vector with the total count of observations in each bin.</p></li>
<li><p>count_pos: Integer vector with the count of positive cases (target=1) in each bin.</p></li>
<li><p>count_neg: Integer vector with the count of negative cases (target=0) in each bin.</p></li>
<li><p>event_rate: Numeric vector with the proportion of positive cases in each bin.</p></li>
<li><p>converged: Logical value indicating if the algorithm converged.</p></li>
<li><p>iterations: Integer value indicating the number of optimization iterations executed.</p></li>
<li><p>total_iv: The total Information Value of the binning solution.</p></li>
</ul></div>
    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>

<div class="section">
<h3 id="statistical-methodology">Statistical Methodology<a class="anchor" aria-label="anchor" href="#statistical-methodology"></a></h3>


<p>The UDT algorithm optimizes binning based on statistical concepts of Weight of Evidence
and Information Value with Laplace smoothing for robustness:</p>
<p>Weight of Evidence measures the predictive power of a bin:
$$WoE_i = \ln\left(\frac{(n_{i+} + \alpha)/(n_+ + 2\alpha)}{(n_{i-} + \alpha)/(n_- + 2\alpha)}\right)$$</p>
<p>Where:</p><ul><li><p>\(n_{i+}\) is the number of positive cases (target=1) in bin i</p></li>
<li><p>\(n_{i-}\) is the number of negative cases (target=0) in bin i</p></li>
<li><p>\(n_+\) is the total number of positive cases</p></li>
<li><p>\(n_-\) is the total number of negative cases</p></li>
<li><p>\(\alpha\) is the Laplace smoothing parameter (default: 0.5)</p></li>
</ul><p>Information Value measures the overall predictive power:
$$IV_i = \left(\frac{n_{i+}}{n_+} - \frac{n_{i-}}{n_-}\right) \times WoE_i$$
$$IV_{total} = \sum_{i=1}^{k} |IV_i|$$</p>
</div>

<div class="section">
<h3 id="algorithm-steps">Algorithm Steps<a class="anchor" aria-label="anchor" href="#algorithm-steps"></a></h3>

<ol><li><p>Input validation and creation of initial bins (one bin per unique category)</p><ul><li><p>Special handling for variables with 1-2 unique levels</p></li>
</ul></li>
<li><p>Merge low-frequency categories below the bin_cutoff threshold</p></li>
<li><p>Calculate WoE and IV for each bin using Laplace smoothing</p></li>
<li><p>Iteratively merge similar bins based on Jensen-Shannon divergence until constraints are satisfied</p></li>
<li><p>Ensure WoE monotonicity across bins for better interpretability</p></li>
<li><p>The process continues until convergence or max_iterations is reached</p></li>
</ol><p>The algorithm uses Jensen-Shannon divergence to measure statistical similarity between bins:
$$JS(P||Q) = \frac{1}{2}KL(P||M) + \frac{1}{2}KL(Q||M)$$</p>
<p>Where:</p><ul><li><p>\(KL\) is the Kullback-Leibler divergence</p></li>
<li><p>\(M = \frac{1}{2}(P+Q)\) is the midpoint distribution</p></li>
<li><p>\(P\) and \(Q\) are the event rate distributions of two bins</p></li>
</ul></div>

<div class="section">
<h3 id="important-notes">Important Notes<a class="anchor" aria-label="anchor" href="#important-notes"></a></h3>

<ul><li><p>Missing values in the feature are handled as a special category</p></li>
<li><p>The algorithm naturally handles sparse data through Laplace smoothing</p></li>
<li><p>No splitting is performed to avoid creating artificial category names</p></li>
<li><p>Uniqueness of categories within bins is guaranteed</p></li>
</ul></div>

    </div>
    <div class="section level2">
    <h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a></h2>

<ul><li><p>Beltrán, C., et al. (2022). Weight of Evidence (WoE) and Information Value (IV): A novel implementation for predictive modeling in credit scoring. Expert Systems with Applications, 183, 115351.</p></li>
<li><p>Lin, J. (1991). Divergence measures based on the Shannon entropy. IEEE Transactions on Information Theory, 37(1), 145-151.</p></li>
</ul></div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="kw">if</span> <span class="op">(</span><span class="cn">FALSE</span><span class="op">)</span> <span class="op">{</span> <span class="co"># \dontrun{</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">target</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fl">0</span><span class="op">:</span><span class="fl">1</span>, <span class="fl">1000</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">feature</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="va">LETTERS</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span><span class="op">]</span>, <span class="fl">1000</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">result</span> <span class="op">&lt;-</span> <span class="fu">optimal_binning_categorical_udt</span><span class="op">(</span><span class="va">target</span>, <span class="va">feature</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">result</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">}</span> <span class="co"># }</span></span></span>
<span class="r-in"><span></span></span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Lopes J. E.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer></div>





  </body></html>


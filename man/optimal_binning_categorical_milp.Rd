% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RcppExports.R
\name{optimal_binning_categorical_milp}
\alias{optimal_binning_categorical_milp}
\title{Optimal Binning for Categorical Variables using MILP}
\usage{
optimal_binning_categorical_milp(
  target,
  feature,
  min_bins = 3L,
  max_bins = 5L,
  bin_cutoff = 0.05,
  max_n_prebins = 20L
)
}
\arguments{
\item{target}{An integer vector of binary target values (0 or 1).}

\item{feature}{A character vector of feature values.}

\item{min_bins}{Minimum number of bins (default: 3).}

\item{max_bins}{Maximum number of bins (default: 5).}

\item{bin_cutoff}{Minimum proportion of total observations for a bin to avoid being merged (default: 0.05).}

\item{max_n_prebins}{Maximum number of pre-bins before the optimization process (default: 20).}
}
\value{
A list containing two elements:
\item{woefeature}{A numeric vector of Weight of Evidence (WoE) values for each observation.}
\item{woebin}{A data frame with the following columns:
\itemize{
\item bin: Character vector of bin categories.
\item woe: Numeric vector of WoE values for each bin.
\item iv: Numeric vector of Information Value (IV) for each bin.
\item count: Integer vector of total observations in each bin.
\item count_pos: Integer vector of positive target observations in each bin.
\item count_neg: Integer vector of negative target observations in each bin.
}
}
}
\description{
This function performs optimal binning for categorical variables using a Mixed Integer Linear Programming (MILP) inspired approach. It creates optimal bins for a categorical feature based on its relationship with a binary target variable, maximizing the predictive power while respecting user-defined constraints.
}
\details{
The Optimal Binning algorithm for categorical variables using a MILP-inspired approach works as follows:
\enumerate{
\item Create initial bins for each unique category.
\item Merge bins with counts below the cutoff.
\item Calculate initial Weight of Evidence (WoE) and Information Value (IV) for each bin.
\item Optimize bins by merging categories to maximize total IV while respecting constraints.
\item Ensure the number of bins is between min_bins and max_bins.
\item Recalculate WoE and IV for the final bins.
}

The algorithm aims to create bins that maximize the predictive power of the categorical variable while adhering to the specified constraints.

Weight of Evidence (WoE) is calculated as:
\deqn{WoE = \ln(\frac{\text{Positive Rate}}{\text{Negative Rate}})}

Information Value (IV) is calculated as:
\deqn{IV = (\text{Positive Rate} - \text{Negative Rate}) \times WoE}
}
\examples{
\dontrun{
# Create sample data
set.seed(123)
n <- 1000
target <- sample(0:1, n, replace = TRUE)
feature <- sample(LETTERS[1:10], n, replace = TRUE)

# Run optimal binning
result <- optimal_binning_categorical_milp(target, feature, min_bins = 2, max_bins = 4)

# Print results
print(result$woebin)

# Plot WoE values
barplot(result$woebin$woe, names.arg = result$woebin$bin,
        xlab = "Bins", ylab = "WoE", main = "Weight of Evidence by Bin")
}

}
\references{
\itemize{
\item Belotti, P., Kirches, C., Leyffer, S., Linderoth, J., Luedtke, J., & Mahajan, A. (2013). Mixed-integer nonlinear optimization. Acta Numerica, 22, 1-131.
\item Mironchyk, P., & Tchistiakov, V. (2017). Monotone optimal binning algorithm for credit risk modeling. SSRN Electronic Journal. doi:10.2139/ssrn.2978774
}
}
\author{
Lopes, J. E.
}

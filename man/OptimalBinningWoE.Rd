% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/OptimalBinningR.R
\name{OptimalBinningWoE}
\alias{OptimalBinningWoE}
\title{Optimal Binning and Weight of Evidence Calculation}
\usage{
OptimalBinningWoE(
  dt,
  target,
  feature = NULL,
  method = "auto",
  preprocess = TRUE,
  min_bins = 3,
  max_bins = 4,
  control = list(),
  positive = "bad|1"
)
}
\arguments{
\item{dt}{A data.table containing the dataset.}

\item{target}{The name of the target variable (must be binary).}

\item{feature}{Optional. Name of a specific feature to process. If NULL, all features except the target will be processed.}

\item{method}{The binning method to use. Can be "auto" or a specific method name. See Details for more information.}

\item{preprocess}{Logical. Whether to preprocess the data before binning.}

\item{min_bins}{Minimum number of bins.}

\item{max_bins}{Maximum number of bins.}

\item{control}{A list of additional control parameters. See Details for more information.}

\item{positive}{Character string specifying which category should be considered as positive. Must be either "bad|1" or "good|1".}
}
\value{
A list containing:
\itemize{
\item woe_feature: The original dataset with added WoE columns
\item woe_woebins: Information about the bins created
\item prep_report: Preprocessing report for each feature
}
}
\description{
This function performs optimal binning and calculates Weight of Evidence (WoE) for multiple features.
It supports automatic method selection and data preprocessing.
}
\details{
Supported Algorithms:
The function supports the following binning algorithms:
\itemize{
\item CAIM (Class-Attribute Interdependence Maximization)
\item ChiMerge
\item MDLP (Minimum Description Length Principle)
\item MIP (Minimum Information Pure)
\item MOB (Monotone Optimal Binning)
\item IV (Information Value)
\item PAVA (Pool Adjacent Violators Algorithm)
\item Tree-based binning
}

Each algorithm has its own strengths and may perform differently depending on the nature of the data.
The automatic method selection option tests applicable algorithms and chooses the one that produces the highest Information Value.

When specifying a method, use the short name (e.g., "caim", "chimerge") rather than the full algorithm name.

Control Parameters:
The control list can include the following parameters:
\itemize{
\item min_bads: Minimum proportion of "bad" cases in each bin (default: 0.05)
\item pvalue_threshold: P-value threshold for statistical tests (default: 0.05)
\item max_n_prebins: Maximum number of pre-bins before optimization (default: 20)
\item monotonicity_direction: Direction of monotonicity ("increase" or "decrease") (default: "increase")
\item lambda: Regularization parameter for tree-based methods (default: 0.1)
\item min_bin_size: Minimum proportion of cases in each bin (default: 0.05)
\item min_iv_gain: Minimum IV gain for creating a new split (default: 0.01)
\item max_depth: Maximum depth for tree-based methods (default: 10)
\item num_miss_value: Value to represent missing numeric values (default: -999.0)
\item char_miss_value: Value to represent missing categorical values (default: "N/A")
\item outlier_method: Method for outlier detection ("iqr", "zscore", or "grubbs") (default: "iqr")
\item outlier_process: Whether to process outliers (default: FALSE)
\item iqr_k: Factor for IQR method (default: 1.5)
\item zscore_threshold: Threshold for Z-score method (default: 3)
\item grubbs_alpha: Significance level for Grubbs' test (default: 0.05)
}
}
\examples{
\dontrun{
# Load necessary libraries
library(data.table)

# Create a sample dataset
dt <- data.table(
  target = sample(0:1, 1000, replace = TRUE),
  num_feat = rnorm(1000),
  cat_feat = sample(letters[1:5], 1000, replace = TRUE)
)

# Run OptimalBinningWoE with automatic method selection
result <- OptimalBinningWoE(dt, target = "target", method = "auto")

# Check the results
head(result$woe_feature)
head(result$woe_woebins)
head(result$prep_report)
}

}

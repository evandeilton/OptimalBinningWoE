% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RcppExports.R
\name{optimal_binning_numerical_mdlp}
\alias{optimal_binning_numerical_mdlp}
\title{Optimal Binning for Numerical Variables using MDLP}
\usage{
optimal_binning_numerical_mdlp(
  target,
  feature,
  min_bins = 3L,
  max_bins = 5L,
  bin_cutoff = 0.05,
  max_n_prebins = 20L
)
}
\arguments{
\item{target}{An integer vector of binary target values (0 or 1).}

\item{feature}{A numeric vector of feature values.}

\item{min_bins}{Minimum number of bins (default: 3).}

\item{max_bins}{Maximum number of bins (default: 5).}

\item{bin_cutoff}{Minimum proportion of total observations for a bin to avoid being merged (default: 0.05).}

\item{max_n_prebins}{Maximum number of pre-bins before the optimization process (default: 20).}
}
\value{
A list containing two elements:
\item{woefeature}{A numeric vector of Weight of Evidence (WoE) values for each observation.}
\item{woebin}{A data frame with the following columns:
\itemize{
\item bin: Character vector of bin ranges.
\item woe: Numeric vector of WoE values for each bin.
\item iv: Numeric vector of Information Value (IV) for each bin.
\item count: Integer vector of total observations in each bin.
\item count_pos: Integer vector of positive target observations in each bin.
\item count_neg: Integer vector of negative target observations in each bin.
}
}
}
\description{
This function performs optimal binning for numerical variables using the Minimum Description Length Principle (MDLP). It creates optimal bins for a numerical feature based on its relationship with a binary target variable, maximizing the predictive power while respecting user-defined constraints.
}
\details{
The Optimal Binning algorithm for numerical variables using MDLP works as follows:
\enumerate{
\item Create initial bins using equal-frequency binning.
\item Apply the MDLP algorithm to merge bins:
\itemize{
\item Calculate the current MDL cost.
\item For each pair of adjacent bins, calculate the MDL cost if merged.
\item Merge the pair with the lowest MDL cost.
\item Repeat until no further merging reduces the MDL cost or the minimum number of bins is reached.
}
\item Merge rare bins (those with a proportion less than bin_cutoff).
\item Calculate Weight of Evidence (WoE) and Information Value (IV) for each bin:
\deqn{WoE = \ln\left(\frac{\text{Positive Rate}}{\text{Negative Rate}}\right)}
\deqn{IV = (\text{Positive Rate} - \text{Negative Rate}) \times WoE}
}

The MDLP algorithm aims to find the optimal trade-off between model complexity (number of bins) and goodness of fit. It uses the principle of minimum description length, which states that the best model is the one that provides the shortest description of the data.

The MDL cost is calculated as:
\deqn{MDL = \log_2(k - 1) + n \times H(S) - \sum_{i=1}^k n_i \times H(S_i)}
where k is the number of bins, n is the total number of instances, H(S) is the entropy of the entire dataset, and H(S_i) is the entropy of the i-th bin.

This implementation uses OpenMP for parallel processing when available, which can significantly speed up the computation for large datasets.
}
\examples{
\dontrun{
# Create sample data
set.seed(123)
n <- 1000
target <- sample(0:1, n, replace = TRUE)
feature <- rnorm(n)

# Run optimal binning
result <- optimal_binning_numerical_mdlp(target, feature, min_bins = 2, max_bins = 4)

# Print results
print(result$woebin)

# Plot WoE values
plot(result$woebin$woe, type = "s", xaxt = "n", xlab = "Bins", ylab = "WoE",
     main = "Weight of Evidence by Bin")
axis(1, at = 1:nrow(result$woebin), labels = result$woebin$bin)
}

}
\references{
\itemize{
\item Fayyad, U. M., & Irani, K. B. (1993). Multi-interval discretization of continuous-valued attributes for classification learning. In Proceedings of the 13th International Joint Conference on Artificial Intelligence (pp. 1022-1027).
\item Rissanen, J. (1978). Modeling by shortest data description. Automatica, 14(5), 465-471.
}
}
\author{
Lopes, J. E.
}

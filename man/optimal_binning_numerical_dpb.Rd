% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RcppExports.R
\name{optimal_binning_numerical_dpb}
\alias{optimal_binning_numerical_dpb}
\title{Optimal Binning for Numerical Variables using Dynamic Programming}
\usage{
optimal_binning_numerical_dpb(
  target,
  feature,
  min_bins = 3L,
  max_bins = 5L,
  bin_cutoff = 0.05,
  max_n_prebins = 20L,
  n_threads = 1L
)
}
\arguments{
\item{target}{An integer vector of binary target values (0 or 1).}

\item{feature}{A numeric vector of feature values to be binned.}

\item{min_bins}{Minimum number of bins (default: 3).}

\item{max_bins}{Maximum number of bins (default: 5).}

\item{bin_cutoff}{Minimum frequency of observations in each bin (default: 0.05).}

\item{max_n_prebins}{Maximum number of pre-bins for initial quantile-based discretization (default: 20).}

\item{n_threads}{Number of threads for parallel processing (default: 1).}
}
\value{
A list containing two elements:
\item{woefeature}{A numeric vector of WoE-transformed feature values.}
\item{woebin}{A data frame with binning details, including bin boundaries, WoE, IV, and count statistics.}
}
\description{
This function implements an optimal binning algorithm for numerical variables using Dynamic Programming with Weight of Evidence (WoE) and Information Value (IV) criteria.
}
\details{
The optimal binning algorithm for numerical variables uses Dynamic Programming to find the optimal binning solution that maximizes the total Information Value (IV) while respecting constraints on the number of bins and minimum bin frequency.

The algorithm follows these steps:
\enumerate{
\item Initial discretization using quantile-based binning
\item Dynamic programming to find optimal bins
\item Enforcement of monotonicity in WoE across bins
\item Calculation of final WoE and IV for each bin
\item Application of WoE transformation to the original feature
}

Weight of Evidence (WoE) is calculated for each bin as:

\deqn{WoE_i = \ln\left(\frac{P(X_i|Y=1)}{P(X_i|Y=0)}\right)}

where \eqn{P(X_i|Y=1)} is the proportion of positive cases in bin i, and \eqn{P(X_i|Y=0)} is the proportion of negative cases in bin i.

Information Value (IV) for each bin is calculated as:

\deqn{IV_i = (P(X_i|Y=1) - P(X_i|Y=0)) * WoE_i}

The total IV for the feature is the sum of IVs across all bins:

\deqn{IV_{total} = \sum_{i=1}^{n} IV_i}

The Dynamic Programming approach ensures that the resulting binning maximizes the total IV while respecting the constraints on the number of bins and minimum bin frequency.
}
\examples{
\dontrun{
# Generate sample data
set.seed(123)
n <- 10000
feature <- rnorm(n)
target <- rbinom(n, 1, plogis(0.5 * feature))

# Apply optimal binning
result <- optimal_binning_numerical_dpb(target, feature, min_bins = 3, max_bins = 5)

# View binning results
print(result$woebin)

# Plot WoE transformation
plot(feature, result$woefeature, main = "WoE Transformation",
     xlab = "Original Feature", ylab = "WoE")
}

}
\references{
\itemize{
\item Wilks, S. S. (1938). The Large-Sample Distribution of the Likelihood Ratio for Testing Composite Hypotheses. The Annals of Mathematical Statistics, 9(1), 60-62.
\item Bellman, R. (1954). The theory of dynamic programming. Bulletin of the American Mathematical Society, 60(6), 503-515.
}
}
\author{
Lopes, J. E.
}

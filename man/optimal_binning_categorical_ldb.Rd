% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RcppExports.R
\name{optimal_binning_categorical_ldb}
\alias{optimal_binning_categorical_ldb}
\title{Categorical Optimal Binning with Local Distance-Based Algorithm}
\usage{
optimal_binning_categorical_ldb(
  target,
  feature,
  min_bins = 3L,
  max_bins = 5L,
  bin_cutoff = 0.05,
  max_n_prebins = 20L,
  bin_separator = "\%;\%",
  convergence_threshold = 1e-06,
  max_iterations = 1000L
)
}
\arguments{
\item{target}{An integer vector of binary target values (0 or 1).}

\item{feature}{A character vector of categorical feature values.}

\item{min_bins}{Minimum number of bins to create (default: 3).}

\item{max_bins}{Maximum number of bins to create (default: 5).}

\item{bin_cutoff}{Minimum frequency for a category to be considered as a separate bin (default: 0.05).}

\item{max_n_prebins}{Maximum number of pre-bins before merging (default: 20).}

\item{bin_separator}{Separator used when merging category names (default: "\%;\%").}

\item{convergence_threshold}{Threshold for considering WoE values equal (default: 1e-6).}

\item{max_iterations}{Maximum number of iterations for the binning process (default: 1000).}
}
\value{
A list containing the following elements:
\itemize{
\item bins: A character vector of bin names.
\item woe: A numeric vector of Weight of Evidence (WoE) values for each bin.
\item iv: A numeric vector of Information Value (IV) for each bin.
\item count: An integer vector of total count for each bin.
\item count_pos: An integer vector of positive class count for each bin.
\item count_neg: An integer vector of negative class count for each bin.
\item converged: A logical value indicating whether the algorithm converged.
\item iterations: An integer indicating the number of iterations performed.
}
}
\description{
This function performs optimal binning for categorical variables using a Local Distance-Based (LDB) algorithm,
which merges categories based on their Weight of Evidence (WoE) similarity and Information Value (IV) loss.
}
\details{
The LDB algorithm works as follows:
\enumerate{
\item Compute initial statistics for each category.
\item Handle rare categories by merging them with the most similar (in terms of WoE) non-rare category.
\item Limit the number of pre-bins to max_n_prebins.
\item Iteratively merge bins with the lowest IV loss until the desired number of bins is reached or monotonicity is achieved.
\item Ensure monotonicity of WoE across bins.
}

Weight of Evidence (WoE) for each bin is calculated as:

\deqn{WoE = \ln\left(\frac{P(X|Y=1)}{P(X|Y=0)}\right)}

Information Value (IV) for each bin is calculated as:

\deqn{IV = (P(X|Y=1) - P(X|Y=0)) \times WoE}
}
\examples{
\dontrun{
# Sample data
target <- c(1, 0, 1, 1, 0, 1, 0, 0, 1, 1)
feature <- c("A", "B", "A", "C", "B", "D", "C", "A", "D", "B")

# Run optimal binning
result <- optimal_binning_categorical_ldb(target, feature, min_bins = 2, max_bins = 4)

# View results
print(result)
}

}

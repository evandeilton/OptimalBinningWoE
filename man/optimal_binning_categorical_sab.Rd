% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RcppExports.R
\name{optimal_binning_categorical_sab}
\alias{optimal_binning_categorical_sab}
\title{Optimal Binning for Categorical Variables using Simulated Annealing}
\usage{
optimal_binning_categorical_sab(
  target,
  feature,
  min_bins = 3L,
  max_bins = 5L,
  bin_cutoff = 0.05,
  max_n_prebins = 20L,
  initial_temperature = 1,
  cooling_rate = 0.995,
  max_iterations = 1000L
)
}
\arguments{
\item{target}{An integer vector of binary target values (0 or 1).}

\item{feature}{A character vector of categorical feature values.}

\item{min_bins}{Minimum number of bins (default: 3).}

\item{max_bins}{Maximum number of bins (default: 5).}

\item{bin_cutoff}{Minimum proportion of observations in a bin (default: 0.05).}

\item{max_n_prebins}{Maximum number of pre-bins (default: 20).}

\item{initial_temperature}{Initial temperature for Simulated Annealing (default: 1.0).}

\item{cooling_rate}{Cooling rate for Simulated Annealing (default: 0.995).}

\item{max_iterations}{Maximum number of iterations for Simulated Annealing (default: 1000).}
}
\value{
A list containing three elements:
\itemize{
\item woefeature: A numeric vector of Weight of Evidence (WoE) values for each observation
\item woebin: A data frame containing binning information, including bin names, WoE, Information Value (IV), and counts
\item total_iv: The total Information Value for the binning solution
}
}
\description{
This function performs optimal binning for categorical variables using a Simulated Annealing approach.
It maximizes the Information Value (IV) while maintaining monotonicity in the bins.
}
\details{
The algorithm uses Simulated Annealing to find an optimal binning solution that maximizes
the Information Value while maintaining monotonicity. It respects the specified constraints
on the number of bins and bin sizes.

The Weight of Evidence (WoE) is calculated as:
\deqn{WoE_i = \ln(\frac{\text{Distribution of positives}_i}{\text{Distribution of negatives}_i})}

Where:
\deqn{\text{Distribution of positives}_i = \frac{\text{Number of positives in bin } i}{\text{Total Number of positives}}}
\deqn{\text{Distribution of negatives}_i = \frac{\text{Number of negatives in bin } i}{\text{Total Number of negatives}}}

The Information Value (IV) is calculated as:
\deqn{IV = \sum_{i=1}^{N} (\text{Distribution of positives}_i - \text{Distribution of negatives}_i) \times WoE_i}

The algorithm uses OpenMP for parallel processing to improve performance on multi-core systems.
}
\examples{
\dontrun{
set.seed(123)
target <- sample(0:1, 1000, replace = TRUE)
feature <- sample(LETTERS[1:5], 1000, replace = TRUE)
result <- optimal_binning_categorical_sab(target, feature)
print(result$woebin)
print(result$total_iv)
}

}
\references{
\itemize{
\item Bertsimas, D., & Dunn, J. (2017). Optimal classification trees. Machine Learning, 106(7), 1039-1082.
\item Mironchyk, P., & Tchistiakov, V. (2017). Monotone optimal binning algorithm for credit risk modeling.
Workshop on Data Science and Advanced Analytics (DSAA).
}
}

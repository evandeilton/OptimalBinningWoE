% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RcppExports.R
\name{optimal_binning_numerical_ir}
\alias{optimal_binning_numerical_ir}
\title{Optimal Binning for Numerical Variables using Isotonic Regression}
\usage{
optimal_binning_numerical_ir(
  target,
  feature,
  min_bins = 3L,
  max_bins = 5L,
  bin_cutoff = 0.05,
  max_n_prebins = 20L
)
}
\arguments{
\item{target}{An integer vector of binary target values (0 or 1).}

\item{feature}{A numeric vector of feature values.}

\item{min_bins}{Minimum number of bins (default: 3).}

\item{max_bins}{Maximum number of bins (default: 5).}

\item{bin_cutoff}{Minimum proportion of total observations for a bin to avoid being merged (default: 0.05).}

\item{max_n_prebins}{Maximum number of pre-bins before the optimization process (default: 20).}
}
\value{
A list containing three elements:
\item{woefeature}{A numeric vector of Weight of Evidence (WoE) values for each observation.}
\item{woebin}{A data frame with the following columns:
\itemize{
\item bin: Character vector of bin ranges.
\item woe: Numeric vector of WoE values for each bin.
\item iv: Numeric vector of Information Value (IV) for each bin.
\item count: Integer vector of total observations in each bin.
\item count_pos: Integer vector of positive target observations in each bin.
\item count_neg: Integer vector of negative target observations in each bin.
\item iv_total: Total Information Value (IV) for the feature.
}
}
}
\description{
This function performs optimal binning for numerical variables using isotonic regression.
It creates optimal bins for a numerical feature based on its relationship with a binary
target variable, maximizing the predictive power while respecting user-defined constraints.
}
\details{
The Optimal Binning algorithm for numerical variables using isotonic regression works as follows:
\enumerate{
\item Create initial bins using equal-frequency binning.
\item Merge low-frequency bins (those with a proportion less than \code{bin_cutoff}).
\item Ensure the number of bins is between \code{min_bins} and \code{max_bins} by splitting or merging bins.
\item Apply isotonic regression to smooth the positive rates across bins.
\item Calculate Weight of Evidence (WoE) and Information Value (IV) for each bin.
}

Weight of Evidence (WoE) is calculated for each bin as:

\deqn{WoE_i = \ln\left(\frac{P(X_i|Y=1)}{P(X_i|Y=0)}\right)}

where \eqn{P(X_i|Y=1)} is the proportion of positive cases in bin i, and
\eqn{P(X_i|Y=0)} is the proportion of negative cases in bin i.

Information Value (IV) for each bin is calculated as:

\deqn{IV_i = (P(X_i|Y=1) - P(X_i|Y=0)) * WoE_i}

The algorithm aims to create monotonic bins that maximize the predictive power of the
numerical variable while adhering to the specified constraints. Isotonic regression ensures
that the positive rates are non-decreasing across bins, which is particularly useful for
credit scoring and risk modeling applications.

This implementation uses OpenMP for parallel processing when available, which can
significantly speed up the computation for large datasets.
}
\examples{
\dontrun{
# Create sample data
set.seed(123)
n <- 1000
target <- sample(0:1, n, replace = TRUE)
feature <- rnorm(n)
# Run optimal binning
result <- optimal_binning_numerical_ir(target, feature, min_bins = 2, max_bins = 4)
# Print results
print(result$woebin)
# Plot WoE values
plot(result$woebin$woe, type = "s", xaxt = "n", xlab = "Bins", ylab = "WoE",
     main = "Weight of Evidence by Bin")
axis(1, at = 1:nrow(result$woebin), labels = result$woebin$bin)
}

}
\references{
\itemize{
\item Barlow, R. E., Bartholomew, D. J., Bremner, J. M., & Brunk, H. D. (1972).
Statistical inference under order restrictions: The theory and application
of isotonic regression. Wiley.
\item Mironchyk, P., & Tchistiakov, V. (2017). Monotone optimal binning algorithm
for credit risk modeling. SSRN Electronic Journal. DOI: 10.2139/ssrn.2978774
}
}
\author{
Lopes, J. E.
}

% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RcppExports.R
\name{binning_categorical_cutpoints}
\alias{binning_categorical_cutpoints}
\title{Binning Categorical Variables using Custom Cutpoints}
\usage{
binning_categorical_cutpoints(feature, target, cutpoints)
}
\arguments{
\item{feature}{A character vector representing the categorical feature to be binned.}

\item{target}{An integer vector representing the binary target variable (0 or 1).}

\item{cutpoints}{A character vector containing the bin definitions, with categories separated by '+' (e.g., "A+B+C").}
}
\value{
A list with two elements:
\item{woefeature}{A numeric vector representing the transformed feature with WoE values for each observation.}
\item{woebin}{A data frame containing detailed statistics for each bin, including counts, WoE, and IV.}
}
\description{
This function performs optimal binning of categorical variables based on predefined cutpoints,
calculates the Weight of Evidence (WoE) and Information Value (IV) for each bin,
and transforms the feature accordingly.
}
\details{
Binning is a preprocessing step that groups categories of a categorical feature into a smaller number of bins.
This function performs binning based on user-defined cutpoints, where each cutpoint specifies a group of categories
that should be combined into a single bin. The resulting bins are evaluated using the WoE and IV metrics, which
are often used in predictive modeling, especially in credit risk modeling.

The Weight of Evidence (WoE) is calculated as:
\deqn{\text{WoE} = \log\left(\frac{\text{Positive Rate}}{\text{Negative Rate}}\right)}
where the Positive Rate is the proportion of positive observations (target = 1) within the bin, and the Negative Rate is the proportion of negative observations (target = 0) within the bin.

The Information Value (IV) measures the predictive power of the categorical feature and is calculated as:
\deqn{IV = \sum (\text{Positive Rate} - \text{Negative Rate}) \times \text{WoE}}

The IV metric provides insight into how well the binned feature predicts the target variable:
\itemize{
\item IV < 0.02: Not predictive
\item 0.02 ≤ IV < 0.1: Weak predictive power
\item 0.1 ≤ IV < 0.3: Medium predictive power
\item IV ≥ 0.3: Strong predictive power
}

WoE is used to transform the categorical variable into a continuous numeric variable, which can be used directly in logistic regression and other predictive models.
}
\examples{
\dontrun{
# Example usage
feature <- c("A", "B", "C", "A", "B", "C", "A", "C", "C", "B")
target <- c(1, 0, 1, 1, 0, 0, 0, 1, 1, 0)
cutpoints <- c("A+B", "C")
result <- binning_categorical_cutpoints(feature, target, cutpoints)
print(result$woefeature)  # WoE-transformed feature
print(result$woebin)      # WoE and IV statistics for each bin
}

}
\references{
Siddiqi, N. (2006). Credit Risk Scorecards: Developing and Implementing Intelligent Credit Scoring.
John Wiley & Sons.
}

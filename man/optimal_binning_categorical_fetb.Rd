% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RcppExports.R
\name{optimal_binning_categorical_fetb}
\alias{optimal_binning_categorical_fetb}
\title{Categorical Optimal Binning with Fisher's Exact Test}
\usage{
optimal_binning_categorical_fetb(
  target,
  feature,
  min_bins = 3L,
  max_bins = 5L,
  bin_cutoff = 0.05,
  max_n_prebins = 20L
)
}
\arguments{
\item{target}{Integer vector of binary target values (0 or 1).}

\item{feature}{Character vector of categorical feature values.}

\item{min_bins}{Minimum number of bins (default: 3).}

\item{max_bins}{Maximum number of bins (default: 5).}

\item{bin_cutoff}{Minimum frequency for a separate bin (default: 0.05).}

\item{max_n_prebins}{Maximum number of pre-bins before merging (default: 20).}
}
\value{
A list with two elements:
\itemize{
\item woefeature: Numeric vector of WoE values for each input feature value.
\item woebin: Data frame with binning results (bin names, WoE, IV, counts).
}
}
\description{
Implements optimal binning for categorical variables using Fisher's Exact Test,
calculating Weight of Evidence (WoE) and Information Value (IV).
}
\details{
The algorithm uses Fisher's Exact Test to iteratively merge bins, maximizing
the statistical significance of the difference between adjacent bins.

Weight of Evidence (WoE) for each bin is calculated as:

\deqn{WoE = \ln\left(\frac{P(X|Y=1)}{P(X|Y=0)}\right)}

Information Value (IV) for each bin is calculated as:

\deqn{IV = (P(X|Y=1) - P(X|Y=0)) \times WoE}

Fisher's Exact Test p-value is calculated using the hypergeometric distribution:

\deqn{p = \frac{{a+b \choose a}{c+d \choose c}}{{n \choose a+c}}}

where a, b, c, d are the elements of the 2x2 contingency table, and n is the total sample size.

The algorithm first merges rare categories based on the bin_cutoff, then
iteratively merges bins with the lowest p-value from Fisher's Exact Test
until the desired number of bins is reached or further merging is not statistically significant.
}
\examples{
\dontrun{
# Sample data
target <- c(1, 0, 1, 1, 0, 1, 0, 0, 1, 1)
feature <- c("A", "B", "A", "C", "B", "D", "C", "A", "D", "B")

# Run optimal binning
result <- optimal_binning_categorical_fetb(target, feature, min_bins = 2, max_bins = 4)

# View results
print(result$woefeature)
print(result$woebin)
}

}
\references{
\itemize{
\item Agresti, A. (1992). A Survey of Exact Inference for Contingency Tables.
Statistical Science, 7(1), 131-153.
\item Savage, L. J. (1956). On the Choice of a Classification Statistic.
In Contributions to Probability and Statistics: Essays in Honor of Harold Hotelling,
Stanford University Press, 139-161.
}
}
\author{
Lopes, J. E.
}

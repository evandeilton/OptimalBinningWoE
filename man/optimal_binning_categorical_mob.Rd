% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RcppExports.R
\name{optimal_binning_categorical_mob}
\alias{optimal_binning_categorical_mob}
\title{Optimal Binning for Categorical Variables using Monotonic Optimal Binning (MOB)}
\usage{
optimal_binning_categorical_mob(
  target,
  feature,
  min_bins = 3L,
  max_bins = 5L,
  bin_cutoff = 0.05,
  max_n_prebins = 20L,
  bin_separator = "\%;\%",
  convergence_threshold = 1e-06,
  max_iterations = 1000L
)
}
\arguments{
\item{target}{An integer vector of binary target values (0 or 1).}

\item{feature}{A character vector of categorical feature values.}

\item{min_bins}{Minimum number of bins (default: 3).}

\item{max_bins}{Maximum number of bins (default: 5).}

\item{bin_cutoff}{Minimum proportion of observations in a bin (default: 0.05).}

\item{max_n_prebins}{Maximum number of pre-bins (default: 20).}

\item{bin_separator}{Separator used for merging category names (default: "\%;\%").}

\item{convergence_threshold}{Convergence threshold for the algorithm (default: 1e-6).}

\item{max_iterations}{Maximum number of iterations for the algorithm (default: 1000).}
}
\value{
A list containing the following elements:
\itemize{
\item id: Numeric vector of bin identifiers.
\item bin: Character vector of bin names (merged categories).
\item woe: Numeric vector of Weight of Evidence (WoE) values for each bin.
\item iv: Numeric vector of Information Value (IV) for each bin.
\item count: Integer vector of total counts for each bin.
\item count_pos: Integer vector of positive target counts for each bin.
\item count_neg: Integer vector of negative target counts for each bin.
\item total_iv: Total Information Value of the binning.
\item converged: Logical value indicating whether the algorithm converged.
\item iterations: Integer value indicating the number of iterations run.
}
}
\description{
Performs optimal binning for categorical variables using the Monotonic Optimal Binning (MOB)
approach with enhanced statistical robustness. This implementation includes Bayesian smoothing
for better stability with small samples, adaptive monotonicity enforcement, and sophisticated
bin merging strategies.
}
\details{
This enhanced version of the Monotonic Optimal Binning (MOB) algorithm implements several
key improvements over traditional approaches:

\strong{Mathematical Framework:}

The Weight of Evidence (WoE) with Bayesian smoothing is calculated as:

\deqn{WoE_i = \ln\left(\frac{p_i^*}{q_i^*}\right)}

where:
\itemize{
\item \eqn{p_i^* = \frac{n_i^+ + \alpha \cdot \pi}{N^+ + \alpha}} is the smoothed proportion of
events in bin i
\item \eqn{q_i^* = \frac{n_i^- + \alpha \cdot (1-\pi)}{N^- + \alpha}} is the smoothed proportion of
non-events in bin i
\item \eqn{\pi = \frac{N^+}{N^+ + N^-}} is the overall event rate
\item \eqn{\alpha} is the prior strength parameter (default: 0.5)
\item \eqn{n_i^+} is the count of events in bin i
\item \eqn{n_i^-} is the count of non-events in bin i
\item \eqn{N^+} is the total number of events
\item \eqn{N^-} is the total number of non-events
}

The Information Value (IV) for each bin is calculated as:

\deqn{IV_i = (p_i^* - q_i^*) \times WoE_i}

\strong{Algorithm Phases:}
\enumerate{
\item \strong{Initialization:} Calculate statistics for each category with Bayesian smoothing.
\item \strong{Pre-binning:} Create initial bins sorted by WoE.
\item \strong{Rare Category Handling:} Merge categories with frequency below bin_cutoff using a similarity-based approach.
\item \strong{Monotonicity Enforcement:} Ensure monotonic WoE across bins using adaptive thresholds and severity-based prioritization.
\item \strong{Bin Optimization:} Reduce number of bins to max_bins while maintaining monotonicity.
\item \strong{Solution Tracking:} Maintain the best solution found during optimization.
}

\strong{Key Features:}
\itemize{
\item Bayesian smoothing for robust WoE estimation with small samples
\item Similarity-based bin merging rather than just adjacent bins
\item Adaptive monotonicity enforcement with violation severity prioritization
\item Best solution tracking to ensure optimal results
\item Efficient uniqueness handling for categories
\item Comprehensive edge case handling
\item Strict enforcement of max_bins parameter
}
}
\examples{
\dontrun{
# Create sample data
set.seed(123)
target <- sample(0:1, 1000, replace = TRUE)
feature <- sample(LETTERS[1:5], 1000, replace = TRUE)

# Run optimal binning
result <- optimal_binning_categorical_mob(target, feature)

# View results
print(result)

# Force exactly 2 bins
result2 <- optimal_binning_categorical_mob(
  target, feature, 
  min_bins = 2, 
  max_bins = 2
)
}

}
\references{
\itemize{
\item Belotti, T., Crook, J. (2009). Credit Scoring with Macroeconomic Variables Using Survival Analysis.
\emph{Journal of the Operational Research Society}, 60(12), 1699-1707.
\item Mironchyk, P., Tchistiakov, V. (2017). Monotone optimal binning algorithm for credit risk modeling.
\emph{arXiv preprint} arXiv:1711.05095.
\item Gelman, A., Jakulin, A., Pittau, M. G., & Su, Y. S. (2008). A weakly informative default prior
distribution for logistic and other regression models. The annals of applied statistics, 2(4), 1360-1383.
\item Navas-Palencia, G. (2020). Optimal binning: mathematical programming formulations for binary
classification. arXiv preprint arXiv:2001.08025.
\item Thomas, L.C., Edelman, D.B., & Crook, J.N. (2002). Credit Scoring and its Applications. SIAM.
}
}

% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RcppExports.R
\name{optimal_binning_numerical_gmb}
\alias{optimal_binning_numerical_gmb}
\title{Optimal Binning for Numerical Variables using Greedy Monotonic Binning}
\usage{
optimal_binning_numerical_gmb(
  target,
  feature,
  min_bins = 3L,
  max_bins = 5L,
  bin_cutoff = 0.05,
  max_n_prebins = 20L
)
}
\arguments{
\item{target}{An integer vector of binary target values (0 or 1).}

\item{feature}{A numeric vector of feature values to be binned.}

\item{min_bins}{Minimum number of bins (default: 3).}

\item{max_bins}{Maximum number of bins (default: 5).}

\item{bin_cutoff}{Minimum fraction of total observations in each bin (default: 0.05).}

\item{max_n_prebins}{Maximum number of pre-bins (default: 20).}
}
\value{
A list containing:
\item{woefeature}{A numeric vector of Weight of Evidence (WoE) values for each observation}
\item{woebin}{A data frame with binning information, including bin ranges, WoE, IV, and counts}
}
\description{
This function implements an optimal binning algorithm for numerical variables using a greedy monotonic binning approach. It aims to find the best binning strategy that maximizes the predictive power while ensuring monotonicity in the Weight of Evidence (WoE) values.
}
\details{
The optimal binning algorithm using greedy monotonic binning consists of several steps:
\enumerate{
\item Initial binning: The feature is initially divided into a maximum number of bins specified by \code{max_n_prebins}.
\item Merging low-frequency bins: Bins with a fraction of observations less than \code{bin_cutoff} are merged with adjacent bins.
\item Calculating WoE and IV: The Weight of Evidence (WoE) and Information Value (IV) are calculated for each bin.
\item Enforcing monotonicity: The algorithm ensures that the WoE values are either monotonically increasing or decreasing across the bins.
}

The Weight of Evidence (WoE) for each bin is calculated as:

\deqn{WoE = \ln\left(\frac{P(X|Y=1)}{P(X|Y=0)}\right)}

where \eqn{P(X|Y=1)} is the probability of the feature being in a particular bin given a positive target, and \eqn{P(X|Y=0)} is the probability given a negative target.

The Information Value (IV) for each bin is calculated as:

\deqn{IV = (P(X|Y=1) - P(X|Y=0)) * WoE}

The algorithm uses a greedy approach to enforce monotonicity:
\enumerate{
\item Check if the initial WoE values are monotonic (increasing or decreasing).
\item If not monotonic, iteratively merge adjacent bins with the smallest WoE difference until monotonicity is achieved or the minimum number of bins is reached.
\item After each merge, recalculate WoE and IV values and check for monotonicity.
}

This approach ensures that the final binning solution has monotonic WoE values, which is often desirable for interpretability and stability of the binning.
}
\examples{
\dontrun{
set.seed(123)
target <- sample(0:1, 1000, replace = TRUE)
feature <- rnorm(1000)
result <- optimal_binning_numerical_gmb(target, feature)
print(result$woebin)
}

}
\references{
\itemize{
\item Belotti, P., & Carrasco, M. (2017). Optimal binning: mathematical programming formulation and solution approach. arXiv preprint arXiv:1705.03287.
\item Mironchyk, P., & Tchistiakov, V. (2017). Monotone optimal binning algorithm for credit risk modeling. arXiv preprint arXiv:1711.06692.
}
}
\author{
Lopes, J. E.
}
